[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Numerical Analysis 2018-23",
    "section": "",
    "text": "1 Introduction\nIn our digital age, mathematics isn’t just an abstract pursuit; it’s an essential tool that powers a vast array of applications. From weather forecasting to black hole simulations, from urban planning to medical research, the application of mathematics has become indispensable. Central to this applied force is Numerical Analysis.\nNumerical Analysis is the discipline that bridges continuous mathematical theories with their concrete implementation on digital computers. These computers, by design, work with discrete quantities, and translating continuous problems into this discrete realm isn’t always straightforward. So why should you want to venture into Numerical Analysis?\n\nPrecision and Stability: Computers, despite their power, can introduce significant errors if mathematical problems are implemented without care. Numerical Analysis offers techniques to ensure we obtain results that are both accurate and stable.\nEfficiency: Real-world applications often demand not just correctness, but efficiency. By grasping the methods of Numerical Analysis, we can design algorithms that are both accurate and resource-efficient.\nBroad Applications: Whether your interest lies in physics, engineering, biology, finance, or many other scientific fields, Numerical Analysis provides the computational tools to tackle complex problems in these areas.\nBasis for Modern Technologies: Core principles of Numerical Analysis are foundational in emerging fields such as artificial intelligence, quantum computing, and data science.\n\nIn this module, we’ll explore the key techniques, algorithms, and principles of Numerical Analysis that enable us to translate mathematical problems into computational solutions. We’ll delve into the challenges that arise in this translation, the strategies to overcome them, and the interaction of theory and practice.\nBy the end, you won’t merely understand the methods of scientific computing; you’ll be equipped to apply them efficiently and effectively in diverse scenarios. With a strong foundation in Numerical Analysis, you’ll be better prepared to engage with the practical challenges of the modern world.\nThe main topic of this module is finding approximate solutions to various mathematical problems. A typical example for such a problem would be to find \\(x&gt;0\\) such that \\(\\cos(x)=x\\).\n\n\nCode\n# plot the function cos(x) and the line y=x\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the range for x values\nx = np.linspace(0, np.pi/2, 100)\n\n# Plot cos(x)\nplt.plot(x, np.cos(x), label='cos(x)')\n\n# Plot y = x\nplt.plot(x, x, label='y=x')\n\n# Adding a legend\nplt.legend()\n\n\n\n\n\n\n\n\nFigure 1.1\n\n\n\n\n\nThere is indeed one and only one such \\(x\\); this is apparent from a graph (Figure 1.1), and can also be proven rigorously without too much difficulty. However, it seems impossible to find a closed form expression for this \\(x\\): It’s not a fraction, a square root of a fraction, an integer multiple of \\(\\pi\\), etc. For practical purposes, the best we can give is a numerical approximation of this \\(x\\), that is, we can compute it to, say, 10 decimal digits of accuracy.\nThis situation is pervasive in mathematics and its applications. Many problems of practical importance can be solved only approximately, and for others an approximation is much more efficient to find than the closed-form expression.\nIn Numerical Analysis, we aim to find approximation algorithms for mathematical problems, i.e., schemes that allow us to compute the solution approximately. These algorithms use only elementary operations (\\(+,-,\\times,/\\)) but often a long sequence of them, so that in practice they need to be run on computers. This part of the problem—how to implement such algorithms on a computer—is called Scientific Computing.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapter02.html",
    "href": "chapter02.html",
    "title": "2  Errors",
    "section": "",
    "text": "2.1 Floating point numbers\nAs we embark on our exploration of Numerical Analysis, it might be tempting to dive directly into the algorithms, tools, and techniques that form the core of this discipline. Yet, there’s a foundational aspect that we must address before we venture further: errors. Just as a builder needs to understand the properties and potential weaknesses of materials before constructing a robust building, a numerical analyst must grasp the nuances of errors in order to craft effective and reliable algorithms.\nWhy start with errors? Here’s why this is the perfect launching pad:\nErrors are not just a minor consideration; they are central to the field of Numerical Analysis. By addressing them upfront, we lay a solid foundation upon which the rest of our study will be built. This chapter will shed light on the nature of rounding errors, demonstrate how seemingly benign calculations can lead to substantial inaccuracies, and offer insights into mitigating these pitfalls.\nSo, as we delve into the world of errors, remember: understanding our limitations and challenges is the first step to overcoming them. Let us begin our journey with a clear-eyed view of the obstacles, so we are best prepared to navigate the rich landscape of Numerical Analysis.\nAs mentioned, our goal is to find approximate rather than exact solutions to problems. That is, our results will always contain errors. Errors can arise in several ways:\nItem a is outside our scope in this course. In this chapter, we will discuss roundoff errors (item b). Approximation errors (item c) will be discussed in later chapters.\nWe can write any real number in floating point notation \\[\nx=\\pm 0.d_{1}d_{2}d_{3}\\dots d_{k}d_{k+1}d_{k+2}\\dots \\times 10^n.\n\\tag{2.1}\\]\nThe number \\(\\pm 0. d_{1} d_{2}d_{3} \\ldots d_{k}\\ldots\\) is called the mantissa and the power of ten is called the exponent. However, a computer can work only with finite set of digits. Therefore, we truncate the mantissa and limit the range of the exponent \\(n\\) to produce a \\(k\\)-digit (decimal) machine number. This can be done in two ways:\nEither machine number is called (decimal) \\(k\\)-digit floating point representation of \\(x\\), and denoted by \\(fl(x)\\).\nThe error resulting from replacing a number by its floating-point form is called roundoff error. In order to quantify roundoff errors (and other errors), we introduce:\nWith these notions, our roundoff errors can be estimated. If \\(x^\\ast=fl(x)\\) is obtained by \\(k\\)-digit chopping, then (prove it!) \\[\n\\frac{\\vert x-x^\\ast\\vert}{\\vert x \\vert}\\leq 10^{-k+1}.\n\\tag{2.10}\\] If \\(x^\\ast=fl(x)\\) is obtained by \\(k\\)-digit rounding, then (prove it!) \\[\n\\frac{\\vert x-x^\\ast\\vert}{\\vert x \\vert}\\leq 0.5\\times 10^{-k+1}.\n\\tag{2.11}\\]\nIn other words, \\(x^\\ast\\) approximates \\(x\\) to \\(k\\) significant digits if and only if: \\[\n0.1\\times 10^{n-k}\\leq \\vert x^\\ast-x\\vert &lt; 0.5\\times 10^{n-k}.\n\\tag{2.12}\\]\nIt can be shown that if \\(x^\\ast=fl(x)\\) is obtained by \\(k\\)-digit rounding, then \\(x^\\ast\\) has at least \\(k\\) significant digits with respect to \\(x\\).\nFurther reading: Section 1.2 of (Burden and Faires 2010).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Errors</span>"
    ]
  },
  {
    "objectID": "chapter02.html#floating-point-numbers",
    "href": "chapter02.html#floating-point-numbers",
    "title": "2  Errors",
    "section": "",
    "text": "Chopping results in \\[\nx^\\ast=\\pm 0.d_{1}d_{2}...d_{k}\\times 10^n .\n\\tag{2.2}\\]\nRounding results in \\[\nx^\\ast=\\pm 0.d_{1}d_{2}...d_{k-1}d^{*}_{k}\\times 10^n,\n\\tag{2.3}\\] where \\(x^\\ast\\) is obtained by adding \\(0.5\\times 10^{n-k}\\) (or, equivalently, \\(5\\times10^{n-k-1}\\) to \\(x\\) and chopping.\n\n\n\nExample 2.1 The floating point representation of \\(\\pi=3.14159265\\ldots\\) is \\[\n\\pi=0.314159265\\ldots\\times10^1.\n\\tag{2.4}\\] The five-digit floating-point form of \\(\\pi\\) is given by \\[\nfl(\\pi)=0.31415\\times10^1=3.1415\n\\tag{2.5}\\] if chopping is used. In the case of rounding, we first compute \\[\n\\begin{split}\n\\pi+0.5\\times 10^{1-5} &= 0.314159265\\ldots\\times10^1 + 0.000005\\ldots\\times10^1 \\\\\n&=  0.314164265\\ldots\\times10^1\n\\end{split}\n\\tag{2.6}\\] and then chop to obtain \\[\nfl(\\pi)=0.31416\\times10^1=3.1416.\n\\tag{2.7}\\]\n\n\nRemark. In this module, we represent numbers in decimal (base 10) form. Computers actually use binary (base 2) form, but we will usually ignore this difference. Industry standards exist for representing floating point numbers in binary form. For example, a double-precision floating-point number according to Binary Floating Point Arithmetic Standard 574–1985 developed by the IEEE (Institute for Electrical and Electronic Engineers) consists of\n\n1-bit (binary digit) sign indicator,\n11-bit exponent with a base of 2,\n52-bit mantissa.\n\nThis provides between 15 and 16 decimal digits of precision and a range of approximately \\(10^{-308}\\) to \\(10^{+308}\\) (and similarly \\(-10^{+308}\\) to \\(-10^{-308}\\) for negative numbers). If numbers occurring in calculations have a magnitude of less than the lower limit (\\(\\approx 10^{-308}\\)), they are set to zero; this is called underflow. Numbers greater than the upper limit (\\(\\approx 10^{+308}\\)) result in overflow and computations are halted.\n\n\n\nDefinition 2.1 If \\(x^\\ast\\) is an approximation to \\(x\\), the absolute error is \\[\nE_{abs}:=\\vert x-x^\\ast\\vert,\n\\tag{2.8}\\] and the relative error (for \\(x\\neq 0\\)) is \\[\nE_{rel}:=\\frac{\\lvert x-x^\\ast\\rvert}{\\lvert x \\rvert} .\n\\tag{2.9}\\]\n\n\n\nDefinition 2.2 Suppose that a number \\(x^\\ast\\) approximates \\(x\\) and that \\(x^\\ast\\neq x\\). We say that \\(x^\\ast\\) approximates \\(x\\) to \\(k\\) significant digits (or \\(x^\\ast\\) has \\(k\\) significant digits with respect to \\(x\\)) if\n\nthe floating point representations of \\(x^\\ast\\) and \\(x\\) have the same exponent, say \\(n\\);\nthe exponent of \\(\\vert x^\\ast-x\\vert\\) is \\(n-k\\) and the first digit of its mantissa is less than or equal to \\(5\\).\n\n\n\n\nExample 2.2 Suppose that \\(x=23.492=0.23492\\times 10^{2}\\) and \\(x^\\ast=23.489=0.23489\\times 10^{2}\\). Then the absolute error is \\[\n\\vert x^\\ast-x\\vert=0.00003\\times 10^{2}=0.3\\times 10^{-2},\n\\tag{2.13}\\] so \\(x^\\ast\\) approximates \\(x\\) to \\(4\\) significant digits. The relative error is \\[\n\\frac{\\lvert x-x^\\ast\\rvert}{\\lvert x \\rvert} = \\frac{0.3\\times 10^{-2}}{0.23492\\times 10^{2}}\\approx0.1277\\times10^{-3}.\n\\tag{2.14}\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Errors</span>"
    ]
  },
  {
    "objectID": "chapter02.html#error-generating-computations",
    "href": "chapter02.html#error-generating-computations",
    "title": "2  Errors",
    "section": "2.2 Error-generating computations",
    "text": "2.2 Error-generating computations\nIn each arithmetic computation performed by a computer on floating point numbers, additional roundoff error may occur. Let us illustrate this in the example of addition. Let \\(x,y\\) be two real numbers and \\(x^\\ast = fl(x)\\), \\(y^\\ast = fl(y)\\). We denote the computer-performed addition of \\(x^\\ast\\) and \\(y^\\ast\\) as \\(x^\\ast \\oplus y^\\ast\\), as opposed to the normal addition \\(+\\). In a simple model, we will assume that \\(\\oplus\\) is just normal addition followed by rounding: \\[\nx^\\ast \\oplus y^\\ast = fl(x^\\ast + y^\\ast).\n\\tag{2.15}\\] Rounding is unavoidable in general due to the finite length of the mantissa, and generates additional error. Let us quantify this by estimating the absolute error of \\(x^\\ast \\oplus y^\\ast\\), as an approximation for \\(x+y\\). Using the triangle inequality, we obtain \\[\n\\begin{split}\n     \\lvert x+y - x^\\ast \\oplus y^\\ast \\rvert\n  &=\n     \\lvert x-x^\\ast \\; + \\; y - y^\\ast \\; + \\; x^\\ast + y^\\ast  -  fl(x^\\ast + y^\\ast) \\rvert\n   \\\\\n  &\\leq\n     \\lvert x-x^\\ast \\rvert + \\lvert y - y^\\ast \\rvert + \\lvert x^\\ast + y^\\ast  - fl(x^\\ast + y^\\ast) \\rvert.\n  \\end{split}\n\\tag{2.16}\\] Thus, the total absolute error is the sum of the individual absolute errors for \\(x^\\ast\\) and \\(y^\\ast\\), plus an extra term arising from rounding.\nFrom this, it might seem that addition is relatively unaffected by rounding—after all, the rounding error occurs in the last digit of the mantissa. However, there are several situations where the rounding error can become very relevant. First, if we are performing a large number of additions (say, several thousands), then every one of these can cause an additional (small) rounding error, and the sum of these may be quite large. Second, the relative error can increase significantly in the case of subtraction, which is included in the above by considering \\(y&lt;0\\).\n\nExample 2.3 Consider 5-digit rounding and set \\[\nx = 1 + \\frac{\\pi}{1000}, \\quad x^\\ast = 1.0031, \\quad y=y^\\ast = -1.\n\\tag{2.17}\\] In this case, \\(x^\\ast \\oplus y^\\ast = fl(0.0031) = 3.1 \\times 10^{-3}\\). The absolute errors of \\(x^\\ast\\) and \\(x^\\ast\\oplus y^\\ast\\), as well as the relative error of \\(x^\\ast\\), are approximately \\(0.4 \\times 10^{-4}\\). However, the relative error of \\(x^\\ast\\oplus y^\\ast\\) is approximately \\(0.4 \\times 10^{-4} / 3.1 \\times 10^{-3} \\approx 10^{-2}\\)—subtraction has increased it significantly, and \\(x^\\ast\\oplus y^\\ast\\) has only 2 valid digits.\n\nThis phenomenon is called cancellation of digits and occurs whenever two almost equal numbers are subtracted from each other.\nMultiplication behaves similar to addition, only that the relative error is the sum of the individual relative errors, plus an extra error arising from rounding. Also, multiplying a machine number \\(x^\\ast\\) by a large number (or dividing by a small number) will not much affect the relative error, but significantly increase the absolute error.\nTo summarize, typical sources of significant roundoff error are\n\nperforming a large number of individual arithmetic operations (e.g., additions),\nsubtraction of almost equal numbers,\nmultiplication by a very large number, or division by a very small number.\n\nWhere these occur, it can be worthwhile to reformulate the algebraic expressions suitably in order to circumvent the roundoff problem. Several examples for this can be found in Practical A1.\nRoundoff errors occur in virtually all numerical methods that we will consider. However, for reasons of simplicity, we will usually ignore roundoff errors in the theoretical discussion, and mention them only where they become particularly relevant.\nFurther reading: Section 1.2 of (Burden and Faires 2010).\n\n\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical Analysis. 9th ed. Brooks Cole.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Errors</span>"
    ]
  },
  {
    "objectID": "chapter03.html",
    "href": "chapter03.html",
    "title": "3  Solving nonlinear equations",
    "section": "",
    "text": "3.1 Defining the problem\nHaving navigated the intricacies of rounding errors and understanding the nuances they introduce, it is time to delve into one of the cornerstones of Numerical Analysis: solving nonlinear equations, also known as the root-finding problem. The challenge of finding the roots of equations that do not lend themselves to simple algebraic solutions has been a persistent one throughout the history of mathematics. Yet, it is exactly these challenges that have spurred the development of a rich array of techniques, many of which are iterative in nature.\nWhy start with nonlinear equations? The reasons are manifold:\nThroughout this chapter, we will dissect each method, understanding its mechanics, advantages, drawbacks, and areas of application. Through hands-on examples and explorations, you will gain not just theoretical knowledge, but practical skills that are immediately applicable.\nLet \\(f:[a,b] \\to \\mathbb{R}\\) be a continuous function, i.e. \\(f\\in C[a,b]\\). The task is to find an \\(p \\in [a,b]\\) such that \\[\nf(p)=0.\n\\tag{3.1}\\] The number \\(p\\) is called a root of the equation or a zero of the function \\(f\\). In our example in the introduction, we had \\(f(x)=\\cos(x)-x\\).\nThe first question to clarify is whether such a root exists. If we assume that \\(f\\) changes sign on \\([a,b]\\), that is, that \\(f(a)f(b)&lt;0\\), then we know (by the Intermediate Value Theorem) that \\(f\\) must have a zero in \\([a,b]\\). However, in general there could be more than one zero in the interval. For our purposes, we will always assume that \\(f\\) has a unique zero \\(p\\in (a,b)\\), and we will investigate our algorithms under that assumptions. In practice, one would first need to choose the interval \\([a,b]\\) suitably so that it contains a unique zero.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Solving nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter03.html#bisection-method",
    "href": "chapter03.html#bisection-method",
    "title": "3  Solving nonlinear equations",
    "section": "3.2 Bisection method",
    "text": "3.2 Bisection method\nThe bisection method is a very simple approach to the root finding problem, and one where the approximation error is very easy to control. The idea behind it is as follows: One divides the interval \\([a,b]\\) into halves, and decides in which subinterval the zero is located (by looking at the sign of \\(f(x)\\) in the midpoint of the interval). Then one repeats the method for this subinterval, and continues this until sufficient precision is reached.\n\n\n\n\n\n\nFigure 3.1: Bisection method\n\n\n\nMore formally, the bisection method would be described as follows:\n\nSet \\(a_{1}=a\\), \\(b_{1}=b\\), and \\(x_{1}=(a_{1}+b_{1})/2\\).\nCompute \\(f(x_{1})\\).\nIf \\(f(x_{1})=0\\), then \\(p=x_{1}\\).\nIf \\(f(x_{1})\\neq 0\\), then we choose \\(a_{2}\\) and \\(b_{2}\\) as follows:\n\nif \\(f(x_{1})\\cdot f(a_{1}) &gt; 0\\) (i.e. \\(f(x_{1})\\) and \\(f(a_{1})\\) have the same sign), then we know \\(p\\in (x_{1}, b_{1})\\), and we set \\(a_{2}=x_{1}\\) and \\(b_{2}=b_{1}\\);\nif \\(f(x_{1})\\cdot f(a_{1}) &lt; 0\\) (i.e. \\(f(x_{1})\\) and \\(f(a_{1})\\) have opposite signs), then we know \\(p\\in (a_{1}, x_{1})\\), and we set \\(a_{2}=a_{1}\\) and \\(b_{2}=x_{1}\\).\n\nWe repeat the procedure for the interval \\([a_{2}, b_{2}]\\) and so on until we compute \\(p\\) with a specified accuracy.\n\nWe now show that this method actually works as expected: namely, that the sequence \\((x_n)\\) converges to the root \\(p\\), and that we can control the error of \\((x_n)\\) approximating \\(p\\).\n\nTheorem 3.1 Suppose that \\(f\\in C[a, b]\\) has a unique zero \\(p\\) and that \\(f(a)\\cdot f(b) &lt; 0\\). Then the sequence \\(\\{x_n\\}\\) of the bisection method converges to \\(p\\), and \\[\n\\left\\vert x_{n} - p\\right\\vert\\leq \\frac{ b-a}{2^{n}} \\quad \\text{for all }n\\ge1.\n\\tag{3.2}\\]\n\n\nProof. For \\(n\\geq 1\\), we have by construction \\[\na_{n} \\leq p \\leq b_{n} .\n\\tag{3.3}\\] Subtracting \\(x_{n}\\) from this inequality yields \\[\na_n-x_{n}  \\leq p - x_n \\leq b_n - x_{n}.\n\\tag{3.4}\\] Recalling that \\(x_{n}=(a_{n}+b_{n})/2\\), we can rewrite this as \\[\n-\\frac{b_{n}- a_{n}}{2} \\leq p - x_{n}  \\leq \\frac{b_{n}- a_{n}}{2},\n\\tag{3.5}\\] or equivalently, since \\(b_n-a_n=(b-a)/2^{n-1}\\), \\[\n\\left\\vert p-x_{n}\\right\\vert\n\\leq \\frac{1}{2}\\left(b_{n} - a_{n}\\right)\n= \\frac{ b-a}{2^{n}} .\n\\tag{3.6}\\] This implies that \\(x_{n} \\to p\\) as \\(n \\to \\infty\\) and also gives us the proposed error estimate.  ◻\n\n\nExample 3.1 Let us find an approximation to \\(\\sqrt{2}\\) correct to within \\(10^{-3}\\). Consider the function \\(f(x)=x^{2}-2\\). One of its zeros is \\(\\sqrt{2}\\). If we take \\(a=1\\) and \\(b=2\\), then \\(f(a)=-1&lt;0\\) and \\(f(b)=2&gt;0\\). In addition, we know that \\(\\sqrt{2}\\) is the unique zero of \\(f\\) on the interval \\([a, b]\\). Now we can apply the bisection method and calculate an approximation to \\(\\sqrt{2}\\).\nFirst, we calculate the number of steps necessary to compute \\(\\sqrt{2}\\) with accuracy \\(10^{-3}\\). This requires to find an integer \\(N\\) such that \\[\n\\vert x_{N}-p\\vert\\leq \\frac{b-a}{2^{N}}=2^{-N}&lt; 10^{-3}.\n\\tag{3.7}\\] Since \\(2^{10}=1024\\), this inequality is satisfied if we take \\(N=10\\). Table 3.1 shows the results of the bisection method.\n\n\nCode\nimport pandas as pd\n\n# Define the function\ndef f(x):\n    return x**2 - 2\n\n# Initialize parameters\nN = 10\na = 1.0\nb = 2.0\n\n# Initialize a list to store the data\ndata = []\n\n# Bisection method\nfor i in range(1, N + 1):\n    # Find the middle point\n    x = (a + b) / 2\n    \n    # Add the values to the data list\n    data.append({'n': i, 'a': a, 'b': b, 'x': x, 'f_x': f(x)})\n    \n    # Decide the side to repeat the steps\n    if f(x) * f(a) &lt; 0:\n        b = x\n    else:\n        a = x\n\npd.DataFrame(data)\n\n\n\n\nTable 3.1: Ten iterations of the bisection method for approximating \\(\\sqrt{2}\\)\n\n\n\n\n\n\n\n\n\n\nn\na\nb\nx\nf_x\n\n\n\n\n0\n1\n1.000000\n2.000000\n1.500000\n0.250000\n\n\n1\n2\n1.000000\n1.500000\n1.250000\n-0.437500\n\n\n2\n3\n1.250000\n1.500000\n1.375000\n-0.109375\n\n\n3\n4\n1.375000\n1.500000\n1.437500\n0.066406\n\n\n4\n5\n1.375000\n1.437500\n1.406250\n-0.022461\n\n\n5\n6\n1.406250\n1.437500\n1.421875\n0.021729\n\n\n6\n7\n1.406250\n1.421875\n1.414062\n-0.000427\n\n\n7\n8\n1.414062\n1.421875\n1.417969\n0.010635\n\n\n8\n9\n1.414062\n1.417969\n1.416016\n0.005100\n\n\n9\n10\n1.414062\n1.416016\n1.415039\n0.002336\n\n\n\n\n\n\n\n\n\n\nThus, \\(\\sqrt{2}\\approx 1.4150\\) with absolute error smaller than \\(10^{-3}\\) (Note that \\(\\sqrt{2}=1.414213562373095\\ldots\\), so that the actual error is \\(E=\\vert x_{10}-\\sqrt{2}\\vert=0.0008255001269048545\\ldots\\)).\nThis example illustrates that the method converges, although rather slowly—we will come across much faster methods in due course. Also, it appears that the method is unnecessarily inefficient—note that \\(x_7\\) was a better approximation to \\(\\sqrt{2}\\) than \\(x_{10}\\). On the other hand, the advantage is the simple and clear error estimate.\n\nFinally, let us write the algorithm in a form that is more adapted to a computer implementation. We do not use a specific programming language here, but pseudocode. The bisection method is formulated in Algorithm 2.1. This matches our heuristic description above; note however that there are a number of efficiency improvements: We do not need to store the entire sequences \\(\\{a_n\\}\\), \\(\\{b_n\\}\\), \\(\\{x_n\\}\\), but only their “current” values, which we label \\(a,b,x\\). Also, by storing intermediate results, one tries to evaluate \\(f\\) as few times as possible, which means that the implementation is efficient even if evaluating \\(f\\) is time consuming.\n\n\n\n\n\n\nAlgorithm 2.1: Bisection method\n\n\n\n\n\\[\n\\begin{array}{ll}\n\\ 1: \\ \\textbf{function} \\ Bisection(f,a,b,N) &\\sharp \\ function \\ f, \\ interval \\ [a,b], \\ number \\ of \\ steps \\ N \\\\\n\\ 2: \\ \\quad F_a \\gets f(a)               & \\\\\n\\ 3: \\ \\quad \\textbf{for} \\ k \\ from \\ 1 \\ to \\ N \\ \\textbf{do} & \\\\\n\\ 4: \\ \\quad\\quad x\\gets (a+b)/2; \\ \\ F_x \\gets f(x)  &\\sharp \\ computes \\ midpoint \\ and \\ function \\ value \\ there \\\\\n\\ 5: \\ \\quad\\quad \\textbf{if} \\ F_x=0 \\ \\textbf{then}  &\\sharp \\ zero \\ has \\ already \\ been \\ found  \\\\\n\\ 6: \\ \\quad\\quad\\quad \\textbf{break}  & \\\\\n\\ 7: \\ \\quad\\quad \\textbf{else \\ if} \\ F_x\\cdot F_a &lt; 0 \\ \\textbf{then}  &\\sharp \\ zero \\ is \\ in \\ [a,x]  \\\\\n\\ 8: \\ \\quad\\quad\\quad b\\gets x  & \\\\\n\\ 9: \\ \\quad\\quad \\textbf{else} &\\sharp \\ zero \\ is \\ in \\ [x,b] \\\\\n10: \\ \\quad\\quad\\quad a\\gets x; \\ \\ F_a \\gets F_x  & \\\\\n11: \\ \\quad\\quad \\textbf{end if}  & \\\\\n12: \\ \\quad \\textbf{end for}  & \\\\\n13: \\ \\quad \\textbf{return} \\ x  & \\\\\n14: \\ \\textbf{end function} &\n\\end{array}\n\\]\n\n\n\nFurther reading: Sections 1.3, 2.1 of (Burden and Faires 2010).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Solving nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter03.html#method-of-false-position",
    "href": "chapter03.html#method-of-false-position",
    "title": "3  Solving nonlinear equations",
    "section": "3.3 Method of false position",
    "text": "3.3 Method of false position\nThe method of false position (or regula falsi method) is a slight variation of the bisection method. The idea is to choose a more efficient intermediate point \\(x\\) than just the midpoint of the interval \\([a,b]\\). Instead, one joins the points \\((a, f(a))\\) and \\((b, f(b))\\) with a straight line (the secant line) and find the point where this line intersects the \\(x\\) axis. Since the line is given by \\[\ny=f(a)+\\frac{f(b)-f(a)}{b-a}(x-a),\n\\tag{3.8}\\] this intersection point is located at \\[\n\\quad x =  a-\\frac{f(a)}{f(b)-f(a)}(b-a) .\n\\tag{3.9}\\]\nThis method is illustrated in Figure 3.2.\n\n\n\n\n\n\nFigure 3.2: Method of false position\n\n\n\nThe algorithm for the method of false position is just the same as Algorithm 2.1, except that in line 4, the statement \\(x \\gets (a+b)/2\\) is replaced by \\(x \\gets a-\\frac{f(a)}{f(b)-f(a)}(b-a)\\). (Again, one may optimize this to avoid evaluating \\(f\\) too often.)\n\nExample 3.2 Let us return to the problem of finding an approximation to \\(\\sqrt{2}\\) correct to within \\(10^{-3}\\) by finding a zero of the function \\(f(x)=x^{2}-2\\). Again taking \\(a=1\\) and \\(b=2\\), we have \\(f(a)=-1&lt;0\\) and \\(f(b)=2&gt;0\\), and so \\(\\sqrt{2}\\) is the unique zero of \\(f\\) on the interval \\([a, b]\\). Carrying out 10 steps of the method of false position, we obtain the results in Table 3.2. The desired accuracy is obtained after the fourth step. Moreover, comparing with Table 3.1, it appears that the method of False Position converges much faster than the Bisection method in this example.\n\n\n\nTable 3.2: Numerical example for method of false position\n\n\n\n\n\n\n\n\n\n\n\n\n\\(k\\)\n\\(x_n\\)\n\\(f(x_n)\\)\n\\(\\lvert x_n-\\sqrt{2}\\rvert\\)\n\n\n\n\n\n1\n1.333333333\n-0.222222223\n0.080880229\n\n\n\n2\n1.400000000\n-0.040000000\n0.014213562\n\n\n\n3\n1.411764706\n-0.006920415\n0.002448856\n\n\n\n4\n1.413793104\n-0.001189059\n0.000420458\n\n\n\n5\n1.414141414\n-0.000204061\n0.000072148\n\n\n\n6\n1.414201183\n-0.000035014\n0.000012379\n\n\n\n7\n1.414211438\n-0.000006009\n0.000002124\n\n\n\n8\n1.414213198\n-0.000001031\n3.64\\(\\times10^{-7}\\)\n\n\n\n9\n1.414213500\n\\(-1.76\\times10^{-7}\\)\n6.20\\(\\times10^{-8}\\)\n\n\n\n10\n1.414213552\n\\(-2.90\\times10^{-8}\\)\n1.00\\(\\times10^{-8}\\)\n\n\n\n\n\n\n\n\nThe animation in Figure 3.3 shows the method of false position in action.\n\n\n\n\n\n\nFigure 3.3: Method of false position\n\n\n\nThe method of false position converges faster than the bisection method in many cases. Unfortunately, it is not guaranteed that the method of false position will always converge faster—there are other examples where it actually turns out to be slower. A precise error estimate for the method of false position is hard to find, so we cannot predict how fast the method will converge.\nFurther reading: Sections 2.3 of (Burden and Faires 2010).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Solving nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter03.html#sec-fixedpoint1d",
    "href": "chapter03.html#sec-fixedpoint1d",
    "title": "3  Solving nonlinear equations",
    "section": "3.4 Fixed point iteration",
    "text": "3.4 Fixed point iteration\nWe will now investigate a different problem that is closely related to root finding: the fixed point problem. Given a function \\(g\\) (of one real argument with real values), we look for a number \\(p\\) such that \\[\ng(p)=p.\n\\tag{3.10}\\] This \\(p\\) is called a fixed point of \\(g\\).\nAny root finding problem \\(f(x)=0\\) can be reformulated as a fixed point problem, and this can be done in many (in fact, infinitely many) ways. For example, given \\(f\\), we can define \\(g(x):=f(x) + x\\); then \\[\nf(x) = 0 \\quad \\Leftrightarrow\\quad g(x)=x.\n\\tag{3.11}\\] Just as well, we could set \\(g(x):=\\lambda f(x) + x\\) with any \\(\\lambda\\in{\\mathbb R}\\backslash\\{0\\}\\), and there are many other possibilities.\nThe heuristic idea for approximating a fixed point of a function \\(g\\) is quite simple. We take an initial approximation \\(x_{0}\\) and calculate subsequent approximations using the formula \\[\nx_{n}:=g(x_{n-1}).\n\\tag{3.12}\\] A graphical representation of this sequence is shown in Figure 3.4.\n\n\n\n\n\n\nFigure 3.4: Fixed point iteration\n\n\n\nWhy is this sequence expected to approximate a fixed point? Suppose for a moment that the sequence \\((x_n)\\) converges to some number \\(p\\), and that \\(g\\) is continuous. Then \\[\np=\\lim_{n\\to\\infty}x_{n}=\\lim_{n\\to\\infty}g(x_{n-1})=\ng\\left(\\lim_{n\\to\\infty}x_{n-1}\\right)=g(p).\n\\tag{3.13}\\] Thus, if the sequence converges, then it converges to a fixed point. However, this resolves the problem only partially. One would like to know:\n\nUnder what conditions does the sequence \\((x_n)\\) converge?\nHow fast is the convergence, i.e., can one obtain an estimate for the approximation error?\n\nThe following theorem gives us the answers to those questions. We will revisit this theorem—in a more general case—later.\n\nTheorem 3.2 (Fixed Point Theorem) Suppose that \\(g:[a,b]\\to [a,b]\\) is differentiable, and that there exists \\(0&lt;k&lt;1\\) such that \\[\n\\lvert g^{\\prime}(x)\\rvert\\leq k\\quad \\text{for all }x \\in (a,b).\n\\tag{3.14}\\] Then, \\(g\\) has a unique fixed point \\(p\\in [a,b]\\); and for any choice of \\(x_0 \\in [a,b]\\), the sequence defined by \\[\nx_{n}:=g(x_{n-1}) \\quad \\text{for all }n\\ge1\n\\tag{3.15}\\] converges to \\(p\\). The following estimate holds: \\[\n\\lvert p- x_{n}\\rvert \\leq k^n \\lvert p-x_{0}\\rvert \\quad \\text{for all }n\\geq1.\n\\tag{3.16}\\]\n\n\nProof. We first show that \\(g\\) has a fixed point \\(p\\) in \\([a,b]\\). If \\(g(a)=a\\) or \\(g(b)=b\\) then \\(g\\) has a fixed point at an endpoint. If not, then it must be true that \\(g(a)&gt;a\\) and \\(g(b)&lt;b\\). This means that the function \\(h(x):=g(x)-x\\) satisfies \\[\n\\begin{aligned}\nh(a) &= g(a)-a&gt;0, & h(b)&=g(b)-b&lt;0\n\\end{aligned}\n\\tag{3.17}\\] and since \\(h\\) is continuous on \\([a,b]\\) the Intermediate Value Theorem guarantees the existence of \\(p\\in(a,b)\\) for which \\(h(p)=0\\), equivalently \\(g(p)=p\\), so that \\(p\\) is a fixed point of \\(g\\).\nTo show that the fixed point is unique, suppose that \\(q\\neq p\\) is a fixed point of \\(g\\) in \\([a,b]\\). The Mean Value Theorem implies the existence of a number \\(\\xi\\in(\\min\\{p,q\\},\\max\\{p,q\\})\\subseteq(a,b)\\) such that \\[\n\\frac{g(p)-g(q)}{p-q}=g'(\\xi).\n\\tag{3.18}\\] Then \\[\n\\begin{split}\n\\lvert p - q\\rvert &= \\lvert g(p)-g(q) \\rvert = \\lvert (p-q)g'(\\xi) \\rvert = \\lvert p-q\\rvert \\lvert g'(\\xi) \\rvert\\\\& \\le  k\\lvert p-q\\rvert &lt; \\lvert p-q\\rvert,\n\\end{split}\n\\tag{3.19}\\] where the inequalities follow from Eq. 3.14. This is a contradiction, which must have come from the assumption \\(p\\neq q\\). Thus \\(p=q\\) and the fixed point is unique.\nSince \\(g\\) maps \\([a,b]\\) onto itself, the sequence \\(\\{x_n\\}\\) is well defined. For each \\(n\\ge0\\) the Mean Value Theorem gives the existence of a \\(\\xi\\in(\\min\\{x_n,p\\},\\max\\{x_n,p\\})\\subseteq(a,b)\\) such that \\[\n\\frac{g(x_n)-g(p)}{x_n-p}=g'(\\xi).\n\\tag{3.20}\\] Thus for each \\(n\\ge1\\) by Eq. 3.14, Eq. 3.15 \\[\n\\begin{split}\n\\lvert x_n-p\\rvert &= \\lvert g(x_{n-1})-g(p) \\rvert = \\lvert (x_{n-1}-p)g'(\\xi) \\rvert \\\\\n&= \\lvert x_{n-1}-p\\rvert \\lvert g'(\\xi) \\rvert \\le  k\\lvert x_{n-1}-p\\rvert.\n\\end{split}\n\\tag{3.21}\\] Applying this inequality inductively, we obtain the error estimate Eq. 3.16. Moreover since \\(k &lt;1\\) we have \\[\n\\lim_{n\\rightarrow\\infty}\\lvert x_{n}-p\\rvert \\le \\lim_{n\\rightarrow\\infty} k^n \\lvert x_{0}-p\\rvert = 0,\n\\tag{3.22}\\] which implies that \\((x_n)\\) converges to \\(p\\).  ◻\n\nThe following example shows why the conditions of the Theorem 3.2 are important.\n\nExample 3.3 The equation \\[\nf(x)=x^{2}-2=0\n\\tag{3.23}\\] has a unique root \\(\\sqrt{2}\\) in \\([1, 2]\\). There are many ways of writing this equation in the form \\(x=g(x)\\); we consider two of them: \\[\n\\begin{aligned}\nx&=g(x)=x-(x^{2}-2), &\n  x&=h(x)=x-\\frac{x^{2}-2}{3}.\n\\end{aligned}\n\\tag{3.24}\\] Which of these fixed point problems generate a rapidly converging sequence?\nIt is easy to see that the condition of the fixed point theorem is not satisfied by the function \\(g\\) on \\([1,2]\\): Namely, \\(g(2)=0\\), so that \\(g(2)\\not\\in[1, 2]\\). On the other hand \\(h\\) satisfies the conditions because \\[\nh(x)\\in [1, 2]   \\quad \\left(\\max_{x\\in[1, 2]}h(x)=\\frac{17}{12},\n\\; \\min_{x\\in[1, 2]}h(x)=\\frac{4}{3}\\right) \\quad \\text{and} \\quad \\lvert h^{\\prime}(x)\\rvert\\leq 1/3.\n\\tag{3.25}\\] Thus, the fixed point theorem guarantees that the sequence \\((x_n)\\) produced by the fixed point iteration procedure \\(x_{n}=h(x_{n-1})\\) converges to \\(p=\\sqrt{2}\\).\n\n\n\nTable 3.3: Fixed point iteration converges quickly for \\(h\\)\n\n\n\n\n\n\\(n\\)\n\\(x_{k}=g(x_{n-1})\\)\n\\(\\vert x_n-\\sqrt{2}\\vert\\)\n\n\n\n\n0\n1.0\n0.414213562\n\n\n1\n2.0\n0.585786438\n\n\n2\n0.0\n1.414213562\n\n\n3\n2.0\n0.585786438\n\n\n4\n0.0\n1.414213562\n\n\n5\n2.0\n0.585786438\n\n\n6\n0.0\n1.414213562\n\n\n7\n2.0\n0.585786438\n\n\n8\n0.0\n1.414213562\n\n\n\n\n\n\n\\(n\\)\n\\(x_{k}=h(x_{n-1})\\)\n\\(\\vert x_n-\\sqrt{2}\\vert\\)\n\n\n\n\n0\n1.0\n0.414213562\n\n\n1\n1.333333333\n0.080880229\n\n\n2\n1.407407407\n0.006806155\n\n\n3\n1.413808871\n0.000404691\n\n\n4\n1.414190363\n0.000023199\n\n\n5\n1.414212235\n0.000001327\n\n\n6\n1.414213486\n7.6\\(\\times 10^{-8}\\)\n\n\n7\n1.414213558\n4.0\\(\\times 10^{-9}\\)\n\n\n8\n1.414213562\n0.0\n\n\n\n\n\n\nTable 3.3 shows the sequences generated by fixed point iteration on \\(g\\) and \\(h\\) with start value \\(x_0=1\\). It is apparent that the sequence generated by \\(h\\) converges quite fast, whereas the one generated by \\(g\\) does not converge at all. The example is explored further in Practical 2.\n\nThe example illustrates that one needs to be careful in rewriting root finding problems as fixed point problems—there are many ways to do so, but not all lead to a good approximation. Note at this point that Theorem 3.2 gives only sufficient conditions for convergence; in practice, convergence might occur even if the conditions are violated.\nFor implementing the fixed point method as a computer algorithm, there’s one more complication to be taken into account: how many steps of the iteration should be taken, i.e., how large should \\(n\\) be chosen, in order to reach the desired precision? For the bisection method, the error estimate Eq. 3.2 allows an easy answer. The estimate in fixed point iteration, Eq. 3.16, turns out to be more difficult to use. While we can certainly estimate \\[\n\\lvert x_{0}-p\\rvert  \\leq \\max\\{ \\lvert x_{0}-a\\rvert, \\lvert x_{0}-b\\rvert\\},\n\\tag{3.26}\\] the constant \\(k\\) (which influences the speed of convergence significantly) is often difficult to obtain in practice, since it involves estimates on the derivative of \\(g\\).\nInstead, one uses a different stopping condition for the algorithm. Since the sequence is expected to converge rapidly, one uses the difference \\(|x_n-x_{n-1}|\\) to measure the precision reached. If this difference is below a specified limit, say \\(\\tau\\), the iteration is stopped. Since it is possible that the iteration does not converge—see the example above—one would also stop the iteration (with an error message) if a certain number of steps is exceeded, in order to avoid infinite loops. Algorithm 2.2 shows all this combined in pseudocode.\n\nAlgorithm 2.2: Fixed point iteration\n\n\\[\n\\begin{array}{ll}\n\\ 1: \\ \\textbf{function} \\ FixedPoint(g,x_0,\\tau, N) &\\sharp \\ function \\ g, \\ start \\ point \\ x_0,\\\\\n\\ 2: \\ \\quad x \\gets x_0; \\ n \\gets 0               &\\sharp \\ tolerance \\ \\tau, \\ max. \\ num. \\ of \\\\\n\\ 3: \\ \\quad \\textbf{loop}                          &\\sharp \\ iterations \\ N \\\\\n\\ 4: \\ \\quad\\quad y \\gets x; \\ x \\gets g(x)  & \\\\\n\\ 5: \\ \\quad\\quad \\textbf{if} \\ |y-x| &lt; \\tau \\ \\textbf{then}  &\\sharp \\ Desired \\ tolerance \\ reached  \\\\\n\\ 6: \\ \\quad\\quad\\quad \\textbf{break}  & \\\\\n\\ 7: \\ \\quad\\quad \\textbf{end \\ if}  &  \\\\\n\\ 8: \\ \\quad\\quad \\quad n\\gets n+1  & \\\\\n\\ 9: \\ \\quad\\quad \\textbf{if} \\ n &gt; N \\ \\textbf{then}  &\\sharp \\ Max.~num. \\ of \\ iterations  \\\\\n10: \\ \\quad\\quad\\quad \\textbf{exception}(\"Iteration \\ does \\ not \\ converge\") &\\sharp \\ reached  \\\\\n11: \\ \\quad\\quad \\textbf{end if}  & \\\\\n12: \\ \\quad \\textbf{end loop}  & \\\\\n13: \\ \\quad \\textbf{return} \\ x  & \\\\\n14: \\ \\textbf{end function} &\n\\end{array}\n\\]\n\nFurther reading: Section 2.2 of (Burden and Faires 2010).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Solving nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter03.html#sec-newton1d",
    "href": "chapter03.html#sec-newton1d",
    "title": "3  Solving nonlinear equations",
    "section": "3.5 Newton’s method",
    "text": "3.5 Newton’s method\nNewton’s method is one of the most effective numerical methods for solving a root-finding problem \\(f(x)=0\\). To derive this method, we need Taylor’s theorem in its simplest form, for a real-valued function of one real variable, with the remainder in Lagrange form.\n\nTheorem 3.3 (Taylor’s Theorem in 1d) Suppose that \\(f \\in C^{k+1}(I)\\) for some \\(I\\subset\\mathbb{R}\\). For each \\(a \\in I\\) and \\(x \\in I\\), there exists \\(\\xi\\) between \\(a\\) and \\(x\\) such that \\[\nf(x) = f(a) + (x-a)f'(a)+ \\dots +\n   \\frac{(x-a)^{k}}{(k)!} f^{(k)}(a)   + \\frac{(x-a)^{k+1}}{(k+1)!}  f^{(k+1)}(\\xi).\n\\tag{3.27}\\] Here \\(f^{(k)}(a)\\) denotes the \\(k\\)th derivative of \\(f\\) at \\(x=a\\).\n\nThe idea behind Newton’s method is as follows. We assume that \\(f\\in C^{2}[a,b]\\). Let \\(p\\) be the root of \\(f(x)=0\\), and let \\(x^{*}\\) be an (initial) approximation to \\(p\\) such that \\(\\lvert x^{*}-p\\rvert\\) is small. The first-order Taylor expansion of \\(f(x)\\) about \\(x^{*}\\) is \\[\nf(x)=f(x^{*})+(x-x^{*})f^{\\prime}(x^{*})+ \\frac{(x-x^{*})^{2}}{2}\nf^{\\prime\\prime}(\\xi)\n\\tag{3.28}\\] with some \\(\\xi\\) between \\(x\\) and \\(x^*\\) (so that \\(\\xi\\in[a,b]\\)). Setting \\(x=p\\), we have \\[\n0=f(x^{*})+(p-x^{*})f^{\\prime}(x^{*})+ \\frac{(p-x^{*})^{2}}{2}\nf^{\\prime\\prime}(\\xi).\n\\tag{3.29}\\] Since \\(\\vert x^{*}-p\\vert\\) is small, we ignore the last term in this formula and obtain \\[\n0\\approx f(x^{*})+(p-x^{*})f^{\\prime}(x^{*}) \\ \\ \\ \\Rightarrow \\ \\ \\\np\\approx x^{*}-\\frac{f(x^{*})}{f^{\\prime}(x^{*})} .\n\\tag{3.30}\\] Of course, \\(p\\) computed using this formula will not be the exact root, but it is natural to expect it to be a better approximation than \\(x^{*}\\).\nLet us formulate this as an iterative algorithm. Starting with an initial approximation \\(x_{0}\\), we define a sequence of approximation values \\((x_n)\\) by \\[\nx_{n+1}:=x_{n}-\\frac{f(x_{n})}{f^{\\prime}(x_{n})} .\n\\tag{3.31}\\] Note that this is just a fixed point iteration with the function \\[\ng(x) := x - \\frac{f(x)}{f'(x)}.\n\\tag{3.32}\\] Geometrically, at the \\(n\\)th iteration, we consider the tangent to \\(f(x)\\) at \\(x=x_{n-1}\\), and finding its intersection with the \\(x\\) axis—see Figure 3.5.\n\n\n\n\n\n\nFigure 3.5: Newton’s method\n\n\n\nSo far, this was a heuristical motivation. We would like a mathematical statement that guarantees convergence of \\(\\{x_n\\}\\) to a root of the equation; this is the content of the following theorem.\n\nTheorem 3.4 Let \\(f\\in C^{2}[a, b]\\). If \\(p\\in (a, b)\\) is such that \\(f(p)=0\\) and \\(f^{\\prime}(p)\\neq 0\\), then there exists a \\(\\delta &gt;0\\) such that the sequence \\((x_n)\\) generated by Newton’s method converges to \\(p\\) for any initial approximation \\(x_{0}\\in [p-\\delta, p+\\delta]\\).\n\nThe idea of the proof is to show that for some \\(\\delta\\) the conditions of the fixed point theorem for function \\(g(x)\\) (given by Eq. 3.32) are satisfied. The proof can be found in the book by (Burden and Faires 2010).\nWe did not give an explicit error estimate, but it will turn out later that Newton’s method, under suitable conditions, converges even much faster than a general fixed point method.\nUnfortunately, the conditions of the above theorem are such that it is hard to predict in concrete examples whether Newton’s method will produce a converging sequence for a given initial approximation. Sometimes, a combination of the bisection method and Newton’s method is used in practice: the first method is employed to obtain a sufficiently good initial approximation for the second one, which then produces a fast and precise approximation.\n\nExample 3.4 For \\(f(x)=x^{2}-2\\), \\(x\\in (0,\\infty)\\), equation Eq. 3.32 yields the function \\[\ng(x)=x-\\frac{f(x) }{ f^{\\prime}(x)}=x-\\frac{x^{2}-2}{2x}=\\frac{x}{2}+\\frac{1}{x}.\n\\tag{3.33}\\] The sequence generated by the formula \\(x_{n}=\\frac{x_{n-1}}{2}+\\frac{1}{x_{n-1}}\\) (\\(n\\geq 1\\)) converges to the root \\(\\sqrt{2}\\) of the equation \\(f(x)=0\\) for any choice of \\(x_0\\in (0, \\infty)\\) (prove it!). Calculations yield the values in Table 3.4, which shows a very fast convergence. (Compare this with the result of fixed point iteration in Table 3.3.)\n\n\n\nTable 3.4: Numerical example for Newton’s method\n\n\n\n\n\n\\(n\\)\n\\(x_n=g(x_{n-1})\\)\n\\(\\vert x_n-\\sqrt{2}\\vert\\)\n\n\n\n\n0\n1.0\n0.414213562\n\n\n1\n1.500000000\n0.085786438\n\n\n2\n1.416666667\n0.002453105\n\n\n3\n1.414215686\n0.000002124\n\n\n4\n1.414213562\n0.0\n\n\n5\n1.414213562\n0.0\n\n\n\n\n\n\n\nLet us write down the algorithm as a pseudocode. Since Newton’s method is a special case of fixed point iteration, this just follows Algorithm  2.2 line by line, with the same stopping conditions. For the sake of completeness, it is shown in Algorithm 2.3.\n\nAlgorithm 2.3: Newton’s method\n\n\\[\n\\begin{array}{ll}\n\\ 1: \\ \\textbf{function} \\ NewtonMethod(f,f',x_0,\\tau, N) &\\sharp \\ function \\ f, \\ its \\ derivative \\ f', \\\\\n\\ 2: \\ \\quad x \\gets x_0; \\ n \\gets 0               &\\sharp \\ start \\ point \\ x_0, \\ tolerance \\ \\tau, \\\\\n\\ 3: \\ \\quad \\textbf{loop}                          &\\sharp \\ max. \\ num. \\ of  \\ iterations \\ N \\\\\n\\ 4: \\ \\quad\\quad v \\gets f(x)/f'(x); \\ y \\gets x-v  & \\\\\n\\ 5: \\ \\quad\\quad \\textbf{if} \\ |y-x| &lt; \\tau \\ \\textbf{then}  &\\sharp \\ Desired \\ tolerance \\ reached  \\\\\n\\ 6: \\ \\quad\\quad\\quad \\textbf{break}  & \\\\\n\\ 7: \\ \\quad\\quad \\textbf{end \\ if}  &  \\\\\n\\ 8: \\ \\quad\\quad \\quad n\\gets n+1; \\ x \\gets y  & \\\\\n\\ 9: \\ \\quad\\quad \\textbf{if} \\ n &gt; N \\ \\textbf{then}  &\\sharp \\ Max.~num. \\ of \\ iterations  \\\\\n10: \\ \\quad\\quad\\quad \\textbf{exception}(``Iteration \\ does \\ not \\ converge'') &\\sharp \\ reached  \\\\\n11: \\ \\quad\\quad \\textbf{end if}  & \\\\\n12: \\ \\quad \\textbf{end loop}  & \\\\\n13: \\ \\quad \\textbf{return} \\ y  & \\\\\n14: \\ \\textbf{end function} &\n\\end{array}\n\\]\n\nAs a final remark, let us mention that Newton’s method works just the same for analytic function on \\(\\mathbb{C}\\), rather than real-valued functions on \\(\\mathbb{R}\\). The definition of the approximating sequence is identical to Eq. 3.31, where subtraction and division are now read in terms of complex numbers. We will not go into detail here, but you will investigate an example in Practical A3.\nFurther reading: Section 2.3 of (Burden and Faires 2010).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Solving nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter03.html#secant-method",
    "href": "chapter03.html#secant-method",
    "title": "3  Solving nonlinear equations",
    "section": "3.6 Secant method",
    "text": "3.6 Secant method\nWhile Newton’s method is often convenient, one problem is that it requires explicit knowledge of the derivative of \\(f\\). In practice, this may not always be available; e.g., when the function \\(f\\) itself is approximated by a piece of computer code. In this situation, one can use a slightly different method, called the secant method.\nThe idea here is to replace the derivative with a finite difference quotient. By definition of the derivative, we have \\[\nf^{\\prime}(x_{n})=\\lim_{x\\to x_{n}} \\frac{f(x)-f(x_{n})}{x-x_{n}}.\n\\tag{3.34}\\] Replacing \\(x\\) by \\(x_{n-1}\\), we obtain \\[\nf^{\\prime}(x_{n})\\approx \\frac{f(x_{n-1})-f(x_{n})}{x_{n-1}-x_{n}}.\n\\tag{3.35}\\] Using this approximation, the definition Eq. 3.31 of the approximating sequence is replaced by \\[\nx_{n+1} := x_{n}- \\frac{f(x_{n})(x_{n}-x_{n-1})}{f(x_{n})-f(x_{n-1})}.\n\\tag{3.36}\\] This defines the secant method. In geometrical terms, we have replaced the tangent used in Newton’s method (Figure 3.5) by a secant (Figure 3.6).\n\n\n\n\n\n\nFigure 3.6: Secant method\n\n\n\nNote that the secant method is not an example of fixed point iteration as discussed in Section 3.4, since the expression for \\(x_{n+1}\\) in equation Eq. 3.36 involves both \\(x_n\\) and \\(x_{n-1}\\). For the same reason, the method requires two initial approximations, \\(x_{0}\\) and \\(x_{1}\\).\n\nExample 3.5 Applying the secant method to the same example \\(f(x)=x^2-2\\) with \\(x_{0}=1\\) and \\(x_{1}=1.1\\), we obtain the data in Table 3.5. We see that the convergence of the method is quite fast, although slower than the convergence of the Newton method applied to the same problem.\n\n\n\nTable 3.5: Numerical example for secant method\n\n\n\n\n\n\\(n\\)\n\\(x_n\\)\n\\(\\vert x_n-\\sqrt{2}\\vert\\)\n\n\n\n\n0\n1.0\n0.414213562\n\n\n1\n1.1\n0.314213562\n\n\n2\n1.476190476\n0.061976914\n\n\n3\n1.406654344\n0.007559218\n\n\n4\n1.414051050\n0.000162512\n\n\n5\n1.414213998\n4.36\\(\\times 10^{-7}\\)\n\n\n6\n1.414213562\n0.0\n\n\n7\n1.414213562\n0.0\n\n\n\n\n\n\n\nFurther reading: Section 2.3 of (Burden and Faires 2010).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Solving nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter03.html#order-of-convergence",
    "href": "chapter03.html#order-of-convergence",
    "title": "3  Solving nonlinear equations",
    "section": "3.7 Order of convergence",
    "text": "3.7 Order of convergence\n\n3.7.1 Definition\n\nDefinition 3.1 Suppose that \\(x_{n}\\to p\\) as \\(n\\to\\infty\\) and \\(x_n\\neq p\\) for all \\(n\\). The sequence \\(\\{x_{n}\\}\\) is said to have order of convergence \\(\\alpha \\ge 1\\) if there exists a constant \\(\\lambda &gt;0\\) such that \\[\n\\lim_{n\\to\\infty}\\frac{E_{n+1}}{E_{n}^{\\alpha}}=\\lambda .\n\\tag{3.37}\\] Here \\(E_n\\) denotes the absolute error in the \\(n\\)th approximation: \\(E_{n}=\\vert x_{n}-p\\vert\\).\n\nIf \\(\\alpha=1,2,3,\\dots\\), the convergence is said to be linear, quadratic, cubic, \\(\\dots\\), respectively. Note that if the convergence is linear, then the positive constant \\(\\lambda\\) that appears in the above definition must be smaller than 1 (\\(0&lt;\\lambda&lt;1\\)), because otherwise the sequence will not converge.\nA sequence with a higher order of convergence converges much more rapidly than a sequence with a lower order of convergence. To see this, let us consider the following example:\n\nExample 3.6 Let \\(\\{x_{n}\\}\\) and \\(\\{y_{n}\\}\\) be sequences converging to zero and let, for \\(n\\geq 0\\), \\[\n\\vert x_{n+1}\\vert = k \\vert x_{n}\\vert \\quad \\text{  and  } \\quad\n\\vert y_{n+1}\\vert = k \\vert y_{n}\\vert^{2},\n\\tag{3.38}\\] where \\(0&lt; k &lt; 1\\). According to the definition, \\(\\{x_{n}\\}\\) is linearly convergent and \\(\\{y_{n}\\}\\) is quadratically convergent.\nAlso, we have \\[\n\\begin{split}\n\\vert x_{n}\\vert&=k\\vert x_{n-1}\\vert=\nk^{2}\\vert x_{n-2}\\vert=...=k^{n}\\vert x_{0}\\vert ,\\\\\n\\vert y_{n}\\vert&=k\\vert y_{n-1}\\vert^{2}=\nk\\vert k\\vert y_{n-2}\\vert^{2}\\vert^{2}=k^{3}\\vert y_{n-2}\\vert^{4}=\nk^{7}\\vert y_{n-3}\\vert^{8}=...\n=k^{2^{n}-1}\\vert y_{0}\\vert^{2^{n}}.\n\\end{split}\n\\tag{3.39}\\] This illustrates that the quadratic convergence is much faster that the linear convergence.\n\n\n\n3.7.2 Order of convergence for the Fixed Point Iteration\nSuppose that \\(g(x)\\) satisfies the conditions of the Fixed Point Theorem on interval \\([a,b]\\), so that the sequence \\(\\{x_{n}\\}\\) generated by the formula \\(x_{n+1}=g(x_{n})\\) with \\(x_{0}\\in [a,b]\\) converges to a fixed point \\(p\\). Then, using the Mean Value Theorem, we obtain \\[\n\\begin{split}\nE_{n+1}&=\\vert x_{n+1}-p\\vert=\\vert g(x_{n})-g(p)\\vert\\\\\n&=\\vert g'(\\xi)( x_{n}-p)\\vert = E_{n}\\vert g'(\\xi_{n})\\vert,\n\\end{split}\n\\tag{3.40}\\] where \\(\\xi_{n}\\) is a number between \\(x_n\\) and \\(p\\). This implies that if \\(x_n\\to p\\), then \\(\\xi_n\\to p\\) as \\(n\\to\\infty\\). Therefore, \\[\n\\lim_{n\\to\\infty}\\frac{E_{n+1}}{E_{n}}=\\vert g'(p)\\vert .\n\\tag{3.41}\\] In general, \\(g'(p)\\neq 0\\), so that the fixed point iteration produces a linearly convergent sequence.\nCan the fixed-point iteration produce convergent sequences with convergence of order 2, 3, etc. ? It turns out that, under certain conditions, this is possible.\nWe will prove the following\n\nTheorem 3.5 Let \\(m &gt; 1\\) be an integer, and let \\(g\\in C^{m}[a,b]\\). Suppose that \\(p\\in [a,b]\\) is a fixed point of \\(g\\), and a point \\(x_{0}\\in [a,b]\\) exists such that the sequence generated by the formula \\(x_{n+1}=g(x_{n})\\) converges to \\(p\\). If \\(g'(p)=\\dots =g^{(m-1)}(p)=0\\), then \\(\\{x_{n}\\}\\) has the order of convergence \\(m\\).\n\n\nProof. Expanding \\(g(x_{n})\\) in Taylor’s series at point \\(p\\), we obtain: \\[\n\\begin{split}\nx_{n+1}=g(x_{n}) &= g(p) + (x_{n}-p)g'(p)+\\dots  \\\\\n&\\qquad + \\frac{(x_{n}-p)^{m -1}}{(m -1)!}g^{(m -1)}(p)\\\\\n&\\qquad + \\frac{(x_{n}-p)^{m}}{m!}g^{(m)}(\\xi_n) \\\\\n&=p+\\frac{(x_{n}-p)^{m}}{(m)!}g^{(m)}(\\xi_n),\n\\end{split}\n\\tag{3.42}\\] where \\(\\xi_n\\) is between \\(x_{n}\\) and \\(p\\) and, therefore, in \\([a,b]\\) (\\(x_{n}\\in[a,b]\\) at least for sufficiently large \\(n\\)). Then we have \\[\n\\begin{split}\nE_{n+1}&=\\vert x_{n+1}-p\\vert=\\vert g(x_{n})-p\\vert= \\left\\vert\\frac{(x_{n}-p)^{m}}{(m)!}g^{(m)}(\\xi_n)\\right\\vert\\\\\n&= E_{n}^m \\frac{\\vert g^{(m)}(\\xi_n)\\vert}{m!}.\n\\end{split}\n\\tag{3.43}\\] Therefore (using the fact that \\(\\xi_n\\to p\\)), \\[\n\\lim_{n\\to\\infty}\\frac{E_{n+1}}{E_{n}^m}= \\frac{\\vert g^{(m)}(p)\\vert}{m!} ,\n\\tag{3.44}\\] which means that \\(\\{x_{n}\\}\\) has convergence of order \\(m\\).\n\n\n\n3.7.3 Order of convergence of Newton’s method\nNewton’s method for approximating the root \\(p\\) of the equation \\(f(x)=0\\) is equivalent to the fixed-point iteration \\(x_{n+1}=g(x_{n})\\) with \\[\ng(x)=x-\\frac{f(x)}{f'(x)}.\n\\tag{3.45}\\] Suppose that sequence \\(\\{x_{n}\\}\\) converges to \\(p\\) and \\(f'(p)\\neq 0\\). We have \\[\ng'(x)=\\frac{f(x)f''(x)}{[f'(x)]^2} \\quad \\Rightarrow \\quad g'(p)=\\frac{f(p)f''(p)}{[f'(p)]^2}=0 .\n\\tag{3.46}\\] It follows from the above theorem that the order of convergence of Newton’s method is 2 (except in the special case where \\(g''(p)=0\\)).\n\n\n3.7.4 Order of convergence of the secant method\nThe situation with the secant method is more complicated (since it cannot be reduced to the fixed point iteration) and requires a separate treatment. The result is that the secant method has order of convergence \\(\\alpha=\\frac{1+\\sqrt{5}}{2}\\approx 1.618\\).\nNote that \\(\\alpha\\) is known as the golden ratio. If you are intrigued to see the golden ratio appear in this context, you can find a proof below. If you are happy to just accept the miracle, you can skip the proof and go on to the Exercises.\nSuppose that a sequence \\(\\{x_{n}\\}\\), generated by the secant method \\[\nx_{n+1}=x_{n}- \\frac{f(x_{n})(x_{n}-x_{n-1})}{f(x_{n})-f(x_{n-1})},\n\\tag{3.47}\\] converges to \\(p\\). Let \\[\ne_{n}=x_{n}-p,\n\\tag{3.48}\\] so that \\(E_n=\\vert e_n\\vert\\), and we assume that \\(E_n \\ll 1\\), which is definitely true for sufficiently large \\(n\\) (since the sequence \\(\\{x_n\\}\\) is converging to \\(p\\)). Subtracting \\(p\\) from both sides of Eq. 3.47, we obtain \\[\ne_{n+1}=e_{n}- \\frac{f(p+e_{n})(e_{n}-e_{n-1})}{f(p+e_{n})-f(p+e_{n-1})},\n\\tag{3.49}\\] Expanding \\(f(p+e_{n})\\) and \\(f(p+e_{n-1})\\) in Taylor series about \\(p\\) and taking into account that \\(f(p)=0\\), we find that \\[\n\\begin{split}\nf(p+e_{n})&=e_{n}f^{\\prime}(p)+\n\\frac{e_{n}^{2}}{2}f^{\\prime\\prime}(p)+ \\cdots \\\\\n&=e_{n}f^{\\prime}(p)(1+e_{n}Q)+ \\cdots,\\\\\nf(p+e_{n-1})&=e_{n-1}f^{\\prime}(p)+\n\\frac{e_{n-1}^{2}}{2}f^{\\prime\\prime}(p)+ \\cdots  \\\\\n&=e_{n-1}f^{\\prime}(p)(1+e_{n-1}Q)+ \\cdots,\n\\end{split}\n\\tag{3.50}\\] where \\[\nQ=\\frac{f^{\\prime\\prime}(p)}{2f^{\\prime}(p)}.\n\\tag{3.51}\\] Substitution of Eq. 3.50 into Eq. 3.49 yields \\[\n\\begin{split}\ne_{n+1}&=e_{n}- \\frac{e_{n}(e_{n}-e_{n-1})f^{\\prime}(p)(1+e_{n}Q)+\\cdots}{f^{\\prime}(p)\n\\left[e_{n}-e_{n-1}+Q(e_{n}^2-e_{n-1}^2)+\\cdots\\right]} \\\\\n&=e_{n}\\left(1-\\frac{1+e_{n}Q+\\cdots}{1+Q(e_{n}+e_{n-1})+\\cdots}\\right).\n\\end{split}\n\\tag{3.52}\\] Since, for small \\(x\\), \\[\n\\frac{1}{1+x+\\cdots}= 1-x+\\cdots ,\n\\tag{3.53}\\] we obtain \\[\n\\begin{split}\ne_{n+1}&=e_{n}\\left(1-\\left(1+e_{n}Q+\\cdots\\right)\\left(1-Q(e_{n}+e_{n-1})+\\cdots\\right)\\right)\\\\\n&=Q e_{n}e_{n-1}+\\cdots.\n\\end{split}\n\\tag{3.54}\\] Thus, for sufficiently large \\(n\\), we have \\[\ne_{n+1} \\approx Q e_{n}e_{n-1}.\n\\tag{3.55}\\] Hence, \\[\nE_{n+1} \\approx \\vert Q\\vert \\, E_{n}E_{n-1}.\n\\tag{3.56}\\] Now we assume that (for all sufficiently large \\(n\\)) \\[\nE_{n+1} \\approx \\lambda E_{n}^{\\alpha},\n\\tag{3.57}\\] where \\(\\lambda\\) and \\(\\alpha\\) are positive constants. Substituting Eq. 3.57 into Eq. 3.56, we find \\[\n\\lambda E_{n}^{\\alpha} \\approx \\vert Q\\vert E_{n}E_{n-1} \\quad \\text{  or } \\quad\n\\lambda E_{n}^{\\alpha-1} \\approx \\vert Q\\vert E_{n-1}.\n\\tag{3.58}\\] Applying Eq. 3.57 one more time (with \\(n\\) replaced by \\(n-1\\)), we obtain \\[\n\\lambda \\left(\\lambda E_{n-1}^{\\alpha}\\right)^{\\alpha-1} \\approx \\vert Q\\vert E_{n-1}\n\\tag{3.59}\\] or, equivalently, \\[\n\\lambda^{\\alpha} E_{n-1}^{\\alpha(\\alpha-1)} \\approx \\vert Q\\vert E_{n-1}.\n\\tag{3.60}\\] The last equation will be satisfied provided that \\[\n\\lambda^{\\alpha}=\\vert Q\\vert, \\quad \\alpha(\\alpha-1)=1 ,\n\\tag{3.61}\\] which requires that \\[\n\\lambda=\\vert Q\\vert^{1/\\alpha}, \\quad \\alpha=(1+\\sqrt{5})/2\\approx 1.62.\n\\tag{3.62}\\] Thus, we have shown that if \\(\\{x_{n}\\}\\) is a convergent sequence generated by the secant method, then \\[\n\\lim_{n\\to\\infty}\\frac{E_{n+1}}{E_{n}^{\\alpha}}=\\vert Q\\vert^{1/\\alpha}.\n\\tag{3.63}\\] Thus, the secant method has superlinear convergence.\nFurther reading: Section 2.4 of (Burden and Faires 2010).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Solving nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter03.html#exercises",
    "href": "chapter03.html#exercises",
    "title": "3  Solving nonlinear equations",
    "section": "3.8 Exercises",
    "text": "3.8 Exercises\n\n3.8.1 Written exercises\n\nExercise 3.1 Consider the bisection method for finding the zero of \\[\n  f(x) = \\sqrt{x} - \\cos{x}\n\\tag{3.64}\\] on \\(x\\in[0,1]\\)\n\nUsing the starting values of \\(a=0.5\\) and \\(b=1.0\\), calculate the first 5 steps of the bisection method.\nHow many steps of the bisection method would be need to ensure that the root is accurate to 10 significant figures?\nShow that the bisection method gives a sequence \\(x_n\\) with an error that converges linearly to zero. Does that imply that the bisection method converges linearly?\n\n\n\nExercise 3.2 Consider the fixed point iteration \\[\n  x_{n+1} = \\frac{x^3_n+3ax_n}{3x^2_n+a},\n\\tag{3.65}\\] where \\(a&gt;0\\) is given.\n\nWhat does this fixed point iteration approximate?\nUse the scheme to calculate \\(\\sqrt{23}\\) correct to 10 significant digits.\n\n\n\nExercise 3.3 Consider the problem of finding a numerical approximation to \\(\\sqrt{3}\\) using the fixed point iteration method with the function \\[\n  g(x)= x + \\lambda P(x) (x^2 - 3)\n\\tag{3.66}\\] where \\(P(x)\\) is a general polynomial of degree \\(m\\).\nFor the case \\(P(x) = 1\\) and \\(\\lambda = -1/4\\), \\(g(x)\\) satisfies the fixed point theorem on the domain \\([1,2]\\), i.e. \\[\n  g:[1,2] \\to [1,2]\n\\tag{3.67}\\] with \\[\n  |g'(x)| &lt; k, 0 &lt; k &lt; 1, x \\in [1,2].\n\\tag{3.68}\\]\n\nFor \\(P(x) = 1\\) and \\(\\lambda = -1/4\\), show that the sequence \\(\\{x_n\\}\\) defined by \\(x_{n+1}=g(x_n)\\) converges linearly to \\(\\sqrt{3}\\).\nShow that \\(g(x)\\) also satisfies the fixed point theorem on the domain \\([1,2]\\) for the case \\(P(x) = x(x^2-5)\\) and \\(\\lambda = +1/12\\), and thus there exists a unique fixed point defined by \\(x_{n+1}=g(x_n)\\).\nGiven a starting value of \\(x_0 = 1\\), calculate the number \\(n\\) of iterations required to achieve an absolute error of \\(E_n = 10^{-8}\\) for the cases (i) \\(P(x) = 1\\), \\(\\lambda = -1/4\\) and (ii) \\(P(x) = x(x^2 - 5)\\), \\(\\lambda = +1/12\\).\n\n\n\nExercise 3.4 Find the small root of \\[\nx^2-10^4 x + 2 = 0\n\\tag{3.69}\\] to at least 17 significant figures, writing out all steps of your calculation.\n\n\n\n3.8.2 Programming exercises\n\nExercise 3.5 In many physics and engineering applications, the Bessel functions \\(J_n(x)\\) are the radial solutions to the Laplacian operator in cylindrical coordinates, i.e. \\(\\nabla^2 f(r,\\theta,z) = 0\\). Applying boundary conditions to the problem usually results in the need to compute the roots of \\(J_n(x)\\). Here we will use the Bisection Method to identify roots of \\(J_n(x)\\) using the following generalized formula \\[\nJ_n(x) = \\left(\\frac{x}{2}\\right)^n \\sum^\\infty_{k=0} \\frac{(-1)^k x^{2k}}{k!(n+k)! 4^k}.\n\\tag{3.70}\\]\n\nThe c++ code bessel_root.c (or FORTRAN code bessel_root.f90) is set up to compute roots of the Bessel function \\(J_0(x)\\). It takes input from the user for the two points \\(a\\) and \\(b\\) that bracket the root and the maximum error \\(\\epsilon\\) to compute the root to. Alter the code and compute the first three positive roots for \\(J_1(x)\\) to an accuracy of \\(\\epsilon=1.0\\times 10^{-5}\\).\nYou may have noticed when applying the code that unless you choose the initial points \\(a\\) and \\(b\\) to bracket at least one root, the method does not converge. Alter the code to use the **Secant Method*, which does not require the root to be bracketed. Code for the Secant method is provided by secant.c (secant.f90).\nFor mathematical thought - i.e. there is no “right answer”. Instead of using the secant method, we could use Newton’s method here. What is a potential downside to using Newtons method in this application?\n\n\n\nExercise 3.6 Consider the problem of finding the root to the function \\[\nf(x) = \\exp(x) - 10 x^2\n\\tag{3.71}\\]\n\nThe C++ code newton_root.c (or FORTRAN code newton_root.f90) is set up to compute roots of this function using Newton’s method that we learned in lecture. It takes input from the user on an initial guess for the root \\(a\\) and the maximum error \\(\\epsilon\\) to compute the root to. Find three roots of the function.\nTry using a starting value of \\(a=3.5\\). Why does the method converge to the negative root instead of the two positive roots which are closer?\nAlter the code and compute the roots for the function \\(f(x) = x^3 - 1\\) to an accuracy of \\(\\epsilon=1.0\\times 10^{-5}\\). Does the code always converge to the same root?\n Alter the code so that it can identify any real or complex root of the function \\(f(z) = z^3 - 1\\).\n\n\n\nExercise 3.7 Consider the surface that is described by the cylindrical shape of length \\(L\\) and radius given by the general function \\(s(z)\\)\n\n\n\n\n\n\nFigure 3.7: A cylinder of length \\(L\\) with surface generated by the radius function \\(s(z)\\)\n\n\n\nThe surface area of this cylinder is given by: \\[\nA = 2\\pi \\int_0^L s(z) \\sqrt{1 + s'(z)^2} dz.\n\\tag{3.72}\\] We wish to identify the radial function \\(s(z)\\) that minimizes the surface area of the cylinder.\n\nUse the Euler-Lagrange equations to find the ODE for \\(s(z)\\) that minimizes the area.\nVerify that \\[\n  s(z) = \\alpha \\cosh\\left( \\frac{z-\\beta}{\\alpha}\\right)\n\\tag{3.73}\\] is a solution to the ODE.\nApply the boundary conditions \\(s(0) = s(L) = R\\) to the solution in part (b). Use the two equations that you get from the boundary conditions to obtain a single equation in terms of \\(R,L\\) and a single unknown \\(\\alpha\\).\nAssuming \\(R\\) and \\(L\\) are known, choose an appropriate root finding technique (bisection,secant, or Newton) and create a root finding code that solves for the unknown \\(\\alpha\\). Using \\(R=5.0\\) and \\(L=6.0\\), identify the solution (or solutions) \\(\\alpha\\). Plot the resulting function \\(s(z)\\) that minimizes the surface area of the cylinder.\n\n\n\n\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical Analysis. 9th ed. Brooks Cole.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Solving nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter04.html",
    "href": "chapter04.html",
    "title": "4  Solving systems of nonlinear equations",
    "section": "",
    "text": "4.1 Defining the problem\nSo far, we considered the root of one equation in one variable \\(x\\). In applications, one often meets systems of several equations in several variables.\nLet \\(\\mathbf{f}: \\mathbb{R}^m \\to \\mathbb{R}^m\\) be given. The root finding problem is that of finding the solution \\(\\mathbf{x}\\in\\mathbb{R}^m\\) such that \\[\n\\mathbf{f}(\\mathbf{x})=\\mathbf{0} \\ \\ \\hbox{or} \\ \\\n  \\left\\{\n  \\begin{array}{l}\n  f_{1}(x_{1},\\dots,x_{m})=0 \\\\\n  f_{2}(x_{1},\\dots,x_{m})=0 \\\\\n  \\vdots                     \\\\\n  f_{m}(x_{1},\\dots,x_{m})=0\n  \\end{array}\n\\right.\n\\tag{4.1}\\] This is a system of \\(m\\) (linear or nonlinear) equations for \\(m\\) unknowns \\(x_1,\\dots,x_m\\).\nAs in the example above, the solutions of a system with \\(m\\) equations and \\(m\\) variables are typically (though not always) discrete points; and there can be more than one solution. In this simple example, one can find the intersection points of the curves explicitly (try it!), and therefore compute the solutions of the system. In general, however, this will not be possible, and we will need approximation methods.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Solving systems of nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter04.html#defining-the-problem",
    "href": "chapter04.html#defining-the-problem",
    "title": "4  Solving systems of nonlinear equations",
    "section": "",
    "text": "Example 4.1 Let \\(m=2\\) and \\[\n\\mathbf{f}(\\mathbf{x})=\n  \\begin{pmatrix}\n  f_1(x_1,x_2) \\\\\n  f_2(x_1,x_2)\n  \\end{pmatrix}\n= \\begin{pmatrix}\n  x_1^2 + x_2^2 -1 \\\\\n  x_2 - x_1^2\n\\end{pmatrix}.\n\\tag{4.2}\\] Then we have the system of two equations \\[\n\\left\\{\n  \\begin{array}{l}\n  x_1^2 + x_2^2 -1=0 \\\\\n  x_2 - x_1^2=0\n  \\end{array}\n\\right..\n\\tag{4.3}\\] This system has a simple geometrical interpretation (see Figure 4.1).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Make a 2d plot of the two equations\nx1 = np.linspace(-2, 2, 100)\nx2 = np.linspace(-2, 2, 100)\nX1, X2 = np.meshgrid(x1, x2)\nF1 = X1**2 + X2**2 - 1\nF2 = X2 - X1**2\nplt.contour(X1, X2, F1, [0], colors='r')\nplt.contour(X1, X2, F2, [0], colors='b')\nplt.xlabel('$x_1$')\nplt.ylabel('$x_2$')\nplt.gca().set_aspect('equal', adjustable='box')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4.1: The two equations \\(x_1^2 + x_2^2 -1=0\\) and \\(x_2 - x_1^2=0\\). The solutions of this system are the intersection points of the parabola with the circle.\n\n\n\n\n\nPoints \\((x_1,x_2)\\) satisfying the first equation lie on the unit circle, while the second equation gives us the parabola. The solution of this system is represented by the two intersection points of the parabola with the circle in Figure 4.1.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Solving systems of nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter04.html#vector-and-matrix-norms",
    "href": "chapter04.html#vector-and-matrix-norms",
    "title": "4  Solving systems of nonlinear equations",
    "section": "4.2 Vector and matrix norms",
    "text": "4.2 Vector and matrix norms\n\nDefinition 4.1 (Norm of a vector) A function \\(\\Vert\\, \\cdot\\, \\Vert : \\mathbb{R}^m \\to \\mathbb{R}\\) is a vector norm if it has the following properties:\n(i)) \\(\\Vert\\mathbf{x}\\Vert \\geq 0\\) for all \\(\\mathbf{x}\\in\\mathbb{R}^{m}\\) and \\(\\Vert\\mathbf{x}\\Vert = 0\\) \\(\\Leftrightarrow\\) \\(\\mathbf{x}=0\\) (i.e. \\(\\mathbf{x}=(0, 0, ... , 0)^{t}\\)),\n\n\\(\\Vert\\alpha\\mathbf{x}\\Vert = \\vert\\alpha\\vert\\cdot\\Vert\\mathbf{x}\\Vert\\) for all \\(\\alpha\\in\\mathbb{R}\\) and \\(\\mathbf{x}\\in\\mathbb{R}^{m}\\),\n\\(\\Vert\\mathbf{x}+\\mathbf{y} \\Vert \\leq \\Vert\\mathbf{x}\\Vert + \\Vert\\mathbf{y}\\Vert\\) for all \\(\\mathbf{x}, \\mathbf{y}\\in\\mathbb{R}^{m}\\) (the triangle inequality).\n\n\n\nExample 4.2 The \\(l_{2}\\) and \\(l_{\\infty}\\) norms of the vector \\(\\mathbf{x}=(x_{1}, x_{2}, ..., x_{m})^{t}\\) are defined by \\[\n\\Vert\\mathbf{x}\\Vert_{2}=\\left(\\sum_{i=1}^{m}x_{i}^{2}\\right)^{1/2}\n\\ \\ \\ \\text{  and } \\ \\ \\\n\\Vert\\mathbf{x}\\Vert_{\\infty}=\\max_{1\\leq i \\leq m}\\vert x_{i}\\vert .\n\\tag{4.4}\\] The \\(l_{2}\\) norm is called the Euclidean norm of the vector \\(\\mathbf{x}\\). It represents the notion of distance from the origin to the point \\(\\mathbf{x}\\) (the length of the straight line joining the points \\(0\\) and \\(\\mathbf{x}\\)).\n\n\nDefinition 4.2 The distance between any two points \\(\\mathbf{x}\\in \\mathbb{R}^{m}\\) and \\(\\mathbf{y}\\in \\mathbb{R}^{m}\\) is defined as the norm of the difference of the vectors: \\(\\Vert \\mathbf{x}-\\mathbf{y}\\Vert\\).\n\n\nDefinition 4.3 A sequence \\(\\{\\mathbf{x}^{(k)}\\}\\) of vectors in \\(\\mathbb{R}^{m}\\) converges to \\(\\mathbf{x}\\) with respect to the norm \\(\\Vert \\, \\cdot \\, \\Vert\\) if for any \\(\\epsilon &gt;0\\), there exists an integer \\(N(\\epsilon)\\) such that \\[\n\\Vert \\mathbf{x}^{(k)}-\\mathbf{x}\\Vert &lt;\\epsilon \\ \\ \\ \\ \\text{  for \\ all } \\ \\ \\\nk &gt; N(\\epsilon).\n\\tag{4.5}\\] In other words, \\(\\mathbf{x}^{(k)}\\to \\mathbf{x}\\) as \\(k\\to\\infty\\) if \\(\\Vert \\mathbf{x}^{(k)}-\\mathbf{x}\\Vert\\to 0\\) as \\(k\\to\\infty\\). \n\n\nRemark. It can be shown that all norms on \\(\\mathbb{R}^{m}\\) are equivalent with respect to convergence. This means that if \\(\\Vert \\, \\cdot \\, \\Vert\\) and \\(\\Vert \\, \\cdot \\, \\Vert^{\\prime}\\) are two norms on \\(\\mathbb{R}^{m}\\) and \\(\\{\\mathbf{x}^{(k)}\\}\\) converges to \\(\\mathbf{x}\\) with respect to the norm \\(\\Vert \\, \\cdot \\, \\Vert\\), then \\(\\{\\mathbf{x}^{(k)}\\}\\) also converges to \\(\\mathbf{x}\\) with respect to the norm \\(\\Vert \\, \\cdot \\, \\Vert^{\\prime}\\). (Proof of this fact for the case of \\(l_{2}\\) and \\(l_{\\infty}\\) norms follows from the inequality \\(\\Vert \\mathbf{x}\\Vert_{\\infty}\\leq \\Vert \\mathbf{x}\\Vert_{2}\\leq \\sqrt{m}\\Vert \\mathbf{x}\\Vert_{\\infty}\\) which is valid for all \\(\\mathbf{x}\\in \\mathbb{R}^{m}\\).)\n\nLet \\({\\cal M}(m,m)\\) be the space of all \\(m\\times m\\) real matrices.\n\nDefinition 4.4 (Norm of a matrix) A function \\(\\Vert \\, \\cdot \\, \\Vert: {\\cal M}(m,m) \\to \\mathbb{R}\\) is a matrix norm if it has the following properties:\n\n\\(\\Vert A \\Vert \\geq 0\\) and \\(\\Vert A \\Vert = 0\\) \\(\\Leftrightarrow\\) \\(A=O\\) (where \\(O\\) is the matrix with all zero entries),\n\\(\\Vert\\alpha A \\Vert = \\vert\\alpha\\vert\\cdot\\Vert A \\Vert\\),\n\\(\\Vert A+B \\Vert \\leq \\Vert A \\Vert + \\Vert B\\Vert\\) (the triangle inequality),\n\\(\\Vert AB \\Vert \\leq \\Vert A \\Vert \\cdot \\Vert B\\Vert\\).\n\nwhere \\(A\\) and \\(B\\) are any \\(m\\times m\\) real matrices, and \\(\\alpha\\) is any real number.\nA distance between matrices \\(A\\) and \\(B\\) (with respect to this matrix norm) is \\(\\Vert A-B \\Vert\\).\n\n\nDefinition 4.5 (Natural, or induced, matrix norm) If \\(\\Vert \\, \\cdot \\, \\Vert\\) is a vector norm on \\(\\mathbb{R}^{m}\\), then \\[\n\\Vert A \\Vert=\\max_{\\Vert\\mathbf{x}\\Vert =1}\\Vert A\\mathbf{x}\\Vert\n\\tag{4.6}\\] is a matrix norm (called natural, or induced, matrix norm associated with the vector norm).\n\nIn what follows we shall consider only \\(l_{\\infty}\\) matrix norms: \\[\n\\Vert A \\Vert_{\\infty}=\\max_{\\Vert\\mathbf{x}\\Vert_{\\infty} =1}\\Vert A\\mathbf{x}\\Vert_{\\infty}.\n\\tag{4.7}\\]\n\nTheorem 4.1 For any \\(m\\times m\\) matrix \\(A=(a_{ij})\\), \\[\n\\Vert A \\Vert_{\\infty}=\\max_{1\\leq i\\leq m}\\left\\{\\sum_{j=1}^{m}\n\\vert a_{ij}\\vert\\right\\}.\n\\tag{4.8}\\]\n\n\nExample 4.3 Let \\[\nA=\\left[\n\\begin{array}{cccc}\n1 &2 &0 &-1 \\\\\n1 &3 &2 &0 \\\\\n0 &-2 &3 &2 \\\\\n1 &2 &2 &1\n\\end{array}\n\\right], \\quad \\quad\nB=\\left[\n\\begin{array}{cccc}\n2 &2 &-3 \\\\\n1 &3 &2 \\\\\n-3 &-2 &2\n\\end{array}\n\\right].\n\\tag{4.9}\\] Then, according to Eq. 4.8, Evidently, \\(\\Vert A \\Vert_{\\infty}=\\max \\{4, 6, 7, 6\\}=7\\) and \\(\\Vert B \\Vert_{\\infty}=\\max \\{7, 6, 7 \\}=7\\).\n\nLater we will need the following important property of a natural matrix norm.\n\nTheorem 4.2 For any \\(\\mathbf{x}\\neq 0\\), any matrix \\(A\\), and any natural norm \\(\\Vert \\, \\cdot \\, \\Vert\\), \\[\n\\Vert A\\mathbf{x}\\Vert \\leq \\Vert A\\Vert \\cdot\n\\Vert \\mathbf{x}\\Vert.\n\\tag{4.10}\\]\n\n\nProof. The proof is very easy: \\[\n\\frac{\\Vert A\\mathbf{x}\\Vert}{\\Vert \\mathbf{x}\\Vert} = \\left\\Vert A \\frac{\\mathbf{x}}{\\Vert \\mathbf{x}\\Vert}\\right\\Vert \\leq \\max_{\\Vert \\mathbf{y}\\Vert=1}\\Vert A\\mathbf{y}\\Vert = \\Vert A \\Vert\n\\ \\ \\Rightarrow \\ \\ \\Vert A\\mathbf{x}\\Vert \\leq \\Vert A\\Vert \\cdot\n\\Vert \\mathbf{x}\\Vert.\n\\tag{4.11}\\] Here we have used the relevant properties of the vector norm and the definition of the natural matrix norm.  \n\n\nRemark. For any natural norm, the above theorem implies property (iv) in the definition of the matrix norm. Indeed, for any \\(\\mathbf{x}\\neq 0\\) we have \\[\n\\Vert AB\\mathbf{x}\\Vert \\leq \\Vert A\\Vert \\, \\Vert B\\mathbf{x}\\Vert \\leq  \\Vert A\\Vert \\, \\Vert B \\Vert \\, \\Vert \\mathbf{x}\\Vert\n\\tag{4.12}\\] and \\[\n\\left\\Vert AB \\, \\frac{\\mathbf{x}}{\\Vert \\mathbf{x}\\Vert} \\right\\Vert \\leq  \\Vert A\\Vert \\, \\Vert B \\Vert .\n\\tag{4.13}\\] Since the last inequality is valid for all \\(\\mathbf{x}\\neq 0\\), it implies that \\[\n\\Vert AB \\Vert = \\max_{\\Vert \\mathbf{y}\\Vert = 1}\\left\\Vert AB \\mathbf{y}\\right\\Vert  \\leq  \\Vert A\\Vert \\, \\Vert B \\Vert.\n\\tag{4.14}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Solving systems of nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter04.html#fixed-point-iteration-for-vectors",
    "href": "chapter04.html#fixed-point-iteration-for-vectors",
    "title": "4  Solving systems of nonlinear equations",
    "section": "4.3 Fixed point iteration for vectors",
    "text": "4.3 Fixed point iteration for vectors\nWe already know that, in the case of functions of one variable, the root finding problem \\(f(x)=0\\) can be reformulated as a fixed point problem \\(g(x)=x\\). The same is true for systems of nonlinear equations: \\(\\mathbf{f}(\\mathbf{x})=\\mathbf{0}\\) can be rewritten as \\(\\mathbf{g}(\\mathbf{x})=\\mathbf{x}\\) in infinitely many ways, for example with \\(\\mathbf{g}(\\mathbf{x})=\\mathbf{x}-\\lambda \\mathbf{f}(\\mathbf{x})\\) for any nonzero constant \\(\\lambda\\).\nNow we consider the fixed point problem for vectors. Given a function \\(\\mathbf{g}: \\mathbb{R}^m \\to \\mathbb{R}^m\\), the problem is to find a point \\(\\mathbf{x}\\in \\mathbb{R}^m\\) such that \\[\n\\mathbf{g}(\\mathbf{x})=\\mathbf{x} \\ \\ \\hbox{or, equivalently,} \\ \\\n  \\left\\{\n  \\begin{array}{l}\n  g_{1}(x_{1},\\dots,x_{m})=x_1 \\\\\n  g_{2}(x_{1},\\dots,x_{m})=x_2 \\\\\n  \\vdots                     \\\\\n  g_{m}(x_{1},\\dots,x_{m})=x_m\n  \\end{array}\n\\right.\n\\tag{4.15}\\]\nWe choose an initial approximation, a vector \\(\\mathbf{x}^{(0)}\\), and compute the sequence of vectors \\(\\{\\mathbf{x}^{(n)}\\}\\) using the formula \\[\n\\mathbf{x}^{(n+1)}=\\mathbf{g}(\\mathbf{x}^{(n)}) \\quad (n=0,1,\\dots).\n\\tag{4.16}\\]\nTo investigate the convergence of the fixed point iteration, we need to recall some results from Vector Calculus.\nTaylor’s series expansion for functions of several variables. We assume that \\(f: D \\to \\mathbb{R}\\) (where \\(D\\subset \\mathbb{R}^m\\) is an open and convex region of \\(\\mathbb{R}^m\\)) is \\((n+1)\\) times continuously differentiable in \\(D\\), i.e. \\(f\\in C^{n+1}(D)\\). The Taylor’s series expansion for \\(f\\) can be obtained from the expansion for a function of one variable.\nLet \\(\\mathbf{x}\\) and \\(\\mathbf{x}_0\\) be two points in \\(D\\) and let \\(\\mathbf{v}=\\mathbf{x}-\\mathbf{x}_0\\), then the function \\(\\phi:[0,1]\\to\\mathbb{R}\\) defined by \\[\n\\phi(t)=f(\\mathbf{x}_0+t\\mathbf{v})\n\\tag{4.17}\\] is a function of one variable which is \\((n+1)\\) times continuously differentiable on the interval \\([0,1]\\). Note also that \\(f(\\mathbf{x}_0)=\\phi(0)\\) and \\(f(\\mathbf{x})=\\phi(1)\\). Applying Taylor’s theorem for functions of one variable to \\(\\phi(t)\\), we obtain \\[\n\\phi(t)=\\phi(0)+t\\phi'(0)+\\frac{t^2}{2} \\, \\phi''(0)+\\dots +\\frac{t^n}{n!} \\, \\phi^{(n)}(0)+ R_n(t)\n\\tag{4.18}\\] where the remainder term \\(R_n(t)\\) can be written in various forms, e.g. in the Lagrange form \\[\nR_n(t)=\\frac{t^{n+1}}{(n+1)!} \\, \\phi^{(n+1)}(\\xi) \\ \\ \\hbox{for some} \\ \\ \\xi\\in(0,1),\n\\tag{4.19}\\] or in the integral form \\[\nR_n(t)=\\frac{1}{n!} \\, \\int\\limits_{0}^{t} \\phi^{(n+1)}(s)(t-s)^n \\, ds.\n\\tag{4.20}\\] We will see that this integral form of the remainder will be more convenient for us.\nThe chain rule yields \\[\\begin{multline}\nf(\\mathbf{x}_0+t\\mathbf{v})=f(\\mathbf{x}_0)+t(\\mathbf{v}\\cdot\\nabla)f(\\mathbf{x}_0)+\\frac{t^2}{2} \\, (\\mathbf{v}\\cdot\\nabla)^2f(\\mathbf{x}_0)+\\dots \\\\\n+\\frac{t^n}{n!} \\, (\\mathbf{v}\\cdot\\nabla)^nf(\\mathbf{x}_0)+ R_n(t) \\quad\n\\end{multline}\\] {#eq-taylor-multivariable}\nwhere \\(\\mathbf{v}\\cdot\\nabla=v_1\\partial_{x_1}+v_2\\partial_{x_2} +\\dots + v_m\\partial_{x_m}\\). Now we set \\(t=1\\), so that \\[\\begin{multline}\nf(\\mathbf{x})=f(\\mathbf{x}_0)+(\\mathbf{v}\\cdot\\nabla)f(\\mathbf{x}_0)+\\frac{1}{2} \\, (\\mathbf{v}\\cdot\\nabla)^2f(\\mathbf{x}_0)+\\dots\\\\\n+\\frac{1}{n!} \\, (\\mathbf{v}\\cdot\\nabla)^nf(\\mathbf{x}_0)+ R_n(1)\n\\end{multline}\\] {#eq-taylor-multivariable-final} with the remainder term \\[\nR_n(1)=\\frac{1}{n!} \\, \\int\\limits_{0}^{1} \\phi^{(n+1)}(s)(1-s)^n \\, ds .\n\\tag{4.21}\\] In particular, for \\(n=0\\) we get \\[\nf(\\mathbf{x})=f(\\mathbf{x}_0)+\\int\\limits_{0}^{1}\\sum_{i=1}^{m}(x_{i}-x_{0i})\\partial_{x_{i}}f(\\mathbf{x}_0+s\\mathbf{v}) ds\n\\tag{4.22}\\] and for \\(n=1\\) we get \\[\n\\begin{split}\nf(\\mathbf{x})=&f(\\mathbf{x}_0)+\\sum_{i=1}^{m}(x_{i}-x_{0i})\\partial_{x_{i}}f(\\mathbf{x}_0)\\\\\n&+ \\int\\limits_{0}^{1}\\sum_{i,j=1}^{m}(x_{i}-x_{0i})(x_{j}-x_{0j})\\partial_{x_{i}}\\partial_{x_{j}}f(\\mathbf{x}_0+s\\mathbf{v})\n(1-s) ds.\n\\end{split}\n\\tag{4.23}\\] Now let \\(\\mathbf{g}: D \\to \\mathbb{R}^m\\) and \\(\\mathbf{g}\\in C^1(D)\\) (i.e. \\(\\mathbf{g}\\) is continuously differentiable in \\(D\\)). Applying Eq. 4.22 to each component of \\(\\mathbf{g}\\), we obtain the formula \\[\ng_i(\\mathbf{x})=g_i(\\mathbf{y})+\\int\\limits_{0}^{1}\\sum_{k=1}^{m}(x_{k}-y_{k})\\partial_{x_{k}}g_{i}(\\mathbf{y}+s(\\mathbf{x}-\\mathbf{y})) ds,\n\\tag{4.24}\\] which is valid for any \\(\\mathbf{x},\\mathbf{y}\\in D\\). If we introduce the Jacobian matrix \\[\n\\mathbf{J}(\\mathbf{x}) = \\frac{\\partial\\mathbf{g}}{\\partial\\mathbf{x}}\n\\tag{4.25}\\] whose \\((i,j)\\) component is \\(\\partial g_i/\\partial x_j\\), the above formula can be written in a nicer form: \\[\n\\mathbf{g}(\\mathbf{x})=\\mathbf{g}(\\mathbf{y})+\\int\\limits_{0}^{1}\\mathbf{J}(\\mathbf{y}+s(\\mathbf{x}-\\mathbf{y}))(\\mathbf{x}-\\mathbf{y}) ds .\n\\tag{4.26}\\] It can be shown (see for example Ortega 1972, chap. 8) that for any continuous function \\(\\mathbf{G}: [a,b]\\to \\mathbb{R}^m\\) and any vector norm, \\[\n\\left\\Vert \\int\\limits_{a}^{b} \\mathbf{G}(s)ds \\right\\Vert \\leq \\int\\limits_{a}^{b} \\left\\Vert \\mathbf{G}(s)\\right\\Vert \\, ds.\n\\tag{4.27}\\]\nNow we are ready to (partially) prove the following theorem.\n\nTheorem 4.3 Let \\(\\mathbf{g}: D\\to D\\) be continuously differentiable, where \\(D\\subset\\mathbb{R}^m\\) is a closed and convex region. If there exists \\(0&lt;k&lt;1\\) such that \\[\n\\left\\Vert\\frac{\\partial\\mathbf{g}}{\\partial\\mathbf{x}}\\right\\Vert \\leq k \\ \\ \\hbox{for all} \\ \\mathbf{x}\\in D,\n\\tag{4.28}\\] then \\(\\mathbf{g}\\) has a unique fixed point \\(\\mathbf{p}\\) in \\(D\\) and the sequence \\(\\{\\mathbf{x}^{(n)}\\}\\) generated be the formula \\[\n\\mathbf{x}^{(n+1)}=\\mathbf{g}(\\mathbf{x}^{(n)}) \\quad (n=0,1,\\dots)\n\\tag{4.29}\\] converges to \\(\\mathbf{p}\\) for any \\(\\mathbf{x}^{(0)}\\in D\\), and the following estimate holds: \\[\n\\left\\Vert \\mathbf{x}^{(n)}-\\mathbf{p}\\right\\Vert \\leq k^n \\left\\Vert \\mathbf{x}^{(0)}-\\mathbf{p}\\right\\Vert .\n\\tag{4.30}\\]\n\n\nProof. (partial) We will only partially prove this theorem. Namely, we will prove that \\(\\mathbf{g}\\) is a contraction mapping. Then the contraction mapping theorem (see, e.g. Wait 1979, chap. 5) will guarantee the existence and uniqueness of the fixed point, as well as convergence of the fixed point iteration. We will also prove the above error estimate.\nTo show that \\(\\mathbf{g}\\) is a contraction mapping (i.e there is a number \\(k\\in(0,1)\\) such that \\(\\Vert\\mathbf{g}(\\mathbf{x})-\\mathbf{g}(\\mathbf{y})\\Vert \\leq k \\, \\Vert \\mathbf{x}-\\mathbf{y}\\Vert\\) for all \\(\\mathbf{x}, \\mathbf{y}\\in D\\)), we will use Eq. 4.26. It follows from Eq. 4.26 that \\[\n\\Vert\\mathbf{g}(\\mathbf{x})-\\mathbf{g}(\\mathbf{y})\\Vert=\\left\\Vert\\int\\limits_{0}^{1}\\mathbf{J}(\\mathbf{y}+s(\\mathbf{x}-\\mathbf{y}))(\\mathbf{x}-\\mathbf{y}) ds \\right\\Vert.\n\\tag{4.31}\\] Now, with the help of Eq. 4.26, we obtain \\[\n\\begin{split}\n\\Vert\\mathbf{g}(\\mathbf{x})-\\mathbf{g}(\\mathbf{y})\\Vert &\\leq \\int\\limits_{0}^{1}\\left\\Vert\\mathbf{J}(\\mathbf{y}+s(\\mathbf{x}-\\mathbf{y}))(\\mathbf{x}-\\mathbf{y})\\right\\Vert ds \\\\\n&\\leq \\int\\limits_{0}^{1}\\left\\Vert\\mathbf{J}(\\mathbf{y}+s(\\mathbf{x}-\\mathbf{y}))\\right\\Vert \\Vert\\mathbf{x}-\\mathbf{y}\\Vert ds  \\\\\n&\\leq \\sup_{\\mathbf{x}\\in D}\\left\\Vert\\mathbf{J}(\\mathbf{x})\\right\\Vert \\int\\limits_{0}^{1} \\Vert\\mathbf{x}-\\mathbf{y}\\Vert ds =\n\\sup_{\\mathbf{x}\\in D}\\left\\Vert\\mathbf{J}(\\mathbf{x})\\right\\Vert \\Vert\\mathbf{x}-\\mathbf{y}\\Vert \\\\\n&\\leq k \\, \\Vert\\mathbf{x}-\\mathbf{y}\\Vert .\n\\end{split}\n\\tag{4.32}\\] Here we have used the property of the natural matrix norm that we have proved earlier: \\(\\Vert A\\mathbf{x}\\Vert\\leq\\Vert A\\Vert \\Vert \\mathbf{x}\\Vert\\). The above proves the fact that \\(\\mathbf{g}\\) is a contraction mapping.\nThe proof of the error estimate is exactly the same as in the case of functions of one variable: if \\(\\mathbf{p}\\) is a fixed point, then \\[\n\\begin{split}\n\\Vert\\mathbf{x}^{(n)}-\\mathbf{p}\\Vert &= \\Vert\\mathbf{g}(\\mathbf{x}^{(n-1)})-\\mathbf{g}(\\mathbf{p})\\Vert \\\\\n&\\leq k\\Vert \\mathbf{x}^{(n-1)}-\\mathbf{p}\\Vert =  k\\Vert\\mathbf{g}(\\mathbf{x}^{(n-2)})-\\mathbf{g}(\\mathbf{p})\\Vert\\\\\n&\\leq k^2\\Vert \\mathbf{x}^{(n-2)}-\\mathbf{p}\\Vert =  k\\Vert\\mathbf{g}(\\mathbf{x}^{(n-3)})-\\mathbf{g}(\\mathbf{p})\\Vert\\\\\n&\\vdots  \\\\\n&\\leq k^n\\Vert \\mathbf{x}^{(0)}-\\mathbf{p}\\Vert .\n\\end{split}\n\\tag{4.33}\\]\n\n\nExample 4.4 Let us consider the function \\(\\mathbf{g}\\) defined on \\(D=[0,1]\\times[0,1] \\subset \\mathbb{R}^2\\) by \\[\n\\mathbf{g}(\\mathbf{x})=\n\\begin{pmatrix}\ng_1(x_1,x_2) \\\\ g_2(x_1,x_2)\n\\end{pmatrix}=\\begin{pmatrix}\n\\cos x_2 \\\\ \\frac{3}{4}\\sin x_1\n\\end{pmatrix}.\n\\tag{4.34}\\] This is well-defined: For any \\(\\mathbf{x}\\in [0,1]\\times [0,1]\\), we know that \\(\\mathbf{g}(\\mathbf{x})\\in [0,1]\\times [0,1]\\) due to the well-known bounds on the trigonometric functions. We can compute the Jacobian matrix of \\(\\mathbf{g}\\): \\[\n\\frac{\\partial \\mathbf{g}}{\\partial \\mathbf{x}} = \\begin{pmatrix}\n      0 & -\\sin x_2 \\\\ \\frac{3}{4}\\cos x_1 & 0\n\\end{pmatrix}\n\\tag{4.35}\\] Therefore, \\[\n\\left\\Vert \\frac{\\partial \\mathbf{g}}{\\partial \\mathbf{x}} \\right\\Vert\n\\leq \\max \\left\\{  \\sin(1), \\frac{3}{4}  \\right\\} \\leq 0.85,\n\\tag{4.36}\\] so that the conditions of Theorem 4.3 are fulfilled with \\(k=0.85\\). The fixed point iteration will therefore converge for any choice of \\(\\mathbf{x}^{(0)} \\in [0,1] \\times [0,1]\\), although possibly not very fast, since \\(0.85\\) is not very much smaller than \\(1\\). See Table 4.1 for two examples of iteration sequences.\n\n\n\n\n\n\\(n\\)\n\\(x_1^{(n)}\\)\n\\(x_2^{(n)}\\)\n\n\n\n\n\\(0\\)\n\\(1.0\\)\n\\(1.0\\)\n\n\n\\(1\\)\n\\(0.5403023059\\)\n\\(0.6311032386\\)\n\n\n\\(2\\)\n\\(0.8073770495\\)\n\\(0.3857964440\\)\n\n\n\\(3\\)\n\\(0.9264990269\\)\n\\(0.5418571235\\)\n\n\n\\(4\\)\n\\(0.8567523888\\)\n\\(0.5996415238\\)\n\n\n\\(5\\)\n\\(0.8255379728\\)\n\\(0.5667897802\\)\n\n\n\\(6\\)\n\\(0.8436289716\\)\n\\(0.5511845408\\)\n\n\n\\(7\\)\n\\(0.8519047798\\)\n\\(0.5602953112\\)\n\n\n\\(8\\)\n\\(0.8470982088\\)\n\\(0.5644021231\\)\n\n\n\\(9\\)\n\\(0.8449085622\\)\n\\(0.5620215836\\)\n\n\n\\(10\\)\n\\(0.8461795432\\)\n\\(0.5609328142\\)\n\n\n\n\n\n\nTable 4.1: Numerical example for fixed point iteration\n\n\n\n\n\n\\(n\\)\n\\(x_1^{(n)}\\)\n\\(x_2^{(n)}\\)\n\n\n\n\n\\(0\\)\n\\(0.8\\)\n\\(0.6\\)\n\n\n\\(1\\)\n\\(0.8253356149\\)\n\\(0.5380170682\\)\n\n\n\\(2\\)\n\\(0.8587264910\\)\n\\(0.5510816060\\)\n\n\n\\(3\\)\n\\(0.8519586819\\)\n\\(0.5677582977\\)\n\n\n\\(4\\)\n\\(0.8431085532\\)\n\\(0.5644287452\\)\n\n\n\\(5\\)\n\\(0.8448943215\\)\n\\(0.5600357720\\)\n\n\n\\(6\\)\n\\(0.8472361089\\)\n\\(0.5609257244\\)\n\n\n\\(7\\)\n\\(0.8467630160\\)\n\\(0.5620900623\\)\n\n\n\\(8\\)\n\\(0.8461430490\\)\n\\(0.5618550885\\)\n\n\n\\(9\\)\n\\(0.8462682563\\)\n\\(0.5615469756\\)\n\n\n\\(10\\)\n\\(0.8464323655\\)\n\\(0.5616092188\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Solving systems of nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter04.html#sec-nleq",
    "href": "chapter04.html#sec-nleq",
    "title": "4  Solving systems of nonlinear equations",
    "section": "4.4 Newton’s method for systems of equations",
    "text": "4.4 Newton’s method for systems of equations\nA generalisation of Newton’s method to systems of non-linear equations can be done in a straightforward manner.\nConsider a given function \\(\\mathbf{f}: \\mathbb{R}^m \\to \\mathbb{R}^m\\). We are looking for the solution, \\(\\mathbf{x}\\in\\mathbb{R}^m\\), of the system of equations: \\[\n\\mathbf{f}(\\mathbf{x})=\\mathbf{0} \\ \\ \\hbox{or} \\ \\\n  \\left\\{\n  \\begin{array}{l}\n  f_{1}(x_{1},\\dots,x_{m})=0 \\\\\n  f_{2}(x_{1},\\dots,x_{m})=0 \\\\\n  \\vdots                     \\\\\n  f_{m}(x_{1},\\dots,x_{m})=0\n  \\end{array}\n\\right.\n\\tag{4.37}\\]\nThe idea of Newton’s method for systems of equations is the same as for one equation. First we expand each component of \\(\\mathbf{f}\\) in Taylor series \\[\nf_{i}(\\mathbf{x})=f_{i}(\\mathbf{x}_0)+\\sum_j\\frac{\\partial f_i(\\mathbf{x}_0)}{\\partial x_j}(x_{j}-x_{0j})+\\dots  \\quad (i=1,\\dots,m).\n\\tag{4.38}\\] This can be written as \\[\n\\mathbf{f}(\\mathbf{x})=\\mathbf{f}(\\mathbf{x}_0)+J(\\mathbf{x}_0)(\\mathbf{x}-\\mathbf{x}_{0})+\\dots\n\\tag{4.39}\\] where \\(J(\\mathbf{x}_0)\\) is the Jacobian matrix for function \\(\\mathbf{f}\\) at point \\(\\mathbf{x}_0\\).\nLet \\(\\mathbf{p}\\in\\mathbb{R}^m\\) be a solution of \\(\\mathbf{f}(\\mathbf{x})=\\mathbf{0}\\) and \\(\\mathbf{x}^*\\) be a sufficiently good approximation to \\(\\mathbf{p}\\), so that \\(\\Vert \\mathbf{p}- \\mathbf{x}^*\\Vert\\) is small. Then we have \\[\n\\mathbf{0}=\\mathbf{f}(\\mathbf{p})\\approx \\mathbf{f}(\\mathbf{x}^*)+J(\\mathbf{x}^*)(\\mathbf{p}-\\mathbf{x}^*).\n\\tag{4.40}\\] If the matrix \\(J(\\mathbf{x}^*)\\) is invertible, this can be rewritten as \\[\n\\mathbf{p}\\approx \\mathbf{x}^* - J^{-1}(\\mathbf{x}^*)\\mathbf{f}(\\mathbf{x}^*).\n\\tag{4.41}\\] This formula will not give us the exact solution \\(\\mathbf{p}\\) because we have ignored higher order terms in the Taylor expansion. Nevertheless, it is natural to expect that it will give us a better approximation than \\(\\mathbf{x}^*\\).\nSo, we will consider the following iterative process:\n\nWe choose an initial approximation \\(\\mathbf{x}^{(0)}\\).\nWe compute the sequence of approximations, \\(\\left\\{\\mathbf{x}^{(0)}\\right\\}\\), using the formula \\[\n\\mathbf{x}^{(n+1)} = \\mathbf{x}^{(n)} - J^{-1}(\\mathbf{x}^{(n)})\\mathbf{f}(\\mathbf{x}^{(n)}).\n\\tag{4.42}\\]\n\nThis is Newton’s method for systems of equations.\n\nRemark. If the number of equations is large (i.e. \\(m\\) is large), it is computationally very expensive to find \\(J^{-1}(\\mathbf{x}^{(n)})\\). Therefore, in practice, Eq. 4.42 is replaced by the following equivalent procedure: first we solve the system of linear equations \\[\nJ(\\mathbf{x}^{(n)})\\mathbf{v}^{(n)} = - \\mathbf{f}(\\mathbf{x}^{(n)})  \n\\tag{4.43}\\] for \\(\\mathbf{v}^{(n)}\\), and then we compute \\(\\mathbf{x}^{(n+1)}\\): \\[\n\\mathbf{x}^{(n+1)} = \\mathbf{x}^{(n)} + \\mathbf{v}^{(n)} .\n\\tag{4.44}\\]\n\nNewton’s method for systems of equations produces quadratically converging sequences, as follows from the following theorem:\n\nTheorem 4.4 Let \\(D \\subset \\mathbb{R}^m\\) be open and convex, and let \\(\\mathbf{f}\\in C^{2}(D)\\). If \\(\\mathbf{p}\\in D\\) is such that \\(\\mathbf{f}(\\mathbf{p})=0\\) and \\(\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{x}}(\\mathbf{p})\\) is invertible, then there exists \\(\\delta &gt;0\\) such that the sequence \\(\\{\\mathbf{x}^{(n)}\\}\\) defined in Eq. 4.42 converges to \\(\\mathbf{p}\\) for any initial approximation \\(\\mathbf{x}^{(0)}\\) with \\(\\Vert \\mathbf{p}-\\mathbf{x}^{(0)}\\Vert &lt; \\delta\\). Moreover, if \\(\\mathbf{f}\\in C^{3}(D)\\), then there exists \\(K&gt;0\\) such that \\[\n   \\Vert \\mathbf{x}^{(n)} - \\mathbf{p}\\Vert \\leq K \\Vert \\mathbf{x}^{(n-1)} - \\mathbf{p}\\Vert^2  \\quad \\text{for \\ all } \\ \\ n \\geq 1.\n\\tag{4.45}\\]\n\nWe will not prove this theorem here. A proof of a more general theorem can be found in Kelley (1995).\nThe estimate Eq. 4.45 guarantees that convergence is very fast if \\(\\mathbf{x}^{(0)}\\) is chosen close enough to the solution \\(\\mathbf{p}\\). In practical applications, as few as 4 or 5 steps of Newton iteration are often sufficient to reach the desired accuracy.\n\nExample 4.5 Consider the system \\(\\mathbf{f}(\\mathbf{x})=\\mathbf{0}\\) with \\[\n\\mathbf{f}(\\mathbf{x})=\n\\begin{pmatrix}\nf_1(x_1,x_2)\\\\\nf_2(x_1,x_2)\n\\end{pmatrix}\n= \\begin{pmatrix}\nx_1^2 + x_2^2 -1\\\\\nx_2 - x_1^2\n\\end{pmatrix}.\n\\tag{4.46}\\] This system has two solutions corresponding to the two intersection points of the unit circle and the parabola shown in Figure 4.1. These two solutions can be computed analytically: \\[\n\\mathbf{p}_1 = \\begin{pmatrix}\n\\sqrt{\\left(\\sqrt{5}-1\\right)/2}\\\\ \\left(\\sqrt{5}-1\\right)/2 \\end{pmatrix} \\approx\n\\begin{pmatrix} 0.7861513773 \\\\ 0.618033988 \\end{pmatrix}\n\\tag{4.47}\\] and \\[\n\\mathbf{p}_2 = \\begin{pmatrix} -\\sqrt{\\left(\\sqrt{5}-1\\right)/2}\\\\ \\left(\\sqrt{5}-1\\right)/2 \\end{pmatrix} \\approx\n\\begin{pmatrix} -0.7861513773 \\\\ 0.618033988 \\end{pmatrix} .\n\\tag{4.48}\\] The Jacobian of \\(\\mathbf{f}\\) is \\[\nJ(\\mathbf{x}) = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}}(\\mathbf{x}) =\n\\begin{pmatrix}\n2x_{1} & 2x_{2} \\\\ -2x_1 & 1\n\\end{pmatrix},\n\\tag{4.49}\\] so \\(\\mathbf{f}\\) is continuously differentiable. It is also straightforward to check that the second and third order partial derivatives of \\(\\mathbf{f}\\) are continuous (do this!). The inverse of the Jacobian is \\[\nJ^{-1}(\\mathbf{x}) = \\begin{pmatrix}\n\\displaystyle\\frac{1}{2x_1(2x_2+1)} & \\displaystyle -\\frac{x_2}{x_1(2x_2+1)} \\\\\n\\displaystyle\\frac{1}{2x_2+1} & \\displaystyle \\frac{1}{2x_2+1}\n\\end{pmatrix}.\n\\tag{4.50}\\] This matrix is not well-defined for all \\(\\mathbf{x}\\) (it has singularities for \\(x_1=0\\) and any \\(x_2\\) and for \\(x_2=-1/2\\) and any \\(x_1\\)), but it is defined at the roots we seek (check this!), so Newton’s method is convergent by Theorem 4.4, provided that we choose initial values close enough to those roots.\nWe choose \\(\\mathbf{x}^{(0)}=(0.5,0.5)^{t}\\) and \\(\\mathbf{x}^{(0)}=(-0.5,0.5)^{t}\\) as the initial approximations for the two solutions, and then compute sequences of approximations using Eq. 4.43 and Eq. 4.44. Table 4.2 demonstrates the rapid convergence of Newton’s method to the two solutions.\n\n\n\n\n\nTable 4.2: Numerical example for Newton’s method\n\n\n\n\n\n\n\n\n\n\n\n\\(n\\)\n\\(x_{1}^{(n)}\\)\n\\(x_{2}^{(n)}\\)\n\\(\\Vert \\mathbf{x}^{(n)}-\\mathbf{p}_1\\Vert\\)\n\n\n\n\n\\(0\\)\n\\(0.5\\)\n\\(0.5\\)\n\n\n\n\\(1\\)\n\\(0.87500000\\)\n\\(0.62500000\\)\n\\(0.08884862\\)\n\n\n\\(2\\)\n\\(0.79067460\\)\n\\(0.61805556\\)\n\\(0.00452323\\)\n\n\n\\(3\\)\n\\(0.78616432\\)\n\\(0.61803399\\)\n\\(0.00001294\\)\n\n\n\\(4\\)\n\\(0.78615138\\)\n\\(0.61803399\\)\n\\(7.499\\cdot 10^{-10}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(n\\)\n\\(x_{1}^{(n)}\\)\n\\(x_{2}^{(n)}\\)\n\\(\\Vert \\mathbf{x}^{(n)}-\\mathbf{p}_2\\Vert\\)\n\n\n\n\n\\(0\\)\n\\(-0.5\\)\n\\(0.5\\)\n\n\n\n\\(1\\)\n\\(-0.87500000\\)\n\\(0.62500000\\)\n\\(0.08884862\\)\n\n\n\\(2\\)\n\\(-0.79067460\\)\n\\(0.61805556\\)\n\\(0.00452323\\)\n\n\n\\(3\\)\n\\(-0.78616432\\)\n\\(0.61803399\\)\n\\(0.00001294\\)\n\n\n\\(4\\)\n\\(-0.78615138\\)\n\\(0.61803399\\)\n\\(7.499\\cdot 10^{-10}\\)\n\n\n\n\n\n\nFurther reading: Section 10.2 of (Burden and Faires 2010).\n\n\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical Analysis. 9th ed. Brooks Cole.\n\n\nKelley, C. T. 1995. Iterative Methods for Linear and Nonlinear Equations. Frontiers in Applied Mathematics. Society for Industrial; Applied Mathematics (SIAM).\n\n\nOrtega, James M. 1972. Numerical Analysis; a Second Course. Computer Science and Applied Mathematics. New York: Academic Press. https://yorsearch.york.ac.uk/permalink/f/1d5jm03/44YORK_ALMA_DS21223457930001381.\n\n\nWait, R. A. 1979. The Numerical Solution of Algebraic Equations. Wiley-Interscience Publication. John Wiley. https://yorsearch.york.ac.uk/permalink/f/1d5jm03/44YORK_ALMA_DS21219298850001381.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Solving systems of nonlinear equations</span>"
    ]
  },
  {
    "objectID": "chapter05.html",
    "href": "chapter05.html",
    "title": "5  Iterative techniques for solving systems of linear equations",
    "section": "",
    "text": "5.1 The Jacobi method\nConsider the system of linear equations \\[\nA{\\mathbf{x}}={\\mathbf{b}}\n\\tag{5.1}\\] where \\[\nA=\\left(\n\\begin{array}{cccc}\na_{11} &a_{12} &\\dots &a_{1n} \\\\\na_{21} &a_{22} &\\dots &a_{2n} \\\\\n\\vdots &\\vdots &      &\\vdots \\\\\na_{n1} &a_{n2} &\\dots &a_{nn}\n\\end{array}\\right), \\qquad\n\\mathbf{x}=\\left(\n\\begin{array}{c}\nx_{1} \\\\\nx_{2} \\\\\n\\vdots \\\\\nx_{n}\n\\end{array}\\right), \\qquad\n\\mathbf{b}=\\left(\n\\begin{array}{c}\nb_{1} \\\\\nb_{2} \\\\\n\\vdots \\\\\nb_{n}\n\\end{array}\\right)\n\\tag{5.2}\\] for a vector \\(\\mathbf{x}\\) of unknowns. An iterative method for a linear system starts with an initial approximation \\(\\mathbf{x}^{(0)}\\) and generates a sequence of vectors \\(\\{\\mathbf{x}^{(k)}\\}\\) that converges to the solution \\(\\mathbf{x}\\). In constructing an iterative method, we first convert the system \\(A\\mathbf{x}=\\mathbf{b}\\) to the form \\[\n\\mathbf{x}=T\\mathbf{x}+ \\mathbf{c}\n\\tag{5.3}\\] where \\(T\\) is a fixed matrix and \\(\\mathbf{c}\\) is a fixed vector. Then, we compute a sequence of approximations using the formula \\[\n\\mathbf{x}^{(k+1)}=T\\mathbf{x}^{(k)} + \\mathbf{c}   \\text{  for }   k=0, 1, 2, ...\n\\tag{5.4}\\] Note that this can be viewed as the fixed point iteration for function \\(\\mathbf{g}(\\mathbf{x})=T\\mathbf{x}^{(k)} + \\mathbf{c}\\).\nLet us say a few words about the convergence of sequences of vectors generated by formula Eq. 5.4 (a more detailed analysis for concrete methods will be given later). Subtracting Eq. 5.3 from Eq. 5.4, we obtain \\[\n\\mathbf{x}^{(k+1)}-\\mathbf{x}=T(\\mathbf{x}^{(k)}-\\mathbf{x})\n\\tag{5.5}\\] from which it follows that \\[\n\\Vert\\mathbf{x}^{(k+1)}-\\mathbf{x}\\Vert=\\Vert T(\\mathbf{x}^{(k)}-\\mathbf{x})\\Vert \\leq \\Vert T\\Vert , \\Vert\\mathbf{x}^{(k)}-\\mathbf{x}\\Vert ,\n\\tag{5.6}\\] where we have used the property of the natural matrix norm, Theorem 4.2. It follows from Eq. 5.6 and the contraction mapping theorem that the sequence will converge linearly provided that \\(\\Vert T\\Vert \\, \\Vert &lt; 1\\).\nThe method we have used is called the Jacobi iterative method. In general, it consists of solving the \\(i\\)th equation of the system \\(A\\mathbf{x}=\\mathbf{b}\\) for \\(x_{i}\\) to obtain \\[\nx_{i}=\\sum_{j=1, j\\neq i}^{n}\n\\left(-\\frac{a_{ij}x_{j}}{a_{ii}}\\right)+\n\\frac{b_{i}}{a_{ii}} \\ \\ \\ \\text{  for } \\ \\ i=1,2,...,n\n\\tag{5.12}\\] and calculating \\(\\mathbf{x}^{(k+1)}\\) from \\(\\mathbf{x}^{(k)}\\) for \\(k\\geq 0\\) by \\[\nx_{i}^{(k+1)}=\\frac{1}{a_{ii}}\\left( \\sum_{j=1, j\\neq i}^{n} \\left(-a{ij}x_{j}^{(k)}\\right)+ b_{i}\\right)    \\text{  for }   i=1,2,...,n.\n\\tag{5.13}\\] Let us write the Jacobi method in matrix form \\(\\mathbf{x}^{(k+1)}=T\\mathbf{x}^{(k)} + \\mathbf{c}\\). To do this, we decompose the matrix \\(A\\) in the form \\(A=D+L+U\\), where \\(D\\) is the diagonal part of \\(A\\), \\(L\\) is the strictly lower-triangular part of \\(A\\), and \\(U\\) is the strictly upper-triangular part of \\(A\\): \\[\nA =\\left(\n\\begin{array}{cccc}\na_{11} &a_{12} &\\dots &a_{1n} \\\\\na_{21} &a_{22} &\\dots &a_{2n} \\\\\n\\vdots &\\vdots &      &\\vdots \\\\\na_{n1} &a_{n2} &\\dots &a_{nn}\n\\end{array}\n\\right) =\\left(\n\\begin{array}{cccc}\na_{11} &0      &\\dots &0   \\\\\n0      &a_{22} &\\ddots &\\vdots \\\\\n\\vdots &\\ddots &\\ddots &0  \\\\\n0      &\\dots &0 &a_{nn}\n\\end{array}\n\\right) + \\left(\n\\begin{array}{cccc}\n0       &\\dots     &\\dots &0   \\\\\na_{12} &\\ddots & &\\vdots \\\\\n\\vdots  &\\ddots &\\ddots &\\vdots  \\\\\na_{n2} &\\dots &a_{n,n-1} &0\n\\end{array}\n\\right)+ \\left(\n\\begin{array}{cccc}\n0      &a_{12}&\\dots &a_{1n}  \\\\\n\\vdots &\\ddots &\\ddots &\\vdots \\\\\n\\vdots &       &\\ddots &a_{n-1,n}  \\\\\n0      &\\dots  &\\dots &0  \\end{array}\n\\right).\n\\tag{5.14}\\] Now we have \\[\n(D+L+U)\\mathbf{x}=\\mathbf{b}   \\Leftrightarrow   D\\mathbf{x}=-(L+U)\\mathbf{x}+\\mathbf{b}   \\Leftrightarrow   \\mathbf{x}=-D^{-1}(L+U)^\\mathbf{x}+D{-1}\\mathbf{b}.\n\\tag{5.15}\\] Thus, we have converted the initial system \\(A\\mathbf{x}=\\mathbf{b}\\) to the form \\(\\mathbf{x}=T_{J}\\mathbf{x}+ \\mathbf{c}_{J}\\) with \\(T_{J}=-D^{-1}(L+U)\\) and \\(\\mathbf{c}_{J}=D^{-1}\\mathbf{b}\\), so that the Jacobi iterative method has the form \\[\n\\mathbf{x}^{(k+1)}=T_{J}^\\mathbf{x}{(k)} + \\mathbf{c}_{J} .\n\\tag{5.16}\\] The Jacobi method requires that \\(a_{ii}\\neq 0\\) for each \\(i=1, 2, ..., n\\). Therefore, if one of the elements \\(a_{ii}\\) is zero, we need to reorder the equation so that \\(a_{ii}\\neq 0\\) for each \\(i=1, 2, ..., n\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Iterative techniques for solving systems of linear equations</span>"
    ]
  },
  {
    "objectID": "chapter05.html#the-jacobi-method",
    "href": "chapter05.html#the-jacobi-method",
    "title": "5  Iterative techniques for solving systems of linear equations",
    "section": "",
    "text": "Example 5.1 Consider the system \\[\n\\begin{split}\n10x_{1} + 2x_{2}-x_{3} &= 7,  \\\\\nx_{1} +8 x_{2} +3x_{3}&= -4,  \\\\\n-2x_{1}-x_{2}+10x_{3} &= 9,  \n\\end{split}\n\\tag{5.7}\\] Its unique solution is \\(\\mathbf{x}=(1, -1,1)^{t}\\). First, we convert the system to the form \\(\\mathbf{x}=T\\mathbf{x}+ \\mathbf{c}\\) by solving the first equation for \\(x_{1}\\), the second for \\(x_{2}\\) and the third for \\(x_{3}\\): \\[\n\\begin{split}\nx_{1} &= -\\frac{2}{10}x_{2}+\\frac{1}{10}x_{3} + \\frac{7}{10},  \\\\\nx_{2} &=-\\frac{1}{8}x_{1} -\\frac{3}{8}x_{3}-\\frac{1}{2},  \\\\\nx_{3} &=\\frac{2}{10} x_{1}+\\frac{1}{10}x_{2} +\\frac{9}{10} ,\n\\end{split}\n\\tag{5.8}\\] Thus, \\(\\mathbf{x}=T\\mathbf{x}+ \\mathbf{c}\\) with \\[\nT=\\left(\n\\begin{array}{ccc}\n0 &-\\frac{2}{10} &\\frac{1}{10} \\\\\n-\\frac{1}{8} &0 &-\\frac{3}{8} \\\\\n\\frac{2}{10} &\\frac{1}{10}  &0\n\\end{array}\n\\right), \\qquad\n\\mathbf{c}=\\left(\n\\begin{array}{c}\n\\frac{7}{10} \\\\\n-\\frac{1}{2} \\\\\n\\frac{9}{10}\n\\end{array}\n\\right).\n\\tag{5.9}\\] Let the initial approximation be \\(\\mathbf{x}^{(0)}=(0, 0,0)^{t}\\). Then, \\[\n\\begin{split}\nx_{1}^{(1)} &= -\\frac{2}{10}x_{2}^{(0)}+\\frac{1}{10}x_{3}^{(0)} +\n\\frac{7}{10}=\\frac{7}{10},   \\\\\nx_{2}^{(1)} &=-\\frac{1}{8}x_{1}^{(0)} -\\frac{3}{8}x_{3}^{(0)}-\n\\frac{1}{2}=- \\frac{1}{2},   \\\\\nx_{3}^{(1)} &=\\frac{2}{10} x_{1}^{(0)}+\\frac{1}{10}x_{2}^{(0)} +\n\\frac{9}{10}=\\frac{9}{10} .\n\\end{split}\n\\tag{5.10}\\] and \\[\n\\begin{split}\nx_{1}^{(2)} &= -\\frac{2}{10}x_{2}^{(1)}+\\frac{1}{10}x_{3}^{(1)} +\n\\frac{7}{10}=0.89,  \\\\\nx_{2}^{(2)} &=-\\frac{1}{8}x_{1}^{(1)} -\\frac{3}{8}x_{3}^{(1)}-\n\\frac{1}{2}=-0.925,  \\\\\nx_{3}^{(2)} &=\\frac{2}{10} x_{1}^{(1)}+\\frac{1}{10}x_{2}^{(1)} +\n\\frac{9}{10}=0.99.\n\\end{split}\n\\tag{5.11}\\] One can see that just two iterations give a fairly good approximation to the solution \\(\\mathbf{x}=(1, -1, 1)^{t}\\). Further calculations yield:\n\n\n\n\n\\(k\\)\n\\(x^{(k)}_{1}\\)\n\\(x^{(k)}_{2}\\)\n\\(x^{(k)}_{3}\\)\n\n\n\n\n0\n0.0\n0.0\n0.0\n\n\n1\n0.7\n-0.5\n0.9\n\n\n2\n0.89\n-0.925\n0.99\n\n\n3\n0.984\n-0.9825\n0.9855\n\n\n4\n0.99505\n-0.9925625\n0.99855\n\n\n5\n0.9983675\n-0.9988375\n0.99975375\n\n\n6\n0.999742875\n-0.9997035938\n0.9997897500",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Iterative techniques for solving systems of linear equations</span>"
    ]
  },
  {
    "objectID": "chapter05.html#the-gauss-seidel-method",
    "href": "chapter05.html#the-gauss-seidel-method",
    "title": "5  Iterative techniques for solving systems of linear equations",
    "section": "5.2 The Gauss-Seidel method",
    "text": "5.2 The Gauss-Seidel method\nHow to improve the Jacobi method? In the Example 5.1, we used the iteration procedure \\[\n\\begin{split}\nx_{1}^{(k+1)} &= -\\frac{2}{10}x_{2}^{(k)}+\\frac{1}{10}x_{3}^{(k)} +\n\\frac{7}{10}, \\\\\nx_{2}^{(k+1)} &=-\\frac{1}{8}x_{1}^{(k)} -\\frac{3}{8}x_{3}^{(k)}-\n\\frac{1}{2}, \\\\\nx_{3}^{(k+1)} &=\\frac{2}{10} x_{1}^{(k)}+\\frac{1}{10}x_{2}^{(k)} +\n\\frac{9}{10} .\n\\end{split}\n\\tag{5.17}\\] When we calculate \\(x_{2}^{(k+1)}\\), we use \\(x_{1}^{(k)}\\) and \\(x_{3}^{(k)}\\), which have been calculated at the previous step. We may notice however that this stage we already know \\(x_{1}^{(k+1)}\\) which is assumed to be a better approximation to \\(x_{1}\\). It is natural therefore to replace \\(x_{1}^{(k)}\\) in the second equation by \\(x_{1}^{(k+1)}\\). Similarly, we may replace \\(x_{1}^{(k)}\\) and \\(x_{2}^{(k)}\\) in the third equation by \\(x_{1}^{(k+1)}\\) and \\(x_{2}^{(k+1)}\\). This yields the formula \\[\n\\begin{split}\nx_{1}^{(k+1)} &= -\\frac{2}{10}x_{2}^{(k)}+\\frac{1}{10}x_{3}^{(k)} +\n\\frac{7}{10},  \\\\\nx_{2}^{(k+1)} &=-\\frac{1}{8}x_{1}^{(k+1)} -\\frac{3}{8}x_{3}^{(k)}\n-\\frac{1}{2},  \\\\\nx_{3}^{(k+1)} &=\\frac{2}{10} x_{1}^{(k+1)}+\\frac{1}{10}x_{2}^{(k+1)}\n+\\frac{9}{10} .\n\\end{split}\n\\tag{5.18}\\] Eq. 5.18 with the initial approximation \\(\\mathbf{x}^{(0)}=(0, 0, 0)^{t}\\) generate the sequence\n\n\n\n\n\\(k\\)\n\\(x^{(k)}_{1}\\)\n\\(x^{(k)}_{2}\\)\n\\(x^{(k)}_{3}\\)\n\n\n\n\n0\n0.0\n0.0\n0.0\n\n\n1\n0.7\n-0.5875\n0.9812500000\n\n\n2\n0.915625\n-0.9824218750\n0.9848828125\n\n\n3\n0.9949726562\n-0.9937026368\n0.9996242675\n\n\n4\n0.9987029542\n-0.9996969695\n0.9997708938\n\n\n5\n0.9999164833\n-0.9999036455\n0.9999929322\n\n\n6\n0.9999800223\n-0.9999948524\n0.9999965193\n\n\n\n\nThis modification of the Jacobi technique is called the Gauss-Seidel iterative method. Comparing \\(\\mathbf{x}^{(6)}\\) obtained using the Jacobi and Gauss-Seidel methods, we see that the Gauss-Seidel method produces a better approximation to the exact solution \\(\\mathbf{x}=(1,-1,1)^{t}\\).\nThe general formula for the Gauss-Seidel method is (cf. Eq. 5.13) \\[\nx_{i}^{(k+1)}=\\frac{1}{a_{ii}}\\left( -\\sum_{j=1}^{i-1} a_{ij}x_{j}^{(k+1)}- \\sum_{j=i+1}^{n} a_{ij}x_{j}^{(k)} + b_{i}\\right)\n\\tag{5.19}\\] for \\(i=1, \\dots, n\\). Let us rewrite the Gauss-Seidel method in matrix form. To do this, we multiply both sides of Eq. 5.19 by \\(a_{ii}\\) and collect all terms of the \\(k\\)th iteration. This yields \\[\na_{i1}x_{1}^{(k+1)}+a_{i2}x_{2}^{(k+1)}+...+a_{ii}x_{i}^{(k+1)}= -a_{i, i+1}x_{i+1}^{(k)}-...- a_{in}x_{n}^{(k)}+b_{i}\n\\tag{5.20}\\] for \\(i=1, \\dots, n\\), or, equivalently, \\[\n\\begin{aligned}\n&&a_{11}x_{1}^{(k+1)} \\qquad\\qquad\\qquad\\qquad\\qquad\\quad\\quad\\quad =\n-a_{12}x_{2}^{(k)}-a_{13}x_{3}^{(k)}-...-\na_{1n}x_{n}^{(k)}+b_{1}\\\\\n&&a_{21}x_{1}^{(k+1)} +a_{22}x_{2}^{(k+1)} \\qquad\\qquad\\qquad \\quad\\quad =\n\\qquad\\qquad \\ -a_{23}x_{3}^{(k)}-...-\na_{2n}x_{n}^{(k)}+b_{2} \\\\\n&&\\vdots \\\\\n&&a_{n1}x_{1}^{(k+1)} +a_{n2}x_{2}^{(k+1)}+...+a_{n,n}x_{n}^{(k+1)} \\ =\n\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\n\\qquad\\quad \\ \\ \\  b_{n} .\n\\end{aligned}\n\\tag{5.21}\\] Therefore, \\[\n(D+L)\\mathbf{x}^{(k+1)}=-U\\mathbf{x}^{(k)}+\\mathbf{b}   \\Leftrightarrow   \\\n\\mathbf{x}^{(k+1)}=-(D+L)^{-1}U\\mathbf{x}^{(k)}+(D+L)^{-1}\\mathbf{b}   \\\n\\tag{5.22}\\] for \\(k=1, 2, \\dots.\\) Introducing the notation \\(T_{G}=-(D+L)^{-1}U\\) and \\(\\mathbf{c}_{G}=(D+L)^{-1}\\mathbf{b}\\), we rewrite the Gauss-Seidel method in the form \\[\n\\mathbf{x}^{(k+1)}=T_{G}\\mathbf{x}^{(k)} + \\mathbf{c}_{G} .\n\\tag{5.23}\\] Note that a lower-triangular matrix is nonsingular iff its diagonal elements are nonzero. In particular, \\(D+L\\) is nonsingular (i.e. its inverse exists) iff \\(a_{ii}\\neq 0\\) for each \\(i=1, 2, ..., n\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Iterative techniques for solving systems of linear equations</span>"
    ]
  },
  {
    "objectID": "chapter05.html#the-convergence-of-iterative-techniques.",
    "href": "chapter05.html#the-convergence-of-iterative-techniques.",
    "title": "5  Iterative techniques for solving systems of linear equations",
    "section": "5.3 The convergence of iterative techniques.",
    "text": "5.3 The convergence of iterative techniques.\nWe will use the following notation \\[\nE_{i}^{(k)} = \\vert x_{i}^{(k)} - x_{i}\\vert\n\\tag{5.24}\\] and \\[\nE^{(k)} = \\Vert \\mathbf{x}^{(k)}-\\mathbf{x}\\Vert_{\\infty}=\\max\\{E_{1}^{(k)}, \\dots, E_{n}^{(k)}\\}.\n\\tag{5.25}\\] Then \\(\\mathbf{x}^{(k)}\\to\\mathbf{x}\\) is equivalent to \\(E^{(k)}\\to 0\\) as \\(k\\to\\infty\\). We assume that \\(a_{ii}\\neq 0\\) for all \\(i\\) (otherwise both methods will not work).\nFor the Jacobi method we have \\[\nx_{i}=\\frac{1}{a_{ii}}\\left( \\sum_{j=1, j\\neq i}^{n} \\left(-a_{ij}x_{j}\\right)+ b_{i}\\right)\n\\tag{5.26}\\] and \\[\nx_{i}^{(k+1)}=\\frac{1}{a_{ii}}\\left( \\sum_{j=1, j\\neq i}^{n} \\left(-a_{ij}x_{j}^{(k)}\\right)+ b_{i}\\right)    \\text{  for }   i=1,2,...,n\n\\tag{5.27}\\] Subtracting Eq. 5.26 from Eq. 5.27 and using the triangle inequality, we obtain \\[\n\\begin{split}\nE_{i}^{(k+1)}&=\\frac{1}{\\vert a_{ii}\\vert}\\left\\vert\n\\sum_{j=1, j\\neq i}^{n}\na_{ij}\\left(x_{j}^{(k)}-x_{j}\\right)\\right\\vert \\leq\n\\frac{1}{\\vert a_{ii}\\vert}\n\\sum_{j=1, j\\neq i}^{n}\n\\left\\vert a_{ij}\\right\\vert \\left\\vert x_{j}^{(k)}-x_{j}\\right\\vert, \\\\\n&=\\sum_{j=1, j\\neq i}^{n}\\frac{\\left\\vert a_{ij}\\right\\vert}{\\vert a_{ii}\\vert}E_{j}^{(k)}\n\\leq \\sum_{j=1, j\\neq i}^{n}\\frac{\\left\\vert a_{ij}\\right\\vert}{\\vert a_{ii}\\vert}E^{(k)}\n\\leq \\mu E^{(k)},\n\\end{split}\n\\tag{5.28}\\] where \\[\n\\mu=\\max_{i}\\sum_{j=1, j\\neq i}^{n}\\frac{\\left\\vert a_{ij}\\right\\vert}{\\vert a_{ii}\\vert} .\n\\tag{5.29}\\] Therefore, \\[\nE^{(k+1)}\\leq \\mu , E^{(k)},\n\\tag{5.30}\\] and if \\(\\mu &lt; 1\\), then \\(\\mathbf{x}^{(k)}\\) converges to \\(\\mathbf{x}\\) strongly linearly, with rate of convergence \\(\\mu\\).\nNote that \\(\\mu\\) depends only on the coefficient matrix \\(A\\). Note also that the terms in Eq. 8.34 are the absolute values of the entries of \\(T_{J}\\), summed in each row, so that \\(\\mu=\\Vert T_{J}\\Vert_{\\infty}\\). In the example, we considered in the previous chapter, \\[\nA=\\left(\n\\begin{array}{ccc}\n10 &2 &-1 \\\\\n1  &8 &3 \\\\\n-2 &-1 &10\n\\end{array}\\right), \\qquad\n\\mathbf{b}=\\left(\n\\begin{array}{c}\n7 \\\\\n-4 \\\\\n9\n\\end{array}\\right), \\qquad\nT_{J}=\\left(\n\\begin{array}{ccc}\n0 &-\\frac{2}{10} &\\frac{1}{10} \\\\\n-\\frac{1}{8} &0 &-\\frac{3}{8} \\\\\n\\frac{2}{10} &\\frac{1}{10}  &0\n\\end{array}\n\\right).\n\\tag{5.31}\\] So, it follows from Eq. 8.34 that in our example \\(\\mu = 1/2\\). In general, the condition \\(\\mu &lt; 1\\) is equivalent to \\[\n\\sum_{j=1, j\\neq i}^{n}\\vert a_{ij}\\vert &lt; \\vert a_{ii}\\vert \\quad \\text{  for \\ all } \\ \\ i.\n\\tag{5.32}\\] Matrices \\(A\\) with this property are said to be strictly diagonally dominant. It follows that every strictly diagonally dominant square matrix is invertible. In fact it is not difficult to prove this directly, using elementary linear algebra.\nFor the Gauss-Seidel scheme the situation is slightly more complicated. Here we have \\[\nx_{i}^{(k+1)}=\\frac{1}{a_{ii}}\\left( -\\sum_{j=1}^{i-1} a_{ij}x_{j}^{(k+1)}-\n\\sum_{j=i+1}^{n} a_{ij}x_{j}^{(k)} + b_{i}\\right)\n\\tag{5.33}\\] for \\(i=1,2, \\dots, n\\). Subtracting Eq. 5.26 from Eq. 5.33, we obtain \\[\n\\begin{split}\nE_{i}^{(k+1)}&=\\frac{1}{\\vert a_{ii}\\vert}\\left\\vert\n\\sum_{j=1}^{i-1}\na_{ij}\\left(x_{j}^{(k+1)}-x_{j}\\right)+\n\\sum_{j=i+1}^{n}\na_{ij}\\left(x_{j}^{(k)}-x_{j}\\right)\\right\\vert \\\\\n&\\leq\n\\frac{1}{\\vert a_{ii}\\vert}\\left(\n\\sum_{j=1}^{i-1}\n\\left\\vert a_{ij}\\right\\vert \\left\\vert x_{j}^{(k+1)}-x_{j}\\right\\vert\n+\\sum_{j=i+1}^{n}\n\\left\\vert a_{ij}\\right\\vert \\left\\vert x_{j}^{(k)}-x_{j}\\right\\vert\\right) \\\\\n&=\\sum_{j=1}^{i-1}\\frac{\\left\\vert a_{ij}\\right\\vert}{\\vert a_{ii}\\vert}E_{j}^{(k+1)}\n+\\sum_{j=i+1}^{n}\\frac{\\left\\vert a_{ij}\\right\\vert}{\\vert a_{ii}\\vert}E_{j}^{(k)}\n\\leq \\alpha_{i} E^{(k+1)}+\\beta_{i} E^{(k)},\n\\end{split}\n\\tag{5.34}\\] where \\[\n\\begin{split}\n\\alpha_{i}&=\\sum{j=1}^{i-1}\\frac{\\left\\vert a_{ij}\\right\\vert}{\\vert a_{ii}\\vert},\\\\\n\\beta_{i}&=\\sum{j=i+1}^{n}\\frac{\\left\\vert a_{ij}\\right\\vert}{\\vert a_{ii}\\vert},\\\\\n\\alpha_{1}&=\\beta_{n}=0.\n\\end{split}\n\\tag{5.35}\\] Evidently, \\(\\mu = \\max_{i}(\\alpha_{i}+\\beta_{i})\\). From our analysis of the Jacobi method it is appropriate to assume \\(\\mu &lt; 1\\), so that \\(\\alpha_{i}+\\beta_{i} &lt; 1\\) for all \\(i\\) and also \\(1-\\alpha_{i} &gt; 0\\) for all \\(i\\) . Suppose now that \\(E^{(k+1)}=E_{m}^{(k+1)}\\) for some \\(m\\) (recalling that \\(E^{(k+1)}\\) is the maximum of the \\(E_{i}^{(k+1)}\\)). Then we have \\[\nE^{(k+1)}=E_{m}^{(k+1)}\\leq \\alpha_{m} E^{(k+1)}+\\beta_{m} E^{(k)}.\n\\tag{5.36}\\] Hence, \\[\nE^{(k+1)} \\leq \\frac{\\beta_{m}}{1-\\alpha_{m}}E^{(k)} \\leq \\eta \\, E^{(k)},\n\\tag{5.37}\\] where \\[\n\\eta=\\max_{i} \\frac{\\beta_{i}}{1-\\alpha_{i}}.\n\\tag{5.38}\\] Finally, we note that for each \\(i\\) we have \\[\n\\alpha_{i}+\\beta_{i}-\\frac{\\beta_{i}}{1-\\alpha_{i}}= \\frac{\\alpha_{i}[1-(\\alpha_{i}+\\beta_{i})]}{1-\\alpha_{i}}\\geq \\frac{\\alpha_{i}[1-\\mu]}{1-\\alpha_{i}}\\geq 0.\n\\tag{5.39}\\] This implies that \\(\\mu\\geq \\eta\\). Indeed, \\[\n\\alpha_{i}+\\beta_{i} \\geq \\frac{\\beta_{i}}{1-\\alpha_{i}} \\quad \\Rightarrow \\quad \\mu = \\max{i}(\\alpha_{i}+\\beta_{i})\\geq \\frac{\\beta_{i}}{1-\\alpha_{i}} \\quad \\Rightarrow \\quad \\mu \\geq \\max_{i}\\frac{\\beta_{i}}{1-\\alpha_{i}}=\\eta .\n\\tag{5.40}\\]\nSo, the Gauss-Seidel imethod converges strongly linearly with rate \\(\\eta\\), which is at least as fast as that of the Jacobi method. Although straightforward, computation of \\(\\eta\\) is more complicated than \\(\\mu\\). In our example we have\n\n\n\n\n\n\n\n\n\n\n\n\\(i\\)\n\\(\\alpha_{i}\\)\n\\(\\beta_{i}\\)\n\\(1-\\alpha_{i}\\)\n\\(\\beta_{i}/(1-\\alpha_{i})\\)\n\n\n\n\n1\n0\n3/10\n1\n3/10\n\n\n2\n1/8\n3/8\n7/8\n3/7\n\n\n3\n3/10\n0\n7/10\n0\n\n\n\n\nTherefore \\(\\eta = 3/7\\approx 0.43\\) (compared with \\(\\mu = 0.5\\)).\nThus, we have proved the following:\n\nTheorem 5.1 If \\(A\\) is strictly diagonally dominant, then for any \\(\\mathbf{x}^{(0)}\\in\\mathbb{R}^{n}\\), both the Jacobi and Gauss-Seidel methods generate sequences \\(\\{\\mathbf{x}^{(k)}\\}\\) that converge to the unique solution of \\(A\\mathbf{x}=\\mathbf{b}\\).\n\nNote that matrix \\(A\\) in our example is strictly diagonally dominant, so it is not unexpected that both Jacobi and Gauss-Seidel iterations converge to the solution of the system.\n\nRemark. The above theorem gives us a sufficient condition for convergence of sequences generated by both methods. However, this condition is not necessary. If it is not satisfied, the Jacobi and/or Gauss-Seidel methods may still produce converging sequences. So, if \\(A\\) is not strictly diagonally dominant, we cannot predict whether the Jacobi method or Gauss-Seidel method will converge.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Iterative techniques for solving systems of linear equations</span>"
    ]
  },
  {
    "objectID": "chapter06.html",
    "href": "chapter06.html",
    "title": "6  Approximation and interpolation",
    "section": "",
    "text": "6.1 Polynomial interpolation\nIn many situations, it is useful to approximate a function \\(f\\) with a “simpler” function with desirable properties. For example, if the antiderivative of a function \\(f\\) is not known, then computing an integral \\(\\int_a^b f(x) \\,dx\\) might be difficult. However, if we approximate \\(f\\) with a function \\(P\\) with known antiderivative, then \\(\\int_a^b f(x) \\,dx \\approx \\int_a^b P(x) \\,dx\\) can be computed easily. This is useful in numerical integration, which we will consider in the next chapter.\nIn this chapter we consider the case where the values of a function \\(f\\) are given only at at certain discrete points \\(x=x_i\\), that is, \\(f\\) is given in the form of a table. For example, \\(f(x_i)\\) might be the result of an experimental measurement or of numerical approximations. In this case, we would like to connect the points \\((x_i,f(x_i))\\) with a simple, reasonably smooth curve; this is called interpolation.\nThe “simple” functions that we will consider here are polynomials, that is, functions of the form \\[\nP(x)=a_nx^{n}+a_{n-1}x^{n-1}+\\ldots+a_1x+a_0,\n\\tag{6.1}\\] where \\(a_0, \\ldots, a_n\\) are real numbers, with \\(a_n\\neq 0\\) is the leading order coefficient and where \\(n\\) is a nonnegative integer, called the degree of \\(P\\) and denoted \\(\\deg P\\).\nThe problem that we want to consider can be stated as follows:\nGiven distinct points \\(x_0, x_1, \\dots , x_n\\) (not necessarily in increasing magnitude) in the domain of a function \\(f\\), find a polynomial \\(P\\) with \\(\\deg P \\leq n\\) such that \\[\n\\begin{aligned}\nP(x_0) &= f(x_0), & P(x_1) &= f(x_1), && \\dots & P(x_n) &= f(x_n).\n\\end{aligned}\n\\tag{6.2}\\] Any such polynomial \\(P\\) is called an interpolating polynomial for \\(f\\).\nPolynomials are suitable for approximation and interpolation because of the following important result.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Approximation and interpolation</span>"
    ]
  },
  {
    "objectID": "chapter06.html#polynomial-interpolation",
    "href": "chapter06.html#polynomial-interpolation",
    "title": "6  Approximation and interpolation",
    "section": "",
    "text": "Theorem 6.1 (Weierstrass Approximation Theorem) If \\(f: \\ [a,b]\\to \\mathbb{R}\\) is continuous on \\([a,b]\\), then for any \\(\\epsilon &gt; 0\\), there is a polynomial \\(P(x)\\) such that \\[\n\\vert f(x)-P(x)\\vert &lt; \\epsilon \\quad \\textrm{for \\ all} \\ \\ x\\in[a,b].\n\\tag{6.3}\\] In other words, any function, continuous on the closed interval, can be uniformly approximated by a polynomial.\n\n\n6.1.1 The Lagrange interpolating polynomial\nWe will now discuss a method of finding an interpolating polynomial. Let us first consider the simplest case, \\(n=1\\). Suppose we know the value of a function \\(f\\) at two points \\(x_0,x_1\\). To interpolate the values of \\(f\\) by a first-degree polynomial means to determine a polynomial \\(P\\) of degree 1 (i.e., a straight line) that passes through two points \\((x_0, f(x_0))\\) and \\((x_1, f(x_1)).\\) This polynomial has the form \\[\nP(x)=a_0+a_1x .\n\\tag{6.4}\\] The conditions \\(P(x_0)=f(x_0)\\) and \\(P(x_1)=f(x_1)\\) give us the following system of linear equations for \\(a_0\\) and \\(a_1\\): \\[\n\\begin{aligned}\na_0+a_1x_0&=f(x_0),  &\na_0+a_1x_1&=f(x_1).\n\\end{aligned}\n\\tag{6.5}\\] This system is solved easily for \\(a_0\\) and \\(a_1\\), and we obtain \\[\n\\begin{aligned}\na_1&=\\frac{f(x_1)-f(x_0)}{x_1-x_0},  &\na_0&=\\frac{x_0f(x_1)-x_1f(x_0)}{x_1-x_0}.\n\\end{aligned}\n\\tag{6.6}\\] Thus, we have \\[\nP(x)=\\frac{x_0f(x_1)-x_1f(x_0)}{x_1-x_0} + \\frac{f(x_1)-f(x_0)}{x_1-x_0}\\, x .\n\\tag{6.7}\\]\nLet us now rewrite this polynomial in a slightly different form: \\[\nP(x) = f(x_0)\\frac{x-x_1}{x_0-x_1} + f(x_1)\\frac{x-x_0}{x_1-x_0}\n\\tag{6.8}\\] If we introduce functions \\[\nL_0(x) = \\frac{x-x_1}{x_0-x_1}, \\quad L_1(x) = \\frac{x-x_0}{x_1-x_0},\n\\tag{6.9}\\] then we can write Eq. 6.7 as the polynomial \\(P\\) can be written as \\[\nP(x) = f(x_0)L_0(x) + f(x_1)L_1(x).\n\\tag{6.10}\\] Note that functions \\(L_0(x)\\) and \\(L_1(x)\\) have the property that \\[\nL_0(x_0)=1=L_1(x_1), \\quad L_0(x_1)=0=L_1(x_0).\n\\tag{6.11}\\] This property ensures that \\(P(x)\\), given by Eq. 6.7, satisfies the required conditions \\(P(x_0)=f(x_0)\\) and \\(P(x_1)=f(x_1)\\). Indeed, \\[\n\\begin{split}\nP(x_0)&=f(x_0)L_0(x_0) + f(x_1)L_1(x_0)=f(x_0)\\cdot 1 + f(x_1)\\cdot 0 = f(x_0), \\\\\nP(x_1)&=f(x_0)L_0(x_1) + f(x_1)L_1(x_1)=f(x_0)\\cdot 0 + f(x_1)\\cdot 1 = f(x_1).\n\\end{split}\n\\tag{6.12}\\]\nLet us now consider the general case. We construct a polynomial of degree at most \\(n\\) that passes through the \\((n+1)\\) points \\((x_0, f(x_0))\\), \\((x_1, f(x_1))\\), …, \\((x_n, f(x_n))\\). As a first step, we need a generalization of the functions \\(L_0\\) and \\(L_1\\) above; namely, we are looking for polynomials \\(L_0,\\ldots,L_n\\) of degree \\(n\\) such that \\[\nL_k(x_i)=\\delta_{ik} = \\left\\{\n\\begin{array}{ll}\n0 &\\text{  if } \\ i\\neq k, \\\\\n1 &\\text{  if } \\ i=k.\n\\end{array}\\right.\n\\tag{6.13}\\]\n(The definition of these \\(L_k\\) also depends on \\(x_0,\\ldots,x_n\\), and in particular on \\(n\\). For ease of reading, we do not indicate this dependence explicitly.)\nA short computation shows that polynomials with this property are given by \\[\nL_k(x)=\\prod_{i=0, i\\neq k}^{n} \\frac{x-x_i}{x_k-x_i}.\n\\tag{6.14}\\] We then set \\[\nP(x) = \\sum_{j=0}^n f(x_j) L_j(x).\n\\tag{6.15}\\] This is indeed a suitable interpolating polynomial. In fact it is the only possible interpolating polynomial, as the following theorem shows.\n\nTheorem 6.2 (Lagrange interpolating polynomial) Suppose that \\(x_0, x_1, \\ldots, x_n\\in\\mathbb{R}\\) are distinct numbers in the domain of a function \\(f\\). There exists a unique polynomial \\(P\\) with \\(\\deg P \\leq n\\) such that \\[\nf(x_k)=P(x_k) \\quad \\text{for all } k=0, 1, \\ldots, n.\n\\tag{6.16}\\] This polynomial, called the \\(n^\\text{th}\\) Lagrange interpolating polynomial, is given by Eq. 6.15, where the functions* \\(L_k(x)\\) are given by Eq. 6.14.\n\n\nProof. It is evident from Eq. 6.14–Eq. 6.15 that \\(\\deg P \\leq n\\). Moreover, by Eq. 6.13, we have for \\(k=0,\\ldots,n\\) \\[\nP(x_k)=\\sum_{j=0}^{n}f(x_{j})L_{j}(x_k) = \\sum_{j=0}^{n}f(x_{j})\\delta_{jk} = f(x_k).\n\\tag{6.17}\\] The only remaining point is uniqueness. Suppose that \\(P\\) and \\(\\hat P\\) are two interpolating polynomials with degree at most \\(n\\). Then \\[\nQ(x):=P(x)-\\hat P(x)\n\\tag{6.18}\\] is another polynomial, and \\(\\deg Q\\leq n\\). However, since \\[\nP(x_k)=f(x_k)=\\hat P (x_k) \\quad\\text{for all }k=0,\\ldots,n,\n\\tag{6.19}\\] we know that \\(Q\\) has \\(n+1\\) zeros, namely \\(x_0,\\ldots,x_n\\). This contravenes the Fundamental Theorem of Algebra, and so the only possibility is \\(Q=0\\), whence \\(P=\\hat P\\). ◻\n\n\nExample 6.1 The values of a function \\(f\\) are given in the table:\n\n\n\n\n\\(k\\)\n\\(x_k\\)\n\\(f(x_k)\\)\n\n\n\n\n0\n-1\n-1\n\n\n1\n1\n3\n\n\n2\n2\n8\n\n\n\n\nLet us construct the Lagrange interpolating polynomial of degree 2 for this data. From Eq. 6.14 we have \\[\n\\begin{split}\nL_0(x)&=\\frac{(x-x_1)(x-x_2)}{(x_0-x_1)(x_0-x_2)}\n=\\frac{(x-1)(x-2)}{(-1-1)(-1-2)}=\n\\tfrac{1}{6}(x^2-3x+2),\\\\\nL_1(x)&=\\frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)}\n=\\frac{(x+1)(x-2)}{(1+1)(1-2)}=\n-\\tfrac{1}{2}(x^2-x-2),\\\\\nL_2(x)&=\\frac{(x-x_0)(x-x_1)}{(x_2-x_0)(x_2-x_1)}\n=\\frac{(x+1)(x-1)}{(2+1)(2-1)}=\\tfrac{1}{3}(x^2-1).\n\\end{split}\n\\tag{6.20}\\] Hence \\[\n\\begin{split}\nP(x)&=\\sum_{j=0}^2f(x_{j})L_{j}(x) \\\\\n&=-1\\cdot\\tfrac{1}{6}(x^2-3x+2)-3\\cdot\\tfrac{1}{2}(x^2-x-2)+8\\cdot\\tfrac{1}{3}(x^2-1) \\\\\n&=x^2+2x.\n\\end{split}\n\\tag{6.21}\\]\n\nAbove we have constructed the polynomial \\(P\\) to interpolate the values of a function \\(f\\) at the points \\(x_0,\\ldots,x_n\\). But is \\(P\\) also a good approximation to \\(f\\) between these points? The theorem below gives an answer.\n\nTheorem 6.3 (Error term for interpolating polynomials) Suppose that \\(x_0, \\ldots, x_n\\) are distinct numbers in the interval \\([a, b]\\) and that \\(f\\in C^{n+1}[a, b]\\). Then, for each \\(x\\in[a, b]\\), there exists a number \\(\\xi\\in (a, b)\\) such that \\[\nf(x)=P(x)+\\frac{f^{(n+1)}(\\xi)}{(n+1)!} \\prod_{k=0}^n(x-x_k),\n\\tag{6.22}\\] where \\(P\\) is the \\(n^\\text{th}\\) interpolating polynomial.\n\n\nProof. We use Rolle’s theorem in this proof. Rolle’s theorem states that, if \\(h \\in C^1[c,d]\\) with \\(h(c)=h(d)=0\\), then there exists \\(x \\in (c,d)\\) such that \\(h'(x)=0\\).\nIf \\(x=x_k\\) for some \\(k\\), then \\(f(x_k)=P(x_k)\\) and Eq. 6.22 holds for any choice of \\(\\xi\\). Therefore for the rest of this proof we assume that \\[\nx \\neq x_k \\quad\\text{for all }k=0, \\ldots, n.\n\\tag{6.23}\\] Define the function \\[\ng(t):=f(t)-P(t)-[f(x)-P(x)]\\prod_{i=0}^{n}\\frac{t-x_i}{x-x_i}\\quad \\text{for }t\\in [a, b].\n\\] {eq-error-function-zeros} Since \\(f\\in C^{n+1}[a, b]\\), \\(P\\in C^{\\infty}[a, b]\\) and in view of Eq. 6.23, it follows that \\(g\\in C^{n+1}[a, b]\\). Applying \\(g\\) at \\(t=x\\) and at \\(t=x_k\\) for \\(k=0,\\ldots,n\\), we obtain \\[\n\\begin{split}\ng(x)&=f(x)-P(x)-[f(x)-P(x)]\\prod_{i=0}^{n}\\frac{x-x_i}{x-x_i}=0,\\\\\ng(x_k)&=f(x_k)-P(x_k)-[f(x)-P(x)]\\prod_{i=0}^{n}\\frac{x_k-x_i}{x-x_i}=0.\n\\end{split}\n\\tag{6.24}\\] Thus \\(g\\in C^{n+1}[a, b]\\) and \\(g\\) has \\(n+2\\) distinct zeros at \\(x, x_0, x_1, \\ldots, x_n\\). Applying Rolle’s theorem to each of the \\(n+1\\) subintervals between these zeros, it follows that the derivative \\(g'\\in C^n[a, b]\\) has at least \\(n+1\\) zeros in \\([a,b]\\). Again applying Rolle’s theorem, the second derivative \\(g''\\in C^{n-1}[a, b]\\) has at least \\(n\\) zeros in \\([a,b]\\). Applying the same argument to successive derivatives of \\(g\\), it follows finally that the \\((n+1)^\\text{th}\\) derivative \\(g^{(n+1)}\\) has at least one zero, which we call \\(\\xi\\). This means that \\[\n0=g^{(n+1)}(\\xi)=f^{(n+1)}(\\xi)-P^{(n+1)}(\\xi)-(f(x)-P(x)) \\left.\\frac{d^{n+1}}{dt^{n+1}}\\prod_{i=0}^{n}\\frac{t-x_i}{x-x_i}\\right\\rvert_{t=\\xi}.\n\\tag{6.25}\\] Considering each of the elements of this equation in turn, we have \\(P^{(n+1)}(\\xi)=0\\) as \\(\\deg P \\leq n\\). Also, we have \\[\n\\frac{d^{n+1}}{dt^{n+1}}\\prod_{i=0}^{n}\\frac{t-x_i}{x-x_i}= \\frac{d^{n+1}}{dt^{n+1}}\\frac{t^{n+1}}{\\prod_{i=0}^{n}(x-x_i)}= \\frac{(n+1)!}{\\prod_{i=0}^{n}(x-x_i)}.\n\\tag{6.26}\\] Substituting this into Eq. 6.25, we obtain the equation \\[\n0=f^{(n+1)}(\\xi)-(f(x)-P(x))\\frac{(n+1)! }{ \\prod_{i=0}^{n}(x-x_i)},\n\\tag{6.27}\\] which is equivalent to Eq. 6.25. ◻\n\n\nExample 6.2 Let \\[\nf(x)=\\frac{1}{x}.\n\\tag{6.28}\\] The interpolating polynomial determined by the values of \\(f\\) at the points \\(x_0=2.0\\), \\(x_1=2.5\\) and \\(x_2=4\\) is given by \\[\nP(x) = \\tfrac{1}{20}x^2-\\tfrac{17}{40}x+\\tfrac{23}{20}.\n\\tag{6.29}\\]\nLet us obtain the theoretical bound for the error of approximation of \\(f(3)\\) by \\(P(3)\\). We have \\[\n\\vert f^{\\prime\\prime\\prime}(\\xi)\\vert =\n\\left\\lvert-\\frac{6}{\\xi^{4}}\\right\\rvert\\leq \\frac{3}{8} \\quad \\text{for all } \\xi\\in[2, 4].\n\\tag{6.30}\\] Therefore, \\[\n\\vert f(3)-P(3)\\vert\\leq\n\\max_{\\xi\\in[2,4]}\\left\\lvert \\frac{f^{\\prime\\prime\\prime}(\\xi)}{3!}\n(3-2)(3-2.5)(3-4) \\right\\rvert \\leq \\frac{1}{32}=0.03125 .\n\\tag{6.31}\\] The actual error of this approximation is \\[\nE=\\vert f(3)- P(3)\\vert=\\frac{1}{3}-0.325=0.008333\\dots,\n\\tag{6.32}\\] which is smaller than our theoretical bound (as one would expect).\nNow let us evaluate the error involved in approximating \\(f\\) by \\(P\\) on the whole interval \\([2, 4]\\). Again using Eq. 6.30, we have \\[\n\\begin{split}\n\\vert f(x)-P(x)\\vert &\\leq\n\\max_{\\xi\\in[2,4]}\\left\\lvert \\frac{f^{\\prime\\prime\\prime}(\\xi)}{3!}\n(x-2)(x-2.5)(x-4) \\right\\rvert \\\\\n&\\leq \\frac{1}{16} \\,\n\\vert \\phi(x)\\vert \\leq\n\\frac{1}{16} \\, \\max_{x\\in[2,4]}\n\\vert \\phi(x)\\vert,\n\\end{split}\n\\tag{6.33}\\] where \\[\n\\phi(x):=(x-2)(x-2.5)(x-4)\\quad\\text{for }x\\in[2,4].\n\\tag{6.34}\\] The function \\(\\phi\\) has a maximum at \\(x':=\\tfrac{17}{6}-\\tfrac{\\sqrt{13}}{6}\\approx 2.232\\), with \\(\\phi(x')\\approx0.110\\), and a minimum at \\(x'':=\\tfrac{17}{6}+\\tfrac{\\sqrt{13}}{6}\\approx 3.434\\), where \\(\\phi(x'')\\approx-0.758\\). By Eq. 6.33 we obtain \\[\n\\vert f(x)-P(x)\\vert\\leq \\frac{\\vert\\phi(x'')\\vert}{ 16}\\approx 0.048.\n\\tag{6.35}\\]\nFinally, let us add one more point to our data, say, \\(x_3=3.5\\). Then the polynomial interpolating the values of \\(f\\) at the four points \\(x_0=2\\), \\(x_1=2.5\\), \\(x_2=4\\) and \\(x_3=3.5\\) is given by \\[\nP(x) = -\\tfrac{1}{70}x^3+\\tfrac{6}{35}x^2-\\tfrac{211}{280}x+\\tfrac{201}{140}.\n\\tag{6.36}\\] In this case, \\(P(3)=\\tfrac{93}{280}\\) and the actual error is \\[\n\\lvert f(3)- P(3)\\rvert = \\left\\lvert\\tfrac{1}{3} - \\tfrac{93}{280}\\right\\rvert = \\tfrac{1}{840} \\approx 0.0012.\n\\tag{6.37}\\] This is almost 8 times smaller than the error of the interpolating polynomial based on the original three points.\n\nFurther reading: Section 3.1 of (Burden and Faires 2010).\n\n\n6.1.2 Divided differences\nAs we saw in Theorem 6.2, the interpolating polynomial (of minimal degree) for a function at distinct points \\(x_0, x_1, \\ldots, x_n\\) is unique. However, it can be rewritten in many different ways. The Lagrange form Eq. 6.15 may not always be the optimal one for numerical purposes, since computing its value requires a large number of multiplications. Here we present an alternative form of the same polynomial, known as the Newton form.\nLet us illustrate the idea again in the case of a linear polynomial, interpolating a function \\(f\\) between two points \\(x_0\\) and \\(x_1\\). It seems natural to write this straight line in the form  \\[\nf(x_0) + m (x-x_0)\n\\tag{6.38}\\] with slope \\(m=\\frac{f(x_1)-f(x_0)}{x_1-x_0}\\). We thus arrive at \\[\n   P(x) = f(x_0) + \\frac{f(x_1)-f(x_0)}{x_1-x_0} (x-x_0).\n\\tag{6.39}\\] Indeed, one checks that \\(P(x_0)=f(x_0)\\), \\(P(x_1)=f(x_1)\\), and so this is the unique interpolating polynomial between these points. The slope \\(\\frac{f(x_1)-f(x_0)}{x_1-x_0}\\), which looks a bit like the derivative of \\(f\\), is called the \\(1^\\text{st}\\) divided difference and we write \\[\nf[x_0,x_1]:=\\frac{f(x_1)-f(x_0)}{x_1-x_0}.\n\\tag{6.40}\\]\nHow does this generalize to higher-order polynomials? It turns out that the second-order interpolating polynomial through the points \\(x_0,x_1,x_2\\) is given by \\[\n\\begin{split}\n   P(x) = f(x_0) &+ \\frac{f(x_1)-f(x_0)}{x_1-x_0} (x-x_0) +\\\\\n   &+ \\underbrace{\\dfrac{\\dfrac{f(x_2)-f(x_1)}{x_2-x_1}-\\dfrac{f(x_1)-f(x_0)}{x_1-x_0}}{x_2-x_0}}_{=:f[x_0,x_1,x_2]} (x-x_0)(x-x_1).\n\\end{split}\n\\tag{6.41}\\] (It is clear that \\(P(x_0)=f(x_0)\\), \\(P(x_1)=f(x_1)\\), and some computation yields \\(P(x_2)=f(x_2)\\).) The term \\(f[x_0,x_1,x_2]\\) is called the \\(2^\\text{nd}\\) divided difference and reminds one of the second derivative.\nLet us define these concepts more generally. We introduce the \\(0^\\text{th}\\) divided difference as \\[\nf[x_i]:=f(x_i),\n\\tag{6.42}\\] and then define the \\(k^\\text{th}\\) divided difference recursively as \\[\nf[x_i, x_{i+1}, \\ldots, x_{i+k}]:=\\frac{f[x_{i+1}, x_{i+2},\\ldots, x_{i+k}]-\nf[x_i,x_{i+1}, \\ldots, x_{i+k-1}]}{x_{i+k}-x_i}.\n\\tag{6.43}\\] This agrees with the examples above.\nWe now claim that all interpolating polynomials can be written in terms of divided differences, in generalization of equations Eq. 6.39 and Eq. 6.41.\n\nTheorem 6.4 Let \\(P\\) be the \\(n^\\text{th}\\) order interpolating polynomial for a function \\(f\\) at the points \\(x_0,\\ldots,x_n\\). It holds that \\[\nP(x) = \\sum_{k=0}^{n} f[x_0, x_1, \\ldots, x_k] \\prod_{0 \\leq j &lt; k} (x-x_j) .\n\\tag{6.44}\\]\n\nThis relation is known as Newton’s divided-difference formula. Note that an empty product is defined to be equal to \\(1\\), so in the \\(k=0\\) term in Eq. 6.44 the factor \\(\\prod_{0 \\leq j &lt; 0} (x-x_0)=1\\) , so the first term in the sum is \\(f[x_0]\\).\n\nProof. We use induction on \\(n\\). For \\(n=0\\), we have \\(P(x)=f(x_0)=f[x_0]\\) and Eq. 6.44 holds. Now suppose that Eq. 6.44 is already known for \\(n-1\\) in place of \\(n\\). Denote by \\(\\hat P\\) the interpolating polynomial through \\(x_0,\\ldots,x_{n-1}\\), and with \\(\\check P\\) the interpolating polynomial through \\(x_1,\\ldots,x_n\\). By the induction hypothesis, \\[\n\\begin{split}\n\\hat P(x) &= \\sum_{k=0}^{n-1} f[x_0, x_1, \\ldots, x_k] \\prod_{0 \\leq j &lt; k} (x-x_j),\\\\\n\\check P(x) &= \\sum_{k=1}^n f[x_1, x_2, \\ldots, x_k] \\prod_{1 \\leq j &lt; k} (x-x_j).\n\\end{split}\n\\tag{6.45}\\]\nLet \\(P\\) be the interpolating polynomial for \\(f\\) at \\(x_0,\\ldots,x_n\\). We first prove that \\[\nP(x) = \\frac{(x-x_0) \\check P(x) - (x-x_n) \\hat P(x) }{x_n-x_0}.\n\\tag{6.46}\\] Indeed, one verifies the equality at \\(x=x_0\\), and \\(x=x_1,\\ldots,x_{n-1}\\), and at \\(x=x_n\\) by a short computation in each case. Then Eq. 6.46 holds in generality due to the uniqueness of the interpolating polynomial (established in Theorem 6.2).\nNow we compute the leading order coefficient \\(c_n\\) of \\(P\\), i.e., the constant \\(c_n\\) such that \\(P(x)= c_n x^n + \\text{lower order terms}\\). From Eq. 6.45, Eq. 6.46 one can directly read off that \\[\nc_n = \\frac{ f[x_1,\\ldots, x_n] - f[x_0, \\ldots, x_{n-1}] }{x_n-x_0} = f[x_0,\\ldots, x_n].\n\\tag{6.47}\\]\nFinally, let us define \\[\nQ(x) := P(x) - f[x_0,\\ldots, x_n](x-x_0) \\cdots (x-x_{n-1}).\n\\tag{6.48}\\] This \\(Q\\) is a polynomial of at most order \\(n-1\\), since the leading coefficients of the two summands cancel. Also, \\(Q(x_i)=P(x_i)=f_i\\) for all \\(0 \\leq i &lt; n\\). Uniqueness of the interpolating polynomial Theorem 6.2 implies \\(Q(x)=\\hat P(x)\\). This yields \\[\n\\begin{split}\n  P(x) &= \\hat P(x) + f[x_0,\\ldots, x_n](x-x_0) \\cdots (x-x_{n-1}) \\\\\n  &= \\sum_{k=0}^{n} f[x_0, x_1, \\ldots, x_k] \\prod_{0 \\leq j &lt; k} (x-x_j)\n\\end{split}\n\\tag{6.49}\\] by Eq. 6.45, which completes the proof. ◻\n\n\nRemark. Note that nowhere in the proof we had to use that the interpolation points \\(x_i\\) had to be arranged in increasing order.\n\nWriting the interpolating polynomial in terms of divided differences has several advantages:\n\nThe polynomial requires fewer algebraic operations to evaluate. In fact, one might rewrite it as \\[\nP(x) = f(x_0) + (x-x_0) \\big( f[x_0,x_1] + (x-x_1)\\big( f[x_0,x_1,x_2] + \\ldots\n\\tag{6.50}\\]\nIf extra precision is required, it is easy to add an extra interpolation point \\(x_{n+1}\\) without recomputing the lower-order divided differences.\nWe can see from Eq. 6.44 that, if the \\(k^\\text{th}\\) divided difference is constant, this means that the degree of the interpolating polynomial is \\(k\\) (because higher divided differences are all zero), so that we do not need to use all the data in the table (\\(k+1\\) points will be enough).\nThe divided differences can be computed easily (by hand or with a computer) in a simple scheme, as shown in the next example.\n\n\nExample 6.3 Suppose that the values of a function \\(f\\) at \\(7\\) points are as in Table 6.1. The remaining columns of that table illustrates how the divided differences are calulated.\n\n\n\n\nTable 6.1: Numerical example for divided difference method\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x\\)\n\\(f[x]\\)\n\\(f[ , ]\\)\n\\(f[ , , ]\\)\n\\(f[ , , , ]\\)\n\\(f[ , , , , ]\\)\n\n\n\n\n\n-1\n-2\n\n\n\n\n\n\n\n\n\n3\n\n\n\n\n\n\n0\n1\n\n0\n\n\n\n\n\n\n\n3\n\n1\n\n\n\n\n1\n4\n\n3\n\n0\n\n\n\n\n\n9\n\n1\n\n\n\n\n2\n13\n\n6\n\n0\n\n\n\n\n\n21\n\n1\n\n\n\n\n3\n34\n\n9\n\n0\n\n\n\n\n\n39\n\n1\n\n\n\n\n4\n73\n\n12\n\n\n\n\n\n\n\n63\n\n\n\n\n\n\n5\n136\n\n\n\n\n\n\n\n\n\n\n\n\nThe third divided difference is constant, so the interpolating polynomial is cubic. We obtain \\[\n\\begin{split}\nP(x) &= f[x_0]+f[x_0,x_1](x-x_0)+f[x_0,x_1,x_2](x-x_0)(x-x_1)\\\\\n&\\qquad +f[x_0,x_1,x_2,x_3](x-x_0)(x-x_1)(x-x_2)  \\\\\n&= -2+3 (x+1)+0(x+1)x+(x+1)x(x-1)=x^3+2x+1.\n\\end{split}\n\\tag{6.51}\\]\n\nFurther reading: Section 3.3 of (Burden and Faires 2010).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Approximation and interpolation</span>"
    ]
  },
  {
    "objectID": "chapter06.html#cubic-spline-interpolation",
    "href": "chapter06.html#cubic-spline-interpolation",
    "title": "6  Approximation and interpolation",
    "section": "6.2 Cubic spline interpolation",
    "text": "6.2 Cubic spline interpolation\nIn the previous sections we considered the approximation of arbitrary functions on closed intervals using a single polynomial. However, this does not always lead to satisfactory approximations because high-degree polynomials can oscillate erratically, and the error bounds can become large if the derivatives of the approximated functions are not bounded. An alternative approach is to divide the approximation interval into a collection of subintervals and construct a (generally) different approximating polynomial on each subinterval. This is called piecewise-polynomial approximation.\nIn this section we consider a function \\(f\\) defined at the points \\(x_0,\\ldots,x_n\\). In contrast to the previous sections, we assume here that \\[\nx_0 &lt; x_1 &lt; \\cdots &lt; x_n.\n\\tag{6.52}\\]\nThe simplest such piecewise-polynomial approximation is linear interpolation, which consists of joining the data points \\((x_0,f(x_0)), (x_1,f(x_1)), \\ldots, (x_n,f(x_n))\\) by a series of straight lines, i.e. the interpolating function \\(S\\) satisfies \\[\nS(x) =\n\\begin{cases}\nf(x_0) + \\frac{f(x_1)-f(x_0)}{x_1-x_0} (x-x_0) &\\text{for }x\\in[x_0,x_1],\\\\\nf(x_1) + \\frac{f(x_2)-f(x_1)}{x_2-x_1} (x-x_1) &\\text{for }x\\in[x_1,x_2], \\\\\n\\vdots\\\\\nf(x_{n-1}) + \\frac{f(x_n)-f(x_{n-1})}{x_n-x_{n-1}} (x-x_{n-1}) &\\text{for }x\\in[x_{n-1},x_n].\n\\end{cases}\n\\tag{6.53}\\] Linear interpolation is simple, but it has the disadvantage that the interpolating function \\(S\\) is generally not differentiable at the interpolation points \\(x_1,\\ldots,x_{n-1}\\).\nThe most common piecewise-polynomial approximation uses cubic polynomials between each successive pair of nodes and is called cubic spline interpolation. We will discuss this here only in the context of approximating functions, but splines more generally can approximate curves in the plane or in higher dimensions. This is useful for example for applications in digital art. For a very good introduction to splines in this context, see this YouTube video.\n\nDefinition 6.1 (Cubic spline interpolant) A cubic spline interpolant \\(S\\) for a function \\(f\\) with known values at points \\(x_0 &lt; x_1 &lt; \\cdots &lt; x_n\\) is a twice continuously differentiable function on \\([x_0,x_n]\\) (i.e. \\(S\\in C^{2}[x_0,x_n]\\)) such that it is equal to a cubic polynomial, denoted \\(S_k\\), on the interval \\([x_{k-1},x_{k}]\\) for each \\(k=1,\\ldots,n\\) and \\(S(x_k)=f(x_k)\\) for \\(k=0,\\ldots,n\\).\n\nThis definition implies that \\[\nS_{i}(x)=a_{i}+b_{i}(x-x_{i})+c_{i}(x-x_{i})^{2} +d_{i}(x-x_{i})^{3}\n\\tag{6.54}\\] for \\(x\\in [x_{i-1}, x_{i}]\\) (\\(i=1, 2, \\dots, n\\)) and that \\(S_i\\) satisfy the following requirements:\n\\[S(x_{i})=f_{i} \\text{ for } i=0, 1, \\dots, n; \\tag{6.55}\\]\n\\[S_{i}(x_{i})=S_{i+1}(x_{i}) \\text{ for } i=1, 2, \\dots, n-1; \\tag{6.56}\\]\n\\[S^{\\prime}_{i}(x_{i})=S^{\\prime}_{i+1}(x_{i}) \\text{ for } i=1, 2, \\dots, n-1; \\tag{6.57}\\]\n\\[S^{\\prime\\prime}_{i}(x_{i})= S^{\\prime\\prime}_{i+1}(x_{i}) \\text{ for } i=1, 2, \\dots, n-1. \\tag{6.58}\\]\nIt is not obvious a priori that such an interpolant exists, or, if so, that it is unique. We have \\(4n\\) unknown coefficients \\(a_{i}\\), \\(b_{i}\\), \\(c_{i}\\), \\(d_{i}\\) (\\(i=1, 2, \\dots, n\\)). Condition 6.55 gives \\(n+1\\) equations. Conditions 6.56, 6.57, 6.58 give \\(3(n-1)\\) equations. Thus, we have \\(n+1+3(n-1)=4n-2\\) equations for \\(4n\\) unknowns. So, we need to specify two more conditions to define \\(S(x)\\) uniquely. Common choices are:\n\n\\(S^{\\prime\\prime}(x_{0})=S^{\\prime\\prime}(x_{n})=0\\) (natural cubic spline);\n\\(S^{\\prime}(x_{0})=f^{\\prime}(x_{0})\\), \\(S^{\\prime}(x_{n})=f^{\\prime}(x_{n})\\) (clamped cubic spline).\n\nNatural cubic spline. Let \\(h_{i}=x_{i}-x_{i-1}\\). Condition 6.55 gives \\[\na_{i}=f_{i} \\quad \\text{  for }\\quad i=1, 2, \\dots, n\n\\tag{6.59}\\] and \\[\na_{1}-b_{1}h_1+c_{1}h_1^{2} -d_{1}h_1^{3}=f_0 .\n\\tag{6.60}\\] Condition 6.56 gives \\[\na_{i}=a_{i+1}-b_{i+1}h_{i+1}+c_{i+1}h_{i+1}^{2}- d_{i+1}h_{i+1}^{3} \\quad \\text{  for }\\quad i=1, 2, \\dots, n-1.\n\\tag{6.61}\\] Condition 6.57 gives \\[\nb_{i}=b_{i+1}-2c_{i+1}h_{i+1}+3d_{i+1}h_{i+1}^{2} \\quad \\text{  for }\\quad i=1, 2, \\dots, n-1.\n\\tag{6.62}\\] Condition 6.58 gives \\[\n2c_{i}=2c_-6d_{i+1}h_{i+1} \\quad \\text{  for }\\quad i=1, 2, \\dots, n-1.\n\\tag{6.63}\\] It follows from Eq. 6.63 that \\[\nd_{i}=\\frac{c_{i}-c_{i-1}}{3h_{i}} \\quad \\text{  for }\\quad i=2, \\dots, n.\n\\tag{6.64}\\] From the (endpoint) conditions \\(S^{\\prime\\prime}(x_{0})=S^{\\prime\\prime}(x_{n})=0\\) (corresponding to the natural cubic spline), it follows that \\[\nd_{1}=\\frac{c_{1}}{3h_{1}} \\quad \\text{  and } \\quad c_{n}=0.\n\\tag{6.65}\\] It follows from Eq. 6.61 that \\[\nb_{i+1}=\\frac{a_{i+1}-a_{i}+c_{i+1}h_{i+1}^{2}\n-d_{i+1}h_{i+1}^{3}}{h_{i+1}} \\quad \\text{  for }\\quad i=1, 2, \\dots, n-1. \\] and \\[\nb_{i}=\\frac{a_{i}-a_{i-1}+c_{i}h_{i}^{2}\n-d_{i}h_{i}^{3}}{h_{i}} \\quad \\text{  for }\\quad i=2, 3, \\dots, n,\n\\tag{6.66}\\] so that \\[\nb_{i+1}-b_{i}=\\frac{a_{i+1}-a_{i}}{h_{i+1}}- \\frac{a_{i}-a_{i-1}}{h_{i}}+c_{i+1}h_{i+1}-c_{i}h_{i} -d_{i+1}h_{i+1}^{2}+d_{i}h_{i}^{2} \\] for \\(i= 2, \\dots, n-1\\). Substituting this into Eq. 6.62 and using Eq. 6.59 and Eq. 6.64 we find that \\[\n\\begin{split}\nh_{i}c_{i-1}+2(h_{i}+h_{i+1})c_{i}+h_{i+1}c_{i+1}&= 3\n\\left(\\frac{f_{i+1}-f_{i}}{h_{i+1}}-\n\\frac{f_{i}-f_{i-1}}{h_{i}}\\right)\\\\\n&= 3(f[x_{i},x_{i+1}]-f[x_{i-1},x_{i}]) \\\\\n&=3(h_{i}+h_{i+1})f[x_{i-1},x_{i},x_{i+1}]\n\\end{split}\n\\tag{6.67}\\] for \\(i= 2, \\dots, n-1\\). Thus, we have obtained \\(n-2\\) linear equations for \\(n-1\\) unknowns \\(c_{1}, \\dots, c_{n-1}\\) (we already know that \\(c_{n}=0\\)). One more equation is obtained as follows. First, the condition \\(S(x_{0})=S_{1}(x_{0})=f_{0}\\) and Eq. 6.65 yield \\[\nb_{1}=\\frac{f_{1}-f_{0}}{h_{1}}+\\frac{2}{3}h_{1}c_{1}.\n\\tag{6.68}\\] On substituting this into Eq. 6.62 for \\(i=1\\) and using Eq. 6.66 for \\(i=2\\), we obtain \\[\n2(h_{1}+h_{2})c_{1}+h_{2}c_{2}=3 \\left(\\frac{f_{2}-f_{1}}{h_{2}}- \\frac{f_{1}-f_{0}}{h_{1}}\\right)=3(h_{1}+h_{2})f(x_{0},x_{1},x_{2}) .\n\\tag{6.69}\\] Eq. 6.67, Eq. 6.69 can be written as \\[\n\\left(\n\\begin{array}{ccccccc}\n          A_{1} &h_{2} &0     &\\dots &\\dots &0 \\\\\n          h_{2} &A_{2} &h_{3} & & &\\vdots \\\\\n          0     &\\ddots &\\ddots &\\ddots & &\\vdots \\\\\n          \\vdots & &\\ddots  &\\ddots &\\ddots &0 \\\\\n          \\vdots  & &  &h_{n-2} &A_{n-2} &h_{n-1} \\\\\n          0 &\\dots &\\dots &0  &h_{n-1} &A_{n-1}\n\\end{array}\n\\right) \\left(\n\\begin{array}{c}\n          c_{1} \\\\\n          c_{2} \\\\\n          \\vdots \\\\\n          \\vdots \\\\\n          \\vdots \\\\\n          c_{n-2} \\\\\n          c_{n-1}\n\\end{array}\n\\right)=3 \\left(\n\\begin{array}{c}\n          F_{1} \\\\\n          F_{2} \\\\\n          \\vdots \\\\\n          \\vdots \\\\\n          \\vdots \\\\\n          F_{n-2} \\\\\n          F_{n-1}\n\\end{array}\n\\right),\n\\tag{6.70}\\] where \\[\nA_{i}=2(h_{i}+h_{i+1}) \\quad \\text{  and } \\quad F_{i}=(h_{i}+h_{i+1})f(x_{i-1},x_{i},x_{i+1})\n\\tag{6.71}\\] for \\(i=1,\\dots, n-1\\) The matrix of this system is symmetric and tridiagonal. Moreover, it is strictly diagonally dominant. So, it can be solved numerically using both Gaussian elimination and iterative techniques.\nWhen \\(c_{1}, \\dots, c_{n}\\) are known, coefficients \\(d_{1}\\dots, d_{n}\\) and \\(b_{1}\\dots, b_{n}\\) can be determined using Eq. 6.64, Eq. 6.65, Eq. 6.66, Eq. 6.68, Eq. 6.69.\n\nExample 6.4 Let us compute the natural spline for the function \\(f\\) given in Table 6.2.\n\n\n\n\n\nTable 6.2: Numerical example for spline interpolation\n\n\n\n\n\n\\(k\\)\n\\(x_k\\)\n\\(f(x_k)\\)\n\n\n\n\n0\n0.0\n\n\n\n1\n0.5\n\n\n\n2\n1.0\n-1\n\n\n3\n1.5\n\n\n\n4\n2.0\n\n\n\n\n\n\n\n\n\nFrom Eq. 6.59, we obtain \\[\na_1=0, \\ \\ a_2=-1, \\ \\ a_3=0, \\ \\ a_4=1 .\n\\tag{6.72}\\] Also, we have \\[\n\\begin{aligned}\nF_1 &= 0, & F_2 &= 12, & F_3 &= 0.\n\\end{aligned}\n\\tag{6.73}\\] We then need to solve the system \\[\n\\begin{pmatrix}\n2 & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 2 & \\frac{1}{2}  \\\\\n0 & \\frac{1}{2} & 2\n\\end{pmatrix}\n\\begin{pmatrix}\nc_1 \\\\ c_2 \\\\ c_3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0\\\\\n12\\\\\n0\n\\end{pmatrix},\n\\tag{6.74}\\] which gives \\[\n\\begin{aligned}\nc_1 &= -\\frac{12}{7}, & c_2 &= \\frac{48}{7}, & c_3 &= -\\frac{12}{7}.\n\\end{aligned}\n\\tag{6.75}\\] We also have \\(c_4=0\\).\nSubstituting these into Eq. 6.64–Eq. 6.66, we find \\[\n\\begin{aligned}\nb_1 &= -\\frac{18}{7}, & b_2 &= 0, & b_3 &= \\frac{18}{7}, & b_4 &= \\frac{12}{7}, \\\\\nd_1 &=  -\\frac{8}{7}, & d_2 &= \\frac{40}{7}, & d_3 &=  -\\frac{40}{7}, & d_4 &= \\frac{8}{7}.\n\\end{aligned}\n\\tag{6.76}\\] which allows us to write the spline interpolant as \\[\nS(x) =\n\\begin{cases}\n-(8/7)x^3-(12/7)x+1 & \\text{if } x\\in[0,0.5),\\\\\n(40/7)x^3-(72/7)x^2+(24/7)x+1/7 & \\text{if } x\\in[0.5,1),\\\\\n-(40/7)x^3+24x^2-(216/7)x+81/7 & \\text{if } x\\in[1,1.5),\\\\\n(8/7)x^3-(48/7)x^2+(108/7)x-81/7 & \\text{if } x\\in[1.5,2].\n\\end{cases}\n\\tag{6.77}\\]\n\nFurther reading: Section 3.5 of (Burden and Faires 2010).\n\n\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical Analysis. 9th ed. Brooks Cole.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Approximation and interpolation</span>"
    ]
  },
  {
    "objectID": "chapter07.html",
    "href": "chapter07.html",
    "title": "7  Numerical integration",
    "section": "",
    "text": "7.1 Trapezium rule\nWe now discuss approximation algorithms for evaluating definite integrals. For many functions of practical relevance, their antiderivative is not explicitly known, so that integrating them is not possible in explicit terms. For example, an integral like \\[\n\\int_0^2 \\exp(-x^2)dx\n\\tag{7.1}\\] can be evaluated only by numerical approximation.\nThe basic method for approximating an integral of a function \\(f(x)\\) is called numerical quadrature and uses a formula of the form \\[\n\\int_a^bf(x)dx\\approx \\sum_{i=0}^nc_if(x_i),\n\\tag{7.2}\\] where \\(x_0,\\ldots,x_n\\) are nodes and \\(c_0,\\ldots,c_n\\) are weights. The nodes are chosen in the interval \\([a,b]\\) and the weights are chosen so that the formula is exact for polynomials of degree \\(n\\). The integral of a general function \\(f\\) is then approximated by the integral of the interpolating polynomial \\(P_n\\) of degree \\(n\\) through the nodes \\(x_0,\\ldots,x_n\\) of \\(f\\). In other words, the integral is replaced with a discrete sum of function values of \\(f\\) with certain numerical coefficients.\nFor a simple example, consider \\(\\int_a^bf(x)dx\\) for a nonnegative function \\(f\\); illustrated in Figure 7.1. The integral \\(\\int_a^bf(x)dx\\) corresponds to the area under the graph of \\(f\\) in the interval \\([a,b]\\). This region can be approximated by a trapezium through the points \\((a,0)\\), \\((a,f(a))\\), \\((b,f(b))\\), \\((b,0)\\). Computing the area of the trapezium, we obtain \\[\n\\int_a^bf(x)dx\\approx (b-a)\\frac{(f(a)+f(b))}{2}.\n\\tag{7.3}\\] This is the so-called Trapezium rule.\nWe motivated the Trapezium rule geometrically, but two question remain open at this point:\nWe will answer these questions by generalizing the Trapezium rule as follows. First, we select a collection of distinct points \\(x_0, x_1, \\ldots, x_n\\) from the interval \\([a,b]\\). Then, in generalization of the straight line that interpolated the function \\(f\\) in the Trapezium method, we construct the Lagrange interpolating polynomial (see Theorem 6.3) through \\(x_0,\\ldots,x_n\\) to obtain \\[\nf(x)=\\sum_{i=0}^nf(x_i)L_i(x) + R(x),\n\\tag{7.4}\\] where \\[\nR(x) = \\frac{f^{(n+1)}(\\xi(x))}{(n+1)!}\\prod_{i=0}^n\n(x-x_i)\n\\tag{7.5}\\] and \\(\\xi(x)\\in[a,b]\\) for each \\(x\\). Integrating this formula over \\([a, b]\\), we obtain \\[\n\\int_a^bf(x)dx=\\sum_{i=0}^nc_if(x_i) + E(f)\n\\tag{7.6}\\] where \\[\n\\begin{aligned}\nc_i&= \\int_a^b L_i(x)dx, &\nE(f)&=\\int_a^b R(x)\\,dx.\n\\end{aligned}\n\\tag{7.7}\\] The idea is that it is desirable for the error term \\(E(f)\\) to be small—more on that below.\nIt is usual to choose the nodes \\(x_0,\\ldots,x_n\\) equally spaced in the interval \\([a,b]\\), in other words, with \\(h=\\frac{1}{n}(b-a)\\), one sets \\[\nx_i := a + i h \\quad\\text{for }i=0,\\ldots,n.\n\\tag{7.8}\\] The construction above then yields the so called closed Newton-Cotes formulae for integration. Let us consider the cases of \\(n=1\\) (which corresponds to the Trapezium rule as above) and \\(n=2\\) in more detail.\nLet us now put \\(n=1\\), that is, we use interpolation by a straight line. Following the recipe from above, we have \\(h:=b-a\\), the nodes are \\(x_0=a\\) and \\(x_1=b\\), and we have the Lagrange polynomials \\[\n\\begin{split}\n   L_0(x) &= \\frac{x-x_1}{x_0-x_1} = -\\frac{1}{h}(x-b), \\\\\n   L_1(x) &= \\frac{x-x_0}{x_1-x_0} = \\frac{1}{h}(x-a).\n\\end{split}\n\\tag{7.9}\\] The constants \\(c_0,c_1\\) are then \\[\n\\begin{split}\nc_0 &= \\int_a^b L_0(x) dx = -\\frac{1}{h}\\int_a^b (x-b) dx \\\\\n&= -\\frac{1}{2h}\\left[(x-b)^2\\right]_{x=a}^b = \\frac{h}{2},\\\\\nc_1 &= \\int_a^b L_1(x) dx = \\frac{1}{h}\\int_a^b (x-a) dx \\\\\n&= \\frac{1}{2h}\\left[(x-a)^2\\right]_{x=a}^b = \\frac{h}{2}.\n\\end{split}\n\\tag{7.10}\\] The approximation formula Eq. 7.6 then gives \\[\n\\int_a^bf(x)dx \\approx \\frac{h}{2}(f(a)+f(b)),\n\\tag{7.11}\\] which is exactly the Trapezium rule.\nLet us now consider the error term \\(E(f)\\). We assume that \\(f\\in C^{2}[a,b]\\) and employ the formula for the error of the interpolation polynomial \\[\nf(x)=P(x)+\\frac{f^{\\prime\\prime}(\\xi(x))}{2!}(x-x_{0})(x-x_{1}).\n\\tag{7.12}\\] Since \\(f\\in C^{2}[a,b]\\), we have \\[\nm\\leq f^{\\prime\\prime}(x)\\leq M \\quad \\text{  for \\ all } \\ \\ x\\in[a,b],\n\\tag{7.13}\\] where \\[\nm=\\min_{x\\in[a,b]} f^{\\prime\\prime}(x), \\quad M=\\max_{x\\in[a,b]} f^{\\prime\\prime}(x) .\n\\tag{7.14}\\] Let \\[\nB(x)=-\\frac{(x-x_{0})(x-x_{1})}{2}.\n\\tag{7.15}\\] Evidently, \\(B(x)\\geq 0\\) for all \\(x\\in[a,b]\\). Therefore, it follows from Eq. 7.12 that \\[\nm \\, B(x) \\leq P(x)-f(x) \\leq M \\, B(x).\n\\tag{7.16}\\] Integration of these inequalities yields \\[\nm \\, \\int_{x_{0}}^{x_{1}} B(x)dx \\leq \\int_{x_{0}}^{x_{1}}\\left(P(x)-f(x)\\right)dx \\leq M \\, \\int_{x_{0}}^{x_{1}}B(x)dx.\n\\tag{7.17}\\] Since \\[\n\\begin{split}\n\\int_{x_{0}}^{x_{1}} B(x)dx &=\\frac{1}{2}\\int_{x_{0}}^{x_{1}}(x-x_{0})(x_{1}-x)dx \\\\\n&=\\frac{1}{2}\\int_{0}^{1}h \\, t \\, h (1-t) \\, h \\, dt\\\\\n&=\\frac{h^3}{2}\\left(\\frac{t^2}{2}-\\frac{t^3}{3}\\right)\\Biggm\\vert_{t=0}^{t=1}=\\frac{h^3}{12}.\n\\end{split}\n\\tag{7.18}\\] (here we have introduced new variable of integration \\(t\\) by the formula \\(x=x_{0}+t h\\)) Eq. 7.17 can we rewritten as \\[\nm  \\leq \\frac{12}{h^3}\\int_{x_{0}}^{x_{1}}\\left(P(x)-f(x)\\right)dx \\leq M .\n\\tag{7.19}\\] Since \\(f^{\\prime\\prime}(x)\\) is continuous in \\([a,b]\\), the intermediate value theorem says that there exists \\(\\xi\\in[a,b]\\) such that \\[\nf^{\\prime\\prime}(\\xi)=\\frac{12}{h^3}\\int_{x_{0}}^{x_{1}}\\left(P(x)-f(x)\\right)dx.\n\\tag{7.20}\\] This and the expression for the integral of \\(P(x)\\) give us the Trapezium rule with error term: \\[\n\\int_{x_{0}}^{x_{1}}f(x)dx = \\frac{h}{2}\\left(f(x_{0})+f(x_{1})\\right)-\\frac{h^3}{12}f^{\\prime\\prime}(\\xi).  \n\\tag{7.21}\\] We see that the error term can be controlled by an estimate of the second derivative of \\(f\\). Also, it will be small if \\(h\\) is small. Evidently, for a fixed interval \\([a,b]\\) we cannot vary \\(h\\) to reduce the error; we will return to this problem later.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Numerical integration</span>"
    ]
  },
  {
    "objectID": "chapter07.html#trapezium-rule",
    "href": "chapter07.html#trapezium-rule",
    "title": "7  Numerical integration",
    "section": "",
    "text": "Remark. It can be shown by direct calculation that the Trapezium rule produces an exact result for \\(f(x)=1\\), \\(f(x)=x\\) and, hence for any polynomial of degree \\(0\\) and \\(1\\). (Prove it!)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Numerical integration</span>"
    ]
  },
  {
    "objectID": "chapter07.html#simpsons-rule",
    "href": "chapter07.html#simpsons-rule",
    "title": "7  Numerical integration",
    "section": "7.2 Simpson’s rule",
    "text": "7.2 Simpson’s rule\nNow let us consider the case \\(n=2\\), which should yield a better approximation. We have \\(h=\\tfrac{1}{2}(b-a)\\), and our nodes are \\(x_0=a\\), \\(x_1=a+h\\), \\(x_2=a+2h=b\\). We first recall the polynomials \\(L_j\\): \\[\n\\begin{split}\n   L_0(x) &= \\frac{(x-x_1)(x-x_2)}{(x_0-x_1)(x_0-x_2)}=\\frac{1}{2h^2}(x-(a+h))(x-b), \\\\\n   L_1(x) &= \\frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)}=-\\frac{1}{h^2}(x-a)(x-b), \\\\\n   L_2(x) &= \\frac{(x-x_0)(x-x_1)}{(x_2-x_0)(x_2-x_1)}=\\frac{1}{2h^2}(x-a)(x-(a+h)).\n\\end{split}\n\\tag{7.22}\\] Their integrals are, with the same substitution \\(x=a+ht\\) as before (but now \\(0 \\leq t \\leq 2\\)), \\[\n\\begin{split}\nc_0=\\int_a^b L_0(x)\\,dx\n&=  \\frac{h}{2} \\int_0^2 (t-1)(t-2) dt = \\frac{h}{2}\\frac{2}{3} = \\frac{h}{3},\n\\\\\nc_1=\\int_a^b L_1(x)\\,dx\n&=  -h \\int_0^2 t(t-2) dt = -h\\left( -\\frac{4}{3}\\right) = \\frac{4h}{3},\n\\\\\nc_2=\\int_a^b L_2(x)\\,dx\n&=  \\frac{h}{2} \\int_0^2 t(t-1) dt = \\frac{h}{2}\\frac{2}{3} = \\frac{h}{3}.\n\\end{split}\n\\tag{7.23}\\] This means that our approximation formula is \\[\n\\int_a^bf(x)dx \\approx \\frac{h}{3}\\left( f(a)+4 f(a+h)+f(b)\\right).\n\\tag{7.24}\\] This is known as Simpson’s rule, which is graphically represented in Figure 7.2.\n\n\n\n\n\n\nFigure 7.2: Simpson’s rule\n\n\n\nError term for Simpson’s rule. Let us recall the Trapezium rule with error term: \\[\n\\int_{x_{0}}^{x_{1}}f(x)dx = \\frac{h}{2}\\left[f(x_{0})+f(x_{1})\\right]-\n\\frac{h^3}{12}f^{\\prime\\prime}(\\xi).  \n\\tag{7.25}\\] It has been obtained by integrating the linear interpolating polynomial with nodes \\(x_{0}\\) and \\(x_{1}=x_{0}+h\\). Therefore, it must produce an exact result for any polynomial of degree 0 and 1. Indeed, the error term in Eq. 11.59 vanishes for polynomials of degree 0 and 1.\nSimpson’s rule has been obtained by integrating the quadratic interpolating polynomial with nodes \\(x_{0}\\), \\(x_{1}=x_{0}+h\\) and \\(x_{2}=x_{0}+2h\\). So, it must produce an exact result for polynomials of degree 0, 1 and 2. Will it generate a nonzero error for cubic polynomials? To examine this, it suffices to consider \\(f(x)=x^3\\). By analogy with the Trapezium rule we assume that Simpson’s rule with error term has the form \\[\n\\int_{x_{0}}^{x_{2}}f(x)dx = \\frac{h}{3}\\left[f(x_{0})+4f(x_{1})  + f(x_{2})\\right]\n+Cf'''(\\xi)  \n\\tag{7.26}\\] for some constant \\(C\\) and some \\(\\xi\\in[x_{0},x_{2}]\\). Substituting \\(f(x)=x^3\\) in Eq. 7.26, we obtain \\[\n\\int_{x_{0}}^{x_{2}}x^3 dx = \\frac{h}{3}\\left[x_{0}^3+4x_{1}^3  + x_{2}^3\\right]\n+6C.  \n\\tag{7.27}\\] The integral on the left hand side of Eq. 11.69 can be written as \\[\\begin{split}\n(\\text{  l.h.s. }) \\, &= \\, \\frac{x_{2}^{4}}{4}-\\frac{x_{0}^{4}}{4}\n=\\frac{(x_{0}+2h)^{4}}{4}-\\frac{x_{0}^{4}}{4}\\\\\n&=2h x_{0}^{3}+6h^2 x_{0}^{2}+8h^3 x_{0}+4h^4.\n\\end{split}\n\\tag{7.28}\\] For the right hand side of Eq. 11.69, we have \\[\n\\begin{split}\n(\\text{  r.h.s. }) &=\\frac{h}{3}\\left[x_{0}^3+4(x_{0}+h)^3  + (x_{0}+2h)^3\\right]+6C \\\\\n&=\\frac{h}{3}\\Bigl[x_{0}^3+4\\left(x_{0}^{3}+3x_{0}^{2}h+3x_{0}h^{2}+h^{3}\\right)\\\\\n&\\qquad\\qquad +\nx_{0}^{3}+6x_{0}^{2}h+12x_{0}h^{2}+8h^{3}\\Bigr]+6C\\\\\n&=\\frac{h}{3}\\left[6x_{0}^3+18x_{0}^{2}h+24x_{0}h^{2}+12h^{3}\\right]+6C\\\\\n&=2h x_{0}^{3}+6h^2 x_{0}^{2}+8h^3 x_{0}+4h^4+6C.\n\\end{split}\n\\tag{7.29}\\] If follows from Eq. 7.28 and Eq. 7.29 that Eq. 11.69 simplifies to \\(0=6C\\), so that \\(C=0\\). This means that Simpson’s rule is exact for polynomials of degree 3 (an unexpected result!).\nThis also means that our assumption about the error term for Simpson’s rule is wrong. So, we make another assumption, namely: \\[\n\\int_{x_{0}}^{x_{2}}f(x)dx = \\frac{h}{3}\\left[f(x_{0})+4f(x_{1})  + f(x_{2})\\right]\n+Cf^{(4)}(\\xi).  \n\\tag{7.30}\\] To find \\(C\\), we substitute \\(f(x)=x^4\\) in Eq. 7.30. This yields the equation \\[\n\\int_{x_{0}}^{x_{2}}x^4 dx = \\frac{h}{3}\\left[x_{0}^4+4x_{1}^4  + x_{2}^4\\right]\n+24C.  \n\\tag{7.31}\\] The left hand side of Eq. 7.31 can be written as \\[\\begin{split}\n(\\text{  l.h.s. }) \\, &= \\, \\frac{x_{2}^{5}}{5}-\\frac{x_{0}^{5}}{5}  =\\frac{(x_{0}+2h)^{5}}{5}-\\frac{x_{0}^{4}}{4}\\\\\n&=2h x_{0}^{4}+8h^2 x_{0}^{3}+16h^3 x_{0}^{2}+16h^4 x_{0}+\\frac{32}{5}h^5.\n\\end{split}\n\\tag{7.32}\\] For the right hand side of Eq. 7.31, we have \\[\n\\begin{split}\n(\\text{  r.h.s. }) &=\\frac{h}{3}\\left[x_{0}^4+4(x_{0}+h)^4  + (x_{0}+2h)^4\\right]+24C\\\\\n&=\\frac{h}{3}\\Bigl[x_{0}^3+4\\left(x_{0}^{4}+4x_{0}^{3}h+6x_{0}^{2}h^2 + 4x_{0}h^3 +h^{4}\\right)\\\\\n& \\qquad\\qquad +\nx_{0}^{4}+8x_{0}^{3}h+24x_{0}^{2}h^2+\n32x_{0}h^{3}+16h^{4}\\Bigr]+24C\\\\\n&=\\frac{h}{3}\\left[6x_{0}^4+24x_{0}^{3}h+48x_{0}^{2}h^{2}+48x_{0}h^{3}+20h^{4}\\right]+24C\\\\\n&=2h x_{0}^{4}+8h^2 x_{0}^{3}+16 h^3 x_{0}^{2}+16 h^4 x_{0}+\\frac{20}{3}h^5+24C.\n\\end{split}\n\\tag{7.33}\\] Eq. 7.31–Eq. 7.33 imply that \\[\n\\frac{32}{5}h^5=\\frac{20}{3}h^5+24C.\n\\tag{7.34}\\] so that \\[\nC=-\\frac{h^5}{90}.\n\\tag{7.35}\\] Thus, Simpson’s rule with error term is given by \\[\n\\int_{x_{0}}^{x_{2}}f(x)dx = \\frac{h}{3}\\left[f(x_{0})+4f(x_{1})  + f(x_{2})\\right]\n-\\frac{h^{5}}{90}f^{(4)}(\\xi)  \n\\tag{7.36}\\] for some \\(\\xi\\in[x_{0},x_{2}]\\). Note that the above argument is not a proof of the existence of such \\(\\xi\\). Alternative derivations of formula Eq. 7.36 can be found in textbooks on Numerical Analysis (e.g. (Burden and Faires 2010)).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Numerical integration</span>"
    ]
  },
  {
    "objectID": "chapter07.html#higher-order-newton-cotes-formulae",
    "href": "chapter07.html#higher-order-newton-cotes-formulae",
    "title": "7  Numerical integration",
    "section": "7.3 Higher-order Newton-Cotes formulae",
    "text": "7.3 Higher-order Newton-Cotes formulae\nWe have now seen that the Trapezium and Simpson’s rules are examples of Newton-Cotes formulae, which are obtained by integrating of an interpolating polynomial for interpolation points \\(x_{0}, \\dots, x_{n}\\). The Trapezium rule and Simpson’s rule correspond to \\(n=1\\) and \\(n=2\\) respectively. For \\(n=3\\), we have Simpson’s three-eighth rule \\[\n\\int_{x_{0}}^{x_{3}}f(x)dx= {3h \\over 8}\n\\left[f(x_{0})+3f(x_{1})+3f(x_{2})+f(x_{3})\\right]-\n{3h^{5} \\over 80}f^{(4)}(\\xi),\n\\tag{7.37}\\] where \\(h=(x_{3}-x_{0})/3\\) and \\(\\xi\\in[x_{0},x_{3}]\\). The error of Simpson’s three-eighth rule is proportional to \\(h^5\\) with a coefficient that is larger than that in the error term of Simpson’s rule, so this method seems less efficient than Simpson’s rule.\nFor \\(n=4\\) we have the formula \\[\n\\begin{split}\n\\int_{x_{0}}^{x_{4}}f(x)dx=& {2h \\over 45}\n\\left[7f(x_{0})+32f(x_{1})+12f(x_{2})+32f(x_{3})\n+7f(x_{4})\\right]\\\\\n&-{8h^{7} \\over 945}f^{(6)}(\\xi).\n\\end{split}\n\\tag{7.38}\\] where \\(h=(x_{4}-x_{0})/4\\) and \\(\\xi\\in[x_{0},x_{4}]\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Numerical integration</span>"
    ]
  },
  {
    "objectID": "chapter07.html#composite-numerical-integration",
    "href": "chapter07.html#composite-numerical-integration",
    "title": "7  Numerical integration",
    "section": "7.4 Composite numerical integration",
    "text": "7.4 Composite numerical integration\nThe Newton-Cotes formulas are generally unsuitable for large integration intervals. This would require high-degree formulas. An alternative to this is a piecewise approach to numerical integration that uses the low-order Newton-Cotes formulas such as the Trapezium and Simpson’s rules.\nLet us apply Simpson’s formula to approximate the integral \\(\\int_{0}^{4}x^{4}dx\\). We have \\[\n\\begin{split}\nI &= \\int_{0}^{4}x^{4}dx\\approx \\frac{2}{3}\n\\left[0 + 4\\cdot 2^{4}+4^{4}\\right]=\\frac{2}{3}(64+256)=213.333, \\\\\nE&=\\vert I-213.333\\vert=\\vert 204.8-213.333\\vert=8.533.\n\\end{split}\n\\tag{7.39}\\] To apply a piecewise technique to this problem, we divide \\([0, 4]\\) into two subintervals \\([0, 2]\\) and \\([2, 4]\\) and use Simpson’s rule twice with \\(h=1\\): \\[\n\\begin{split}\nI =& \\int_{0}^{4}x^{4}dx\\approx \\frac{1}{3}\n\\left[0 + 4\\cdot 1^{4}+2^{4}\\right] \\\\\n&+ \\frac{1}{3}\\left[2^{4} + 4\\cdot 3^{4}+4^{4}\\right]=205.333, \\\\\nE=&\\vert 204.8-205.333\\vert=0.533.\n\\end{split}\n\\tag{7.40}\\] To reduce the error, we can proceed further by subdividing the intervals \\([0, 2]\\) and \\([2, 4]\\) and use Simpson’s rule with \\(h=1/2\\).\nTo generalize this procedure, we choose an even integer \\(n\\) and divide the interval \\([a, b]\\) into \\(n\\) subintervals. Then we apply Simpson’s rule to each consecutive pair of subintervals. With \\(h=(b-a)/n\\) and \\(x_{j}=a+jh\\) for \\(j=0, 1, ..., n\\), we have \\[\n\\begin{split}\n\\int_{a}^{b}f(x)dx &=\\sum_{j=1}^{n/2}\n\\int_{x_{2j-2}}^{x_{2j}}f(x)dx \\\\\n&=\n\\sum_{j=1}^{n/2}\\left\\{\n\\frac{h}{3}\\left[f(x_{2j-2})+4f(x_{2j-1})+f(x_{2j})\\right]-\n\\frac{h^{5}}{90}f^{(4)}(\\xi_{j})\\right\\}\n\\end{split}\n\\tag{7.41}\\] for some \\(\\xi_{j}\\) between \\(x_{2j-2}\\) and \\(x_{2j}\\), provided that \\(f\\in C^{4}[a, b]\\).\nOne can see that for each \\(j=1, 2, ..., (n/2)-1\\), the number \\(f(x_{2j})\\) appears in the term corresponding to the interval \\([x_{2j-2}, x_{2j}]\\) and also in the term corresponding to the interval \\([x_{2j}, x_{2j+2}]\\). Taking this into account, we obtain \\[\n\\begin{split}\n\\int_{a}^{b}f(x)dx &= \\sum_{j=1}^{n/2}\n\\int_{x_{2j-2}}^{x_{2j}}f(x)dx  \\\\\n&=\n\\frac{h}{3}\\left\\{ f(x_{0})+2\\sum_{j=1}^{(n/2)-1}f(x_{2j})+\n4\\sum_{j=1}^{n/2}f(x_{2j-1})+ f(x_{n})\\right\\}\n+E.  \n\\end{split}\n\\tag{7.42}\\] The error of this approximation is \\[\nE=-{h^{5} \\over 90}\\sum_{j=1}^{n/2}f^{(4)}(\\xi_{j})\n\\tag{7.43}\\] where \\(x_{2j-2} &lt; \\xi_{j} &lt; x_{2j}\\) for each \\(j=1, 2, ..., n/2\\). If \\(f\\in C^{4}[a, b]\\), then (according to the Extreme Value Theorem) \\(f^{(4)}(x)\\) attains its maximum and minimum values in \\([a, b]\\). Let \\[\nm=\\min_{x\\in[a, b]}f^{(4)}(x), \\quad M=\\max_{x\\in[a, b]}f^{(4)}(x).\n\\tag{7.44}\\] Then we have \\[\nm \\leq f^{(4)}(\\xi_{j}) \\leq M \\ \\ \\\n\\text{  for \\ each } \\ \\ j=1, 2, ..., n/2 .\n\\tag{7.45}\\] Therefore, \\[\n\\frac{n}{2}m \\leq\n\\sum_{j=1}^{n/2}f^{(4)}(\\xi_{j}) \\leq \\frac{n}{2} M,\n\\tag{7.46}\\] and \\[\nm \\leq \\frac{2}{n}\n\\sum_{j=1}^{n/2}f^{(4)}(\\xi_{j}) \\leq M.\n\\tag{7.47}\\] By the Intermediate Value Theorem, there is a \\(\\mu\\in(a, b)\\) such that \\[\nf^{(4)}(\\mu)={2 \\over n}\n\\sum_{j=1}^{n/2}f^{(4)}(\\xi_{j}).\n\\tag{7.48}\\] Hence, \\[\nE=-{h^{5}\\over 180}n f^{(4)}(\\mu)=-{b-a \\over 180}h^{4} f^{(4)}(\\mu).\n\\tag{7.49}\\] Thus, we have proved the following theorem.\n\nTheorem 7.1 (Composite Simpson’s rule) Let \\(f\\in C^{4}[a, b]\\), \\(n\\) be even, \\(h=(b-a)/n\\), and \\(x_{j}=a+jh\\) for \\(j=0, 1, ..., n\\). There exist a number \\(\\mu\\in(a, b)\\) such that \\[\n\\begin{split}\n\\int_{a}^{b}f(x)dx =&\n{h\\over 3}\\left\\{ f(x_{0})+2\\sum_{j=1}^{(n/2)-1}f(x_{2j})+\n4\\sum_{j=1}^{n/2}f(x_{2j-1})+ f(x_{n})\\right\\} \\\\\n&-\\frac{b-a}{180}h^{4}f^{(4)}(\\mu).\n\\end{split}\n\\tag{7.50}\\]\n\nSimilarly, one can prove analogous theorems for Composite Trapezium rule.\n\nTheorem 7.2 (Composite Trapezium rule) Let \\(f\\in C^{2}[a, b]\\), \\(h=(b-a)/n\\), and \\(x_{j}=a+jh\\) for \\(j=0, 1, ..., n\\). There exist a number \\(\\mu\\in(a, b)\\) such that \\[\n\\int_{a}^{b}f(x)dx=\n\\frac{h}{2}\\left\\{ f(x_{0})+2\\sum_{j=1}^{n-1}f(x_{j})+ f(x_{n})\\right\\}\n-\\frac{b-a}{12}h^{2}f^{\\prime\\prime}(\\mu).\n\\tag{7.51}\\]\n\n\nExample 7.1 Apply the composite Simpson rule to compute \\[\nI=\\int\\limits_{0}^{2}e^{x}dx\n\\tag{7.52}\\] with absolute error less than \\(10^{-2}\\).\n\n\nSolution. First we need to determine the number of subintervals* \\(n\\) in the composite Simpson rule that would ensure that absolute error less than \\(10^{-2}\\). It follows from Eq. 7.50 that \\[\nE=\\frac{b-a}{180}h^{4}\\vert f^{(4)}(\\mu)\\vert\\leq \\frac{b-a}{180}h^{4}M,\n\\tag{7.53}\\] where \\(M\\) is the upper bound for \\(\\vert f^{(4)}(x)\\vert\\) in \\([0,2]\\). Evidently, \\(M=e^2\\). Therefore, we require that \\[\n\\frac{b-a}{180}h^{4}e^2 &lt; 10^{-2} \\quad \\Leftrightarrow \\quad\n\\frac{(b-a)^5}{180 n^4}e^2 &lt; 10^{-2}  \\quad \\Leftrightarrow \\quad\nn^4 &gt; \\frac{100(b-a)^5}{180}e^2 .\n\\tag{7.54}\\] Substituting \\(a=0\\) and \\(b=2\\), we find that \\[\nn^4 &gt; \\frac{5\\cdot 32 e^2}{9}=131.3609973, \\quad \\text{  so \\ that } \\ \\ n\\geq 4 \\ \\ (n^4=256).\n\\tag{7.55}\\] Applying the composite Simpson rule with \\(n=4\\), we obtain the approximation \\[\n\\tilde{I}=6.391210187.\n\\tag{7.56}\\] The actual error is \\[\n\\vert I-\\tilde{I}\\vert=0.002154088.\n\\tag{7.57}\\] So it is indeed less that \\(10^{-2}\\).\n\nAll the Composite Newton-Cotes techniques are stable with respect to roundoff error. Consider, for example, the Composite Simpson rule with \\(n\\) subintervals applied to a function \\(f(x)\\) on \\([a, b]\\). We assume that \\(f(x_{i})\\) is approximated by \\(\\tilde f(x_{i})\\) with the roundoff error \\(e_{i}\\). Then, the accumulated error in the Composite Simpson rule is \\[\n\\begin{split}\nE(h) &= \\left\\vert\\frac{h}{3}\\left( e_{0}\n+2\\sum_{j=1}^{(n/2)-1}e_{2j}+\n4\\sum_{j=1}^{n/2}e_{2j-1}+ e_{n}\\right)\\right\\vert \\\\\n&\\leq\n\\frac{h}{3}\\left( \\vert e_{0}\\vert\n+2\\sum_{j=1}^{(n/2)-1}\\vert e_{2j}\\vert +\n4\\sum_{j=1}^{n/2}\\vert e_{2j-1}\\vert + \\vert e_{n}\\vert\\right)\n\\end{split}\n\\tag{7.58}\\] If the roundoff errors are uniformly bounded by \\(\\varepsilon\\), then \\[\nE(h) \\leq\n{h \\over 3}\\left(\\varepsilon\n+2\\left(\\frac{n}{2}-1\\right)\\varepsilon +\n4\\frac{n}{2}\\varepsilon + \\varepsilon\\right)=nh\\varepsilon=(b-a)\\varepsilon.\n\\tag{7.59}\\] Thus, the bound for the accumulated error is independent of \\(h\\), so that \\(h\\) can be taken as small as we wish.\n\n\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical Analysis. 9th ed. Brooks Cole.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Numerical integration</span>"
    ]
  },
  {
    "objectID": "chapter08.html",
    "href": "chapter08.html",
    "title": "8  Numerical differentiation",
    "section": "",
    "text": "8.1 Two-point forward and backward formulas for \\(f'\\)\nOften we need to calculate the derivative of a function whose values are given only for a finite set of points. So, we need a formula which would approximate the derivatives of our function at these points and which would use only the values of the function at these points.\nRecall that, by definition, the derivative of the function \\(f(x)\\) at \\(x_{0}\\) is \\[\nf^{\\prime}(x_{0})=\\lim_{h\\to 0}\\frac{f(x_{0}+h)-f(x_{0})}{h}.\n\\tag{8.1}\\] It is natural to expect that if \\(h\\) is sufficiently small, then \\[\nf^{\\prime}(x_{0}) \\approx \\frac{f(x_{0}+h)-f(x_{0})}{h}.\n\\tag{8.2}\\] This formula approximates the derivative using values of \\(f\\) at two points \\(x_{0}\\) and \\(x_{0}+h\\).\nWhat is a general method of constructing approximate formulas for the derivative? There are many ways of doing that. For example, given a set of distinct points \\(x_{0},\\dots,x_{n}\\) and values of \\(f\\) at these points, we can construct the interpolating polynomial and then compute the derivatives of this polynomial at each \\(x_{0},\\dots,x_{n}\\). This method, although possible, is less transparent and instructive than a method based of Taylor’s polynomials (series) which we will discuss below.\nLet \\(f\\in C^{(n+1)}(I)\\) where \\(I\\) is an open interval. Then we have the Taylor formula (of order \\(n\\)): \\[\n\\begin{split}\nf(x) =&  f(x_{0})+(x-x_{0})f^{\\prime}(x_{0})+\n\\frac{(x-x_{0})^{2}}{2!}f^{\\prime\\prime}(x_{0})+\\dots \\\\\n&+\n\\frac{(x-x_{0})^{n}}{n!}f^{(n)}(x_{0})+\\frac{(x-x_{0})^{n+1}}{(n+1)!}f^{(n+1)}(\\xi)\n\\end{split}\n\\tag{8.3}\\]\nfor any \\(x,x_{0}\\in I\\) and for some \\(\\xi\\) between \\(x\\) and \\(x_{0}\\) (\\(\\xi\\) depends on \\(x\\) and \\(x_{0}\\)). If we use the notation \\(h=x-x_{0}\\), then Eq. 8.3 takes the form \\[\n\\begin{split}\nf(x_{0}+h) =&  f(x_{0})+h f^{\\prime}(x_{0})+\n\\frac{h^{2}}{2!}f^{\\prime\\prime}(x_{0})+\\dots\\\\\n&+\n\\frac{h^{n}}{n!}f^{(n)}(x_{0})+\n\\frac{h^{n+1}}{(n+1)!}f^{(n+1)}(\\xi)\n\\end{split}\n\\tag{8.4}\\] with \\(\\xi\\) between \\(x_{0}\\) and \\(x_{0}+h\\) (\\(\\xi\\) can also be written as \\(\\xi=x_{0}+\\theta h\\) where \\(0&lt; \\theta&lt;1\\)).\nFor example, function \\(f(x)=\\sin(x)/x-1\\) converges to 0 as fast as \\(x^{2}\\) converges to zero (as \\(x\\to 0\\)). To show this, it suffices to consider the third Taylor polynomial for \\(\\sin(x)\\): \\[\n\\sin(x)=x-\\frac{x^{3}}{3!}\\cos(\\xi)\n\\tag{8.7}\\] where \\(\\xi\\) is some number between 0 and \\(x\\). We have \\[\n\\left\\vert \\frac{\\sin x}{x} -1 \\right\\vert = \\frac{\\vert x\n\\vert^{2}}{3!}\\vert \\cos(\\xi)\\vert \\leq \\frac{x^{2}}{3!}=\\frac{x^{2}}{6} \\ \\ \\\n\\Rightarrow \\ \\ \\ \\ \\frac{\\sin x}{x}-1=O(x^{2}). \\\\\n\\tag{8.8}\\] Here we used the fact that \\(\\vert \\cos x\\vert\\leq 1\\) for all \\(x\\in\\mathbb{R}\\).\nProperties of \\(O(h^n)\\):\nIt follows from Eq. 8.4 that \\[\n\\vert f(x_{0}+h)- T_{n}(h)\\vert=\\left\\vert\\frac{h^{n+1}}{(n+1)!}f^{(n+1)}(\\xi)\\right\\vert\n\\tag{8.9}\\] where \\(T_{n}\\) is the \\(n\\)th Taylor polynomial: \\[\nT_{n}(h)=  f(x_{0})+h f^{\\prime}(x_{0})+\n\\frac{h^{2}}{2!}f^{\\prime\\prime}(x_{0})+\\dots +\n\\frac{h^{n}}{n!}f^{(n)}(x_{0}).\n\\tag{8.10}\\] From our assumption that \\(f\\in C^{(n+1)}(I)\\) and \\(x,x_{0}\\in I\\), it follows that there exists a closed interval \\([a,b]\\) such that \\([a,b]\\subset I\\) and \\(x,x_{0}\\in [a,b]\\). Therefore, \\(f^{(n+1)}(x)\\) attains its maximum and minimum values in \\([a,b]\\), so that \\(\\vert f^{(n+1)}(x)\\vert \\leq M\\) for some \\(M\\). Thus, we have \\[\n\\vert f(x_{0}+h)- T_{n}(h)\\vert \\leq \\left\\vert\\frac{h^{n+1}}{(n+1)!}M\\right\\vert=\\frac{M}{(n+1)!}\\vert h^{n+1}\\vert,\n\\tag{8.11}\\] which means that \\[\nf(x_{0}+h) - T_{n}(h)=O\\left(h^{n+1}\\right)\n\\tag{8.12}\\] or, equivalently, \\[\nf(x_{0}+h) = T_{n}(h) + O\\left(h^{n+1}\\right).\n\\tag{8.13}\\]\nLet us derive the formula for the derivative based on points \\(x_{0}\\) and \\(x_{0}+h\\) (\\(h&gt;0\\)). If we put \\(n=1\\) in Eq. 8.4, we obtain \\[\nf(x_{0}+h)=  f(x_{0})+h f^{\\prime}(x_{0})+\n\\frac{h^{2}}{2!}f^{\\prime\\prime}(\\xi_{1})\n\\tag{8.14}\\] where \\(x_{0} &lt; \\xi_{1} &lt; x_{0}+h\\). Solving this for \\(f^{\\prime}(x_{0})\\), we find that \\[\nf^{\\prime}(x_{0})=\\frac{f(x_{0}+h) - f(x_{0})}{h} -\n\\frac{h}{2!}f^{\\prime\\prime}(\\xi_{1}).\n\\tag{8.15}\\] This is called the forward-difference formula for \\(f^{\\prime}(x_{0})\\). Similarly, one can obtain the backward-difference formula for \\(f^{\\prime}(x_{0})\\)1: \\[\nf^{\\prime}(x_{0})=\\frac{f(x_{0}) - f(x_{0}-h)}{h} +\n\\frac{h}{2!}f^{\\prime\\prime}(\\xi_{2})\n\\tag{8.16}\\] where \\(x_{0}-h &lt; \\xi_{2} &lt; x_{0}\\) (\\(h&gt;0\\)).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Numerical differentiation</span>"
    ]
  },
  {
    "objectID": "chapter08.html#three-point-formulas-for-f",
    "href": "chapter08.html#three-point-formulas-for-f",
    "title": "8  Numerical differentiation",
    "section": "8.2 Three-point formulas for \\(f'\\)",
    "text": "8.2 Three-point formulas for \\(f'\\)\nNow let us derive an approximation formula for \\(f^{\\prime}(x_{0})\\) based on points \\(x_{0}-h\\), \\(x_{0}\\) and \\(x_{0}+h\\) (\\(h&gt;0\\)). The Taylor formula Eq. 8.4 with \\(n=2\\) implies that \\[\n\\begin{split}\nf(x_{0}+h) &=  f(x_{0})+h f^{\\prime}(x_{0})+\n\\frac{h^{2}}{2!}f^{\\prime\\prime}(x_{0})+\n\\frac{h^{3}}{3!}f^{\\prime\\prime\\prime}(\\xi^+), \\quad x_{0} &lt; \\xi^+ &lt; x_{0}+h,  \\\\\nf(x_{0}-h) &=  f(x_{0})-h f^{\\prime}(x_{0})+\n\\frac{h^{2}}{2!}f^{\\prime\\prime}(x_{0})-\n\\frac{h^{3}}{3!}f^{\\prime\\prime\\prime}(\\xi^-), \\quad x_{0}-h &lt; \\xi^- &lt; x_{0}.\n\\end{split}\n\\tag{8.17}\\] Subtracting the second equation from the first one, we obtain \\[\nf(x_{0}+h)-f(x_{0}-h)= 2h f^{\\prime}(x_{0})+\n\\frac{h^{3}}{3!}\\left(f^{\\prime\\prime\\prime}(\\xi^+)+f^{\\prime\\prime\\prime}(\\xi^-)\\right).\n\\tag{8.18}\\] Solving this for \\(f^{\\prime}(x_{0})\\) yields \\[\nf^{\\prime}(x_{0})=\\frac{f(x_{0}+h) - f(x_{0}-h)}{2h} -\n\\frac{h^2}{3!}\\frac{1}{2}\\left(f^{\\prime\\prime\\prime}(\\xi^+)+f^{\\prime\\prime\\prime}(\\xi^-)\\right).\n\\tag{8.19}\\] Since \\(f^{\\prime\\prime\\prime}\\) is continuous, by the Intermediate Value Theorem there exists \\(\\xi\\) between \\(\\xi^-\\) and \\(\\xi^+\\) such that \\[\nf^{\\prime\\prime\\prime}(\\xi)= \\frac{1}{2}\\left(f^{\\prime\\prime\\prime}(\\xi^+)+f^{\\prime\\prime\\prime}(\\xi^-)\\right).\n\\tag{8.20}\\] Therefore, \\[\nf^{\\prime}(x_{0})=\\frac{f(x_{0}+h) - f(x_{0}-h)}{2h} -\n\\frac{h^{2}}{6}f^{\\prime\\prime\\prime}(\\xi)  \n\\tag{8.21}\\] where \\(x_{0}-h &lt; \\xi &lt; x_{0}+h\\). This is the central difference formula for \\(f^{\\prime}(x_{0})\\). Note that the error of the central difference approximation is \\(O(h^2)\\) as \\(h\\to 0\\). Thus, we have a second order approximation for \\(f^{\\prime}(x_{0})\\).\nThere are two more three-point formulas for \\(f^{\\prime}(x_{0})\\): \\[\n\\begin{split}\nf^{\\prime}(x_{0})&=\\frac{1}{2h}\\left[-3f(x_{0})+4f(x_{0}+h)-f(x_{0}+2h)\\right]+O(h^2)\\\\\nf^{\\prime}(x_{0})&=\\frac{1}{2h}\\left[f(x_{0}-2h)-4f(x_{0}-h)+3f(x_{0})\\right]+O(h^2)\n\\end{split}\n\\tag{8.22}\\] The first formula uses points \\(x_{0}\\), \\(x_{0}+h\\) and \\(x_{0}+2h\\) and is called the three-point forward difference formula for \\(f^{\\prime}(x_{0})\\). The second formula is called the three-point backward difference formula and uses points \\(x_{0}-2h\\), \\(x_{0}-h\\) and \\(x_{0}\\). Note that the second equation can be obtained from the first by simply replacing \\(h\\) with \\(-h\\), so, in fact, these two represent only one formula.\n\nExample 8.1 Prove Eq. 8.22 assuming that \\(f\\in C^3(I)\\) where \\(I\\) is some open interval containing \\(x_{0}\\).\n\n\nSolution. First we choose a sufficiently small* \\(h\\), so that \\([x_{0}, x_{0}+2h]\\subset I\\). Then \\(f^{\\prime\\prime\\prime}(x)\\) is bounded for all \\(x\\in [x_{0}, x_{0}+2h]\\) and we can write \\[\n\\begin{split}\nf(x_{0}+h)&=f(x_{0})+h \\, f^{\\prime}(x_{0})+\\frac{h^2}{2} \\, f^{\\prime\\prime}(x_{0})+ O(h^3),\\\\\nf(x_{0}+2h)&=f(x_{0})+2h \\, f^{\\prime}(x_{0})+\\frac{(2h)^2}{2} \\, f^{\\prime\\prime}(x_{0})+ O(h^3) \\\\\n&= f(x_{0})+2h \\, f^{\\prime}(x_{0})+2h^2 \\, f^{\\prime\\prime}(x_{0})+ O(h^3).\n\\end{split}\n\\tag{8.23}\\] These and Eq. 8.22 yield \\[\n\\begin{split}\nE&=f^{\\prime}(x_{0})-\\frac{1}{2h}\\left[-3f(x_{0})+\n4f(x_{0}+h)-f(x_{0}+2h)\\right] \\\\\n&= f^{\\prime}(x_{0})-\\frac{1}{2h}\\Bigl[-3f(x_{0})+\n4\\left(f(x_{0})+h \\, f^{\\prime}(x_{0})+ \\frac{h^{2}}{2}f^{\\prime\\prime}(x_{0})\\right) \\\\\n&\\qquad \\quad -f(x_{0})-2hf^{\\prime}(x_{0})- 2h^2f^{\\prime\\prime}(x_{0})+ O(h^{3})\\Bigr]  \\\\\n&= O(h^{2}).\n\\end{split}\n\\tag{8.24}\\]",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Numerical differentiation</span>"
    ]
  },
  {
    "objectID": "chapter08.html#higher-derivatives",
    "href": "chapter08.html#higher-derivatives",
    "title": "8  Numerical differentiation",
    "section": "8.3 Higher derivatives",
    "text": "8.3 Higher derivatives\nTaylor series can also be used to derive formulas for approximating higher derivatives of a function given at a finite set of points.\nLet us consider an example. First, we expand \\(f\\) in a third Taylor polynomial about \\(x_{0}\\) and evaluate \\(f\\) at \\(x=x_{0}-h\\) and \\(x=x_{0}+h\\). Then \\[\n\\begin{split}\nf(x_{0}+h) &=f(x_{0})+f^{\\prime}(x_{0})h+\n\\frac{1}{2}f^{\\prime\\prime}(x_{0})h^{2}+\n\\frac{1}{6}f^{\\prime\\prime\\prime}(x_{0})h^{3}+\n\\frac{1}{24}f^{(4)}(\\xi^{+})h^{4},  \\\\\nf(x_{0}-h) &=f(x_{0})-f^{\\prime}(x_{0})h+\n\\frac{1}{2}f^{\\prime\\prime}(x_{0})h^{2}-\n\\frac{1}{6}f^{\\prime\\prime\\prime}(x_{0})h^{3}+\n\\frac{1}{24}f^{(4)}(\\xi^{-})h^{4},\n\\end{split}\n\\tag{8.25}\\] where \\(x_{0}-h&lt; \\xi^{-}&lt; x_{0} &lt; \\xi^{+}&lt; x_{0}+h\\). Adding these equations, we obtain \\[\nf^{\\prime\\prime}(x_{0})=\\frac{1}{h^{2}}[f(x_{0}-h)-\n2f(x_{0})+f(x_{0}+h)]-\\frac{h^{2}}{24}[f^{(4)}(\\xi^{+})\n+f^{(4)}(\\xi^{-})].\n\\tag{8.26}\\] Assuming that \\(f^{(4)}\\) is continuous on \\([x_{0}-h, x_{0}+h]\\), we can rewrite this equation in a simpler form. Since \\([f^{(4)}(\\xi^{+}) +f^{(4)}(\\xi^{-})]/2\\) is between \\(f^{(4)}(\\xi^{+})\\) and \\(f^{(4)}(\\xi^{-})\\), the Intermediate Value theorem implies that there exists a number \\(\\xi\\) between \\(\\xi^{+}\\) and \\(\\xi^{-}\\) such that \\[\nf^{(4)}(\\xi)=\\frac{1}{2}[f^{(4)}(\\xi^{+})\n+f^{(4)}(\\xi^{-})] .\n\\tag{8.27}\\] Therefore, \\[\nf^{\\prime\\prime}(x_{0})={1\\over h^{2}}[f(x_{0}-h)-\n2f(x_{0})+f(x_{0}+h)]-{h^{2} \\over 12}f^{(4)}(\\xi).\n\\tag{8.28}\\] where \\(x_{0}-h&lt; \\xi &lt; x_{0}+h\\). This is called the central difference formula for \\(f^{\\prime\\prime}(x_{0})\\) and it uses values of \\(f\\) at three points. Its truncation error is \\(O(h^2)\\). This is one of the most popular finite difference formulas in Numerical Analysis.\nFinite difference formulas for higher derivatives can be derived in a similar manner.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Numerical differentiation</span>"
    ]
  },
  {
    "objectID": "chapter08.html#the-effect-of-roundoff-errors",
    "href": "chapter08.html#the-effect-of-roundoff-errors",
    "title": "8  Numerical differentiation",
    "section": "8.4 The effect of Roundoff Errors",
    "text": "8.4 The effect of Roundoff Errors\nConsider the central difference formula: \\[\nf^{\\prime}(x_{0})=\\frac{1}{2h}\\left[f(x_{0}+h)\n-f(x_{0}-h)\\right]-\\frac{h^{2}}{6}\nf^{(3)}(\\xi).\n\\tag{8.29}\\] Suppose that the values of \\(f(x_{0}-h)\\) and \\(f(x_{0}+h)\\) are computed with roundoff errors \\(e^{-}\\) and \\(e^{+}\\), respectively, i.e.  \\[\nf(x_{0}-h)=f^{-} + e^{-} \\quad \\text{  and } \\quad\nf(x_{0}+h)=f^{+} + e^{+}.\n\\tag{8.30}\\] Here \\(\\tilde{f}^{\\pm}\\) are the computed valued. Substitution of these in the central difference formula yields \\[\nf^{\\prime}(x_{0})=\\frac{1}{2h}\\left[f^{+} + e^{+}\n-f^{-} - e^{-}\\right]-\\frac{h^{2}}{6}\nf^{(3)}(\\xi).\n\\tag{8.31}\\] The total error in the approximation is \\[\nf^{\\prime}(x_{0})-\\frac{f^{+}\n-f^{-}}{2h}=\\frac{e^{+}-e^{-}}{2h}\n-\\frac{h^{2}}{6}f^{(3)}(\\xi).\n\\tag{8.32}\\] The total error has a part due to roundoff error and a part due to truncation error. Suppose that the roundoff errors are bounded by some number \\(\\varepsilon &gt;0\\) (this is always true in practice), i.e.  \\[\n\\vert e^{\\pm}\\vert\\leq \\varepsilon,\n\\tag{8.33}\\] and that the third derivative of \\(f\\) is bounded by \\(M &gt; 0\\) for all \\(x\\in[x_{0}-h,x_{0}+h]\\). Then we have \\[\n\\left\\vert f^{\\prime}(x_{0})-\\frac{f^{+}\n-f^{-}}{2h}\\right\\vert \\leq \\frac{\\varepsilon}{h}+\n\\frac{h^{2}}{6}M .\n\\tag{8.34}\\] One can see that, to reduce the truncation error we must reduce \\(h\\). But as \\(h\\) is reduced, the roundoff error \\(\\varepsilon/h\\) grows.\nTo determine the optimal value of \\(h\\) (for which the total error is the smallest one), we consider the function \\[\nE(h)=\\frac{\\varepsilon}{h}+\n\\frac{h^{2}}{6}M.\n\\tag{8.35}\\] which is the upper bound for the total error as a function of \\(h\\). Since \\(E^{\\prime}(h)=-\\varepsilon/h^{2}+hM/3=0\\) at \\(h=h^{*}=(3\\varepsilon/M)^{1/3}\\), the function \\(E(h)\\) attains its minimum value at \\[\nh=\\left(\\frac{3\\varepsilon}{M}\\right)^{1/3},\n\\tag{8.36}\\] and this is the optimal value of \\(h\\). The corresponding minimum error is \\[\nE_{min}=E(h^{*})=\n\\frac{1}{2}\\left(9M\\varepsilon^{2}\\right)^{1/3}.\n\\tag{8.37}\\]\nUnfortunately, in practice, we cannot compute an optimal \\(h\\) to use in approximating the derivative, because usually we do not know the third derivative of the function. But we must be aware that reducing the step size will not always improve the approximation.\nSimilar analysis can be done for other finite difference formulas for the derivative, and in all cases it leads to similar conclusions.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Numerical differentiation</span>"
    ]
  },
  {
    "objectID": "chapter08.html#footnotes",
    "href": "chapter08.html#footnotes",
    "title": "8  Numerical differentiation",
    "section": "",
    "text": "In fact, it can be obtained from Eq. 8.15 simply by changing \\(h\\) to \\(-h\\).↩︎",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Numerical differentiation</span>"
    ]
  },
  {
    "objectID": "chapter09.html",
    "href": "chapter09.html",
    "title": "9  A direct method for solving tridiagonal linear systems",
    "section": "",
    "text": "Consider the following system of linear equations \\[\nA\\mathbf{x}= \\mathbf{F},\n\\tag{9.1}\\]\nwhere \\(\\mathbf{F}\\in\\mathbb{R}^n\\) is a given vector, \\(\\mathbf{x}\\in\\mathbb{R}^n\\) is the vector of unknowns and \\(A\\) is a given \\(n\\times n\\) tridiagonal matrix, i.e.  \\[\nA= \\begin{pmatrix}\n       D_1      &U_1    &0      &\\cdots &\\cdots &\\cdots  &0      \\\\\n       L_2      &D_2    &U_2    &\\ddots &       &        &\\vdots  \\\\\n       0        &L_3    &D_3    &U_3    &\\ddots &        &\\vdots  \\\\\n       \\vdots   &\\ddots &\\ddots &\\ddots &\\ddots &\\ddots  &\\vdots  \\\\\n       \\vdots   &       &\\ddots &\\ddots &\\ddots &\\ddots  &0       \\\\\n       \\vdots   &       &       &\\ddots &\\ddots &D_{n-1} &U_{n-1} \\\\\n       0        &\\cdots &\\cdots &\\cdots &0      &L_n     &D_n\n\\end{pmatrix}.\n\\tag{9.2}\\]\nA system like this has appeared when we discussed spline interpolation (see Eq. 6.70). Similar linear systems also arise in finite-difference methods for solving differential equations. Of course, the solution of this system can be approximated using iterative techniques such as Jacobi or Gauss-Seidel methods. However, there are much more efficient direct methods for solving such systems. All direct methods are equivalent to Gaussian elimination applied to the above trigiagonal system. One of these, called the double-sweep method, is described below.\nThe above system of linear equations can be written as \\[\n\\begin{split}\nD_{1}x_{i}+U_{1}x_{2}&=F_{1}, \\\\\nL_{i}x_{i-1}+D_{i}x_{i}+U_{i}x_{i+1}&=F_{i} \\quad \\hbox{for}\\quad i=2, \\dots, n-1,\\\\\nL_{n}x_{n-1}+D_{n}x_{n}&=F_{n}.\n\\end{split}\n\\tag{9.3}\\]\nIt is convenient to introduce \\[\nx_0=0 \\quad \\hbox{and} \\quad x_{n+1}=0.  \n\\tag{9.4}\\]\nThen Eq. 9.3 can be rewritten as \\[\nL_{i}x_{i-1}+D_{i}x_{i}+U_{i}x_{i+1}=F_{i} \\quad \\hbox{for}\\quad i=1, \\dots, n.\n\\tag{9.5}\\]\nTo solve Eq. 9.5, we will seek \\(\\alpha_{i}\\) and \\(\\beta_{i}\\) such that \\[\nx_{i-1}=\\alpha_{i}x_{i}+\\beta_{i}  \\quad  \\hbox{for} \\quad\ni=1, 2, \\dots, n+1.  \n\\tag{9.6}\\] Substitution of Eq. 9.6 into Eq. 9.5 yields \\[\n(\\alpha_{i}L_{i}+D_{i})x_{i}+U_{i}x_{i+1}+\\beta_{i}L_{i}-F_{i}=0 \\quad \\hbox{for}\\quad i=1, \\dots, n.\n\\tag{9.7}\\] From Eq. 9.6, we also have \\[\nx_{i}=\\alpha_{i+1}x_{i+1}+\\beta_{i+1}  \\quad  \\hbox{for} \\quad\ni=0, 1, \\dots, n.\n\\tag{9.8}\\] Substituting this into Eq. 9.7, we find that \\[\n[(\\alpha_{i}L_{i}+D_{i})\\alpha_{i+1}+U_{i}]x_{i+1}+[\n(\\alpha_{i}L_{i}+D_{i})\\beta_{i+1}+\\beta_{i}L_{i}-F_{i}]=0 \\quad \\hbox{for}\\quad i=1, \\dots, n.\n\\tag{9.9}\\] The last equation is satisfied if the two expressions in the square brackets are both zero. This leads to the following recursive formulae: \\[\n\\alpha_{i+1}=-\\frac{U_{i}}{D_{i}+\\alpha_{i}L_{i}}, \\quad\n\\beta_{i+1}=-\\frac{\\beta_{i}L_{i}-F_{i}}{D_{i}+\\alpha_{i}L_{i}}, \\quad\n\\hbox{for}\\quad i=1, \\dots, n.\n\\tag{9.10}\\] Now if \\(\\alpha_{1}\\) and \\(\\beta_{1}\\) are known, then \\(\\alpha_{i}\\) and \\(\\beta_{i}\\) for \\(i=2, 3, \\dots, n+1\\) can be computed from Eq. 9.10. \\(\\alpha_{1}\\) and \\(\\beta_{1}\\) can be determined from Eq. 9.6 and the fact that \\(x_{0}=0\\). Indeed, \\[\nx_{0}= \\alpha_{1}x_{1}+\\beta_{1} \\quad \\hbox{and} \\quad x_{0}=0 \\quad \\Rightarrow \\quad\n\\alpha_{1}x_{1}+\\beta_{1}=0.\n\\tag{9.11}\\] To satisfy the last equation, we choose \\(\\alpha_{1}=0\\) and \\(\\beta_{1}=0\\). Once we know all \\(\\alpha_{i}\\) and \\(\\beta_{i}\\), we compute \\(x_{n}, x_{n-1}, \\dots, x_{1}\\) using formula Eq. 9.6.\nFormulae Eq. 9.6 and Eq. 9.10 will work provided that the coefficients \\(L_{i}\\), \\(U_{i}\\) and \\(D_{i}\\) are such that \\(D_{i}+\\alpha_{i}L_{i}\\neq 0\\) for \\(i=1,\\dots,n\\). For tridiagonal systems that arise in finite-difference methods for differential equations, the coefficients \\(L_{i}\\), \\(U_{i}\\) and \\(D_{i}\\) usually satisfy the inequalities \\[\nL_{i}, U_{i} &gt; 0, \\quad  D_{i} &lt; 0, \\quad -D_{i} \\geq L_{i} + U_{i}.  \n\\tag{9.12}\\] It can be shown that these restrictions on \\(L_{i}\\), \\(U_{i}\\) and \\(D_{i}\\) are sufficient for the double-sweep method to work.\nThe following function implements this method in Python:\n\nimport numpy as np\n\ndef solve_tridiagonal(U, L, D, F):\n    \"\"\"\n    Solve a tridiagonal system using the double-sweep method.\n    \n    Parameters:\n    -----------\n    U : Upper diagonal elements (U[-1] is not used)\n    L : Lower diagonal elements (L[0] is not used)\n    D : Main diagonal elements\n    F : Right hand side vector\n        \n    Returns:\n    --------\n    x : ndarray\n        Solution vector\n        \n    Raises:\n    -------\n    ValueError\n        If the coefficients don't satisfy the conditions from equation (y23):\n        L_i, U_i &gt; 0, D_i &lt; 0, and -D_i ≥ L_i + U_i\n    \"\"\"\n    n = len(F)\n    \n    # Check conditions from equation (y23)\n    # Skip U[-1] and L[0] as they are not used\n    if not np.all(U[:-1] &gt; 0):\n        raise ValueError(\"Condition U_i &gt; 0 not satisfied\")\n    if not np.all(L[1:] &gt; 0):\n        raise ValueError(\"Condition L_i &gt; 0 not satisfied\")\n    if not np.all(D &lt; 0):\n        raise ValueError(\"Condition D_i &lt; 0 not satisfied\")\n    \n    # Check -D_i ≥ U_i + L_i for i=1,...,n-1\n    # For i=1: only need U[0] since L[1] is the first lower diagonal element\n    if -D[0] &lt; U[0]:\n        raise ValueError(\"Condition -D_1 ≥ U_1 not satisfied\")\n    # For i=n: only need L[n] since U[n-1] is the last upper diagonal element\n    if -D[-1] &lt; L[-1]:\n        raise ValueError(\"Condition -D_n ≥ L_n not satisfied\")\n    # For i=2,...,n-1: need both L[i] and U[i-1]\n    if not np.all(-D[1:-1] &gt;= L[2:] + U[:-2]):\n        raise ValueError(\"Condition -D_i ≥ L_i + U_i not satisfied\")\n    \n    alpha = np.zeros(n + 1)\n    beta = np.zeros(n + 1)\n    x = np.zeros(n + 1)\n    \n    # First sweep: forward\n    # Initial conditions: alpha[1] = beta[1] = 0\n    for i in range(n):\n        denominator = D[i] + alpha[i] * L[i]\n        alpha[i+1] = -U[i] / denominator\n        beta[i+1] = (F[i] - L[i] * beta[i]) / denominator\n    \n    # Second sweep: backward\n    # Initial condition: x[n+1] = 0\n    for i in range(n-1, -1, -1):\n        x[i] = alpha[i+1] * x[i+1] + beta[i+1]\n    \n    return x[0:n]\n\nLet us look at a simple example of a tri-diagonal system:\n\nL = np.array([0, 1, 1, 1, 1])  # lower diagonal (L₂ to Lₙ)\nU = np.array([1, 1, 1, 1, 0])  # upper diagonal (U₁ to Uₙ₋₁)\nD = np.array([-2, -2, -2, -2, -2])  # main diagonal (D₁ to Dₙ)\nF = np.array([1, 0, 0, 0, 1])  # right-hand side\n\n# Solve using our function\nx = solve_tridiagonal(U, L, D, F)\nprint(\"Solution:\", x)\n\nSolution: [-1. -1. -1. -1. -1.]\n\n\nLet’s check that \\(x\\) does indeed satisfy Eq. 9.1. First we need to construct the full matrix \\(A\\).\n\n# First, construct the full matrix\nn = L.size\nA = np.zeros((n, n))\nfor i in range(n):\n    if i &lt; n-1:\n        A[i, i+1] = U[i]  # upper diagonal\n    A[i, i] = D[i]        # main diagonal\n    if i &gt; 0:\n        A[i, i-1] = L[i]  # lower diagonal\nA\n\narray([[-2.,  1.,  0.,  0.,  0.],\n       [ 1., -2.,  1.,  0.,  0.],\n       [ 0.,  1., -2.,  1.,  0.],\n       [ 0.,  0.,  1., -2.,  1.],\n       [ 0.,  0.,  0.,  1., -2.]])\n\n\nNow we can use Python’s matrix multiplication opeator @ to calculate \\(A\\mathbf{x}\\):\n\nA @ x\n\narray([ 1.00000000e+00, -2.22044605e-16,  0.00000000e+00,  0.00000000e+00,\n        1.00000000e+00])\n\n\nThis indeed agrees with \\(\\mathbf{F}\\) up to rounding errors.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>A direct method for solving tridiagonal linear systems</span>"
    ]
  },
  {
    "objectID": "ivp.html",
    "href": "ivp.html",
    "title": "10  Initial Value Problems",
    "section": "",
    "text": "10.1 Introduction\nThe topic of this and the next chapter is to find approximate solutions to ordinary differential equations.\nLet us briefly recall what an ordinary differential equation (ODE) is. A rather arbitrarily chosen example for an ODE (here, of second order) is \\[\ny''(x) +  4 y'(x) + \\sqrt[3]{y(x)} + \\cos(x) = 0.\n\\tag{10.1}\\] Equations like this are normally satisfied by many functions \\(y(x)\\): the problem has many solutions. In order to specify a uniquely solvable problem, one needs to fix initial values, i.e., the value of \\(y\\) and its first derivative at some point, say, at \\(x=0\\): \\[\ny''(x) +  4 y'(x) + \\sqrt[3]{y(x)} + \\cos(x) = 0, \\quad y(0)=1,\\; y'(0)=-2.\n\\tag{10.2}\\] This is a so-called initial-value problem (IVP). Another variant is to specify the value of \\(y(x)\\), but not of its derivative, at two different points: \\[\ny''(x) +  4 y'(x) + \\sqrt[3]{y(x)} + \\cos(x) = 0, \\quad y(0)=2,\\; y(1)=1.\n\\tag{10.3}\\] This is called a boundary value problem (BVP).\nBoth IVPs and BVPs have a unique solution (under certain mathematical conditions). However, while one can show on abstract grounds that these solutions exist, it is often not practicable to find an explicit expression for them. The best one can hope for is to approximate the solution numerically. This is exactly our topic: to find approximation algorithms for the solutions of IVPs (this chapter) and BVPs (in Chapter 11).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "ivp.html#sec-euler",
    "href": "ivp.html#sec-euler",
    "title": "10  Initial Value Problems",
    "section": "10.2 Euler’s Method",
    "text": "10.2 Euler’s Method\nFor studying initial value problems (IVPs) for ordinary differential equations, let us start with the simplest known approximation scheme: Euler’s method. We will focus on direct computations here, and defer more in-depth discussions of the mathematical foundations to later.\nWe consider an IVP for a first-order equation, of the form \\[\ny'(x) = f(x,y(x)),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha.\n\\tag{10.4}\\] Here \\(a\\), \\(b\\) and \\(\\alpha\\) are some real numbers, and \\(f\\) is a function \\(\\mathbb{R}^2 \\to \\mathbb{R}\\). (For a concrete example, see Example 10.1 below.) Under certain conditions on \\(f\\) — to be discussed in Section 10.3 — one knows that the problem has a unique solution; that is, that there is exactly one function \\(y(x)\\) defined on \\([a,b]\\) which satisfies Eq. 10.4. We often call \\(y(x)\\) the exact solution of the IVP. However, it is often difficult or even impossible to find an explicit expression for \\(y(x)\\). Our aim here is to approximate the solution numerically.\n\n10.2.1 The method\n\n\n\n\n\n\nFigure 10.1: Euler’s method\n\n\n\nThe idea behind Euler’s method is as follows (see Figure 10.1 for a visualization): We pick \\(N \\in \\mathbb{N}\\), and divide the interval \\([a,b]\\) into \\(N\\) subintervals of equal length, \\(h = (b-a)/N\\). The end points of these intervals are \\[\nx_i = a + i h, \\quad i = 0,\\ldots,N.\n\\tag{10.5}\\]\nTerminology: \\(N\\) is called the number of steps and \\(h\\) is called the step size. The points \\(x_0,\\ldots,x_N\\in[a,b]\\) are referred to as mesh points.\nWe will approximate the exact solution \\(y\\) only at the mesh points \\(x_i\\); that is, we are looking for numbers \\(w_0,\\ldots,w_N\\) such that \\(y(x_i) \\approx w_i\\).\nThe first approximation \\(w_0\\) is easy to choose: We know that \\(y\\) satisfies the initial condition, \\(y(x_0) = y(a) = \\alpha\\). Thus we set \\(w_0:=\\alpha\\); this is even exact.\nFor finding \\(w_1 \\approx y(x_1)\\), we use linear approximation: \\[\n\\begin{split}\n   y(x_1) &= y(x_0+h) \\approx y(x_0) + h y'(x_0) \\\\\n   &\\overset{(*)}{=} y(x_0) + h f(x_0,y(x_0)) = w_0 + hf(x_0,w_0).\n\\end{split}\n\\tag{10.6}\\] For the equality \\((*)\\), we have used that \\(y\\) satisfies the ODE Eq. 10.4.\nIn the same way, we can find an approximation for \\(y(x_2)\\): \\[\n\\begin{split}\n   y(x_2) &= y(x_1+h) \\approx y(x_1) + h y'(x_1) \\\\\n   &\\overset{(*)}{=} y(x_1) + h f(x_1,y(x_1)) \\overset{(\\circ)}{\\approx} w_1 + hf(x_1,w_1).\n\\end{split}\n\\tag{10.7}\\] Our approximation value is \\(w_2 := w_1 + hf(x_1,w_1)\\). Note that we have used another approximation step \\((\\circ)\\), using that \\(y(x_1)\\approx w_1\\) and that \\(f\\) is sufficiently smooth; we will come back to this point in Section 10.2.2. We can continue the scheme for \\(w_3\\), \\(w_4\\), etc.: \\[\nw_0 := \\alpha,\n\\tag{10.8}\\] \\[\nw_1 := w_0 + h f(x_0,w_0),\n\\tag{10.9}\\] \\[\nw_2 := w_1 + h f(x_1,w_1),\n\\tag{10.10}\\] \\[\\begin{equation*}\n\\vdots\n\\end{equation*}\\] \\[\nw_{i+1} := w_i + h f(x_i,w_i).\n\\tag{10.11}\\] So the \\(w_i\\) are defined recursively. Eq. 10.11 is called the difference equation of Euler’s method.\n\nExample 10.1 Let us consider the IVP \\[\n  y'(x) = y(x)-x^2+1,  \\quad 0 \\leq x \\leq 1, \\quad y(0) = \\frac{1}{2}.\n\\tag{10.12}\\] In this case, the exact solution can be found using an integrating factor. It is\n\\[\n  y(x) = (x+1)^2-\\frac{1}{2} e^x.\n\\tag{10.13}\\] This will allow us to compare the approximation with the exact solution. It is generally a good idea to test one’s numerical method on an example where one already knows the exact solution.\nWe choose \\(N=10\\) steps, i.e., \\(h=1/10\\). Here we shall only compute the first two steps. By Eq. 10.8, we certainly have \\[\nx_0 = 0, \\quad w_0=\\frac{1}{2}.\n\\tag{10.14}\\] This allows us to compute the approximation \\(w_1\\) at the mesh point \\(x_1=1/10\\), namely, by Eq. 10.9, \\[\n\\begin{split}\nw_1&=w_0+h f(x_0,w_0)\n= w_0 + h (w_0-x_0^2+1)\\\\\n&= \\frac{1}{2} + \\frac{1}{10} \\left(\\frac{1}{2}-0+1\\right) = \\frac{1}{2} + \\frac{3}{20}\\\\\n&= \\frac{13}{20}.\n\\end{split}\n\\tag{10.15}\\] Continuing the iteration to \\(x_2=2/10\\), we have by Eq. 10.10 that \\[\n\\begin{split}\n  w_2&=w_1+h f(x_1,w_1)\n= w_1 + h (w_1-x_1^2+1)\n\\\\\n&= \\frac{13}{20} + \\frac{1}{10} \\left(\\frac{13}{20}-\\left(\\frac{1}{10}\\right)^2+1 \\right)\n= \\frac{13}{20} + \\frac{1}{10} \\cdot \\frac{174}{100}\\\\\n&= \\frac{407}{500}.\n\\end{split}\n\\tag{10.16}\\]\nContinuing further, we would obtain the values shown in Table 10.1. The values of the exact solution Eq. 10.13, evaluated to 9 decimals, are added for comparison. The last column, the error bound, will be discussed shortly.\n\n\n\n\nTable 10.1: Approximation values and errors for Euler’s Method\n\n\n\n\n\n\\(i\\)\n\\(x_i\\)\n\\(w_i\\)\n\\(y(x_i)\\)\n\\(|y(x_i)-w_i|\\)\nerror bound\n\n\n\n\n0\n0\n0.5\n0.5\n0\n0\n\n\n1\n0.1\n0.65\n0.657414541\n0.007414541\n0.0078878189\n\n\n2\n0.2\n0.814\n0.829298621\n0.015298621\n0.0166052069\n\n\n3\n0.3\n0.9914\n1.015070596\n0.023670596\n0.0262394106\n\n\n4\n0.4\n1.18154\n1.214087651\n0.032547651\n0.0368868524\n\n\n5\n0.5\n1.383694\n1.425639364\n0.041945364\n0.0486540953\n\n\n6\n0.6\n1.5970634\n1.648940600\n0.051877200\n0.0616589100\n\n\n7\n0.7\n1.82076974\n1.883123646\n0.062353906\n0.0760314530\n\n\n8\n0.8\n2.053846714\n2.127229536\n0.073382822\n0.0919155696\n\n\n9\n0.9\n2.295231385\n2.380198444\n0.084967059\n0.1094702333\n\n\n10\n1.0\n2.543754524\n2.640859086\n0.097104562\n0.1288711371\n\n\n\n\n\n\n\n\n\n\n10.2.2 Error bounds\nDenote the error at step \\(i\\) of Euler’s method by \\[\n\\varepsilon_i=y(x_i)-w_i.\n\\tag{10.17}\\] Clearly \\(\\varepsilon_0=0\\). We can represent \\(\\varepsilon_1\\) as follows: assuming the second derivative \\(y''\\) exists on \\((a,b)\\), we can use Taylor’s Theorem to give \\[\ny(x_1)=y(x_0+h)=y(x_0)+hy'(x_0)+\\frac{h^2y''(\\xi_1)}{2}\n\\tag{10.18}\\] for some \\(\\xi_1\\in(x_0,x_1)\\). Now, \\(y\\) is a solution to the IVP so \\(y(x_0)=y(a)=\\alpha=w_0\\) and \\(y'(x_0)=f(x_0,y(x_0))=f(x_0,\\alpha)=f(x_0,w_0)\\) and, by definition of \\(w_1\\), \\[\ny(x_0)+hy'(x_0)=w_0+hf(x_0,w_0)=w_1.\n\\tag{10.19}\\] Substituting this gives \\[\ny(x_1)=w_1+\\frac{h^2y''(\\xi_1)}{2}.\n\\tag{10.20}\\] So the error after one step can be written as \\[\n\\varepsilon_1=y(x_1)-w_1=\\frac{h^2y''(\\xi_1)}{2}.\n\\tag{10.21}\\] Although we do not know what \\(y''(\\xi_1)\\) is, this does show how the error depends on the step length: it behaves like a multiple of \\(h^2\\).\nWe can now make an optimistic guess: if every step contributes a multiple of \\(h^2\\), then the total error at the end, after \\(N\\) steps, will be some multiple of \\(Nh^2=(Nh)h=(b-a)h\\). As \\(h\\to 0\\), this tends to zero (whatever the unknown constants are) so the approximate solution converges to the exact solution. It turns out that this is basically correct, although much more careful reasoning is needed, as we shall see when we look at the error after the second step.\nWe can try to analyse the second step in the same way as the first step: use Taylor’s Theorem to write \\[\ny(x_2)=y(x_1+h)=y(x_1)+hy'(x_1)+\\frac{h^2y''(\\xi_2)}{2}\n\\tag{10.22}\\] and use the fact that \\(y\\) is a solution of the DE to substitute \\(y'(x_1)=f(x_1,y(x_1))\\): \\[\ny(x_2)=y(x_1)+hf(x_1,y(x_1))+\\frac{h^2y''(\\xi_2)}{2}.\n\\tag{10.23}\\] At this point, things look different: in the first step, we had \\(y(x_0)=y(a)=\\alpha\\), but here we do not have \\(y(x_1)=w_1\\): the first step starts at \\((x_0,w_0)=(a,\\alpha)\\), which lies exactly on the solution curve, but the second step starts at \\((x_1,w_1)\\), which does not lie on the solution curve. However, \\(w_1\\) is an approximation to \\(y(x_1)\\), and we have an expression for the error, namely \\(\\varepsilon_1\\). Substituting \\(y(x_1)=w_1+\\varepsilon_1\\) gives \\[\ny(x_2)=w_1+\\varepsilon_1+hf(x_1,w_1+\\varepsilon_1)+\\frac{h^2y''(\\xi_2)}{2}.\n\\tag{10.24}\\] Now, \\(w_1+hf(x_1,w_1+\\varepsilon_1)\\) is very similar to the formula for \\(w_2\\): the only difference is that it has \\(w_1+\\varepsilon_1\\), instead of \\(w_1\\). As we did for for \\(y(x_1)\\), we can think of this as being an approximation plus an error: \\[\n\\underbrace{f(x_1,w_1+\\varepsilon_1)}_{\\text{exact}}=\\underbrace{f(x_1,w_1)}_{\\text{approx}}+\n\\underbrace{[f(x_1,w_1+\\varepsilon_1)-f(x_1,w_1)]}_{\\text{error}}\n\\tag{10.25}\\] leading to \\[\ny(x_2)=\\varepsilon_1+\\underbrace{w_1+hf(x_1,w_1)}_{=w_2}+h[f(x_1,w_1+\\varepsilon_1)-f(x_1,w_1)]\\frac{h^2y''(\\xi_2)}{2},\n\\tag{10.26}\\] which, as intended, forces \\(w_2\\) to appear: \\[\ny(x_2)=\\varepsilon_1+w_2+h[f(x_1,w_1+\\varepsilon_1)-f(x_1,w_1)]+\\frac{h^2y''(\\xi_2)}{2}.\n\\tag{10.27}\\] Subtracting \\(w_2\\) from both sides gives \\[\n\\varepsilon_2=\\varepsilon_1+h[f(x_1,w_1+\\varepsilon_1)-f(x_1,w_1)]+\\frac{h^2y''(\\xi_2)}{2}.\n\\tag{10.28}\\] This describes the error at step 2 as the sum of three terms which can be thought of as:\n\n\\(\\varepsilon_1\\), the error carried forward from step 1;\n\\(h[f(x_1,w_1+\\varepsilon_1)-f(x_1,w_1)]\\), the error caused by starting at \\((x_1,w_1)\\), which is not on the solution curve;\n\\(h^2y''(\\xi_2)/2\\), the error built into Euler’s method by the approximation \\(y(x+h)\\approx y(x)+hy'(x)\\).\n\nThis analysis works for every step: we have \\[\n\\varepsilon_{i+1}=\\varepsilon_i+h[f(x_i,w_i+\\varepsilon_i)-f(x_i,w_i)]+\\frac{h^2y''(\\xi_{i+1})}{2},\n\\tag{10.29}\\] where \\(\\xi_{i+1}\\in(x_i,x_{i+1})\\). This is a recurrence relation for \\(\\varepsilon_i\\), and \\(\\varepsilon_0=0\\). Now, we need to ask how large the different contributions can be. For the truncation error inherent in Euler’s method, we simply assume that there is a constant \\(M\\) such that \\(|y''(x)|\\leq M\\) for all \\(x\\in[a,b]\\). For the error associated with starting away from the solution curve, we use Taylor’s Theorem yet again: assuming \\(f\\) is differentiable in the second variable, we can write \\[\nf(x_i,w_i+\\varepsilon_i)-f(x_i,w_i)=\\varepsilon_i\\frac{\\partial}{\\partial z}f(x_i,z)\\bigg|_{z=\\eta_i}\n\\tag{10.30}\\] for some \\(\\eta_i\\in(w_i,w_i+\\varepsilon_i)\\). We now make the assumption that there is a constant \\(L\\) such that \\[\n\\left|\\frac{\\partial}{\\partial z}f(x,z)\\right|\\leq L\n\\tag{10.31}\\] for all \\(x\\in[a,b]\\) and all \\(z\\). This leads to \\[\n|h[f(x_i,w_i+\\varepsilon_i)-f(x_i,w_i)]|=h|f(x_i,w_i+\\varepsilon_i)-f(x_i,w_i)|\\leq hL|\\varepsilon_i|.\n\\tag{10.32}\\] Using the triangle inequality on the formula for \\(\\varepsilon_{i+1}\\), we have \\[\n\\begin{split}\n|\\varepsilon_{i+1}|&\\leq|\\varepsilon_i|+Lh|\\varepsilon_i|+\\frac{Mh^2}{2}=(1+Lh)|\\varepsilon_i|+\\frac{Mh^2}{2}\\\\\n&=(1+Lh)|\\varepsilon_i|+h\\tau(h),\n\\end{split}\n\\tag{10.33}\\] where \\(\\tau(h)=Mh/2\\) (this is just a convenient abbreviation, which makes the final answer look tidy). We can apply this estimate repeatedly, starting off with \\(\\varepsilon_0=0\\), to find an estimate for the error after any number of steps. \\[\n\\begin{aligned}\n|\\varepsilon_0| &= 0 \\\\\n|\\varepsilon_1| &\\leq h\\tau(h) \\\\\n|\\varepsilon_2| &\\leq (1+Lh)|\\varepsilon_1|+h\\tau(h) \\\\\n         &\\leq [(1+Lh)+1]h\\tau(h) \\\\\n|\\varepsilon_3| &\\leq (1+Lh)|\\varepsilon_2|+h\\tau(h) \\\\\n         &\\leq [(1+Lh)^2+(1+Lh)+1]h\\tau(h) \\\\\n         &\\vdots \\\\\n|\\varepsilon_n| &\\leq [(1+Lh)^{n-1}+(1+Lh)^{n-2}+\\dots+1]h\\tau(h).\n\\end{aligned}\n\\tag{10.34}\\] This final formula can be proved by induction. This is a geometric sum, so we can use the standard formula to give for \\(1\\leq n\\leq N\\) \\[\n|\\varepsilon_n|\\leq h\\tau(h)\\sum_{i=0}^{n-1}(1+Lh)^i=h\\tau(h)\\frac{(1+Lh)^n-1}{Lh}\n\\tag{10.35}\\] and the \\(h\\) terms in the numerator and denominator cancel (this is why the abbreviated the Taylor’s Theorem estimate as \\(h\\tau(h)\\)). The dependency on \\(n\\) is awkward here, so we use the fact that \\(1+x\\leq e^x\\) for all \\(x\\) to replace \\(1+Lh\\) by \\(e^{Lh}\\): \\[\n|\\varepsilon_n|\\leq\\frac{\\tau(h)}{L}(e^{Lhn}-1)''\n\\tag{10.36}\\] Now, \\(hn\\) is the distance from \\(x_0=a\\) to \\(x_n\\), so \\[\n|\\varepsilon_n|\\leq\\frac{\\tau(h)}{L}(e^{L(x_n-a)}-1).\n\\tag{10.37}\\] The RHS increases exponentially as \\(x_n\\) increases, with the maximum value at \\(x_n=b\\), so we can finally conclude that \\[\n|\\varepsilon_N|\\leq\\frac{\\tau(h)}{L}(e^{L(x_n-a)}-1)\\leq\\frac{\\tau(h)}{L}(e^{L(b-a)}-1).\n\\tag{10.38}\\]\nIn all cases, we see that the error is bounded above by a multiple of \\(\\tau(h)\\), which is itself a multiple of \\(h\\) (because \\(\\tau(h)=Mh/2\\)). The multiplier depends on the width of the interval on which we solve the equation but, crucially, if we fix the interval then the multiplier does not change as we decrease the step size. The error therefore tends to zero as \\(h\\to 0\\) (equivalently, as \\(N\\to\\infty\\)), so the approximate solution converges to the exact solution.\n\nExample 10.2 (Example for error bounds) Let us reconsider Example 10.1, with \\(f(x,y)= y-x^2+1\\), and compute the error bounds. We have \\(\\partial f / \\partial y = 1\\), so we have \\(L=1\\) – see Eq. 10.31. For the constant \\(M\\), we use the fact that we know the exact solution: \\(y(x)=(x+1)^2-e^x/2\\). This gives us \\(y''(x)=2-e^x/2\\), which, on the interval \\([0,1]\\), is bounded by \\(3/2\\) (its value at \\(0\\)). So \\(M = 3/2\\). Inserting, this gives us \\[\n|y(x_i)-w_i| \\leq \\frac{3}{40} \\big( e^{(x_i-a)} - 1 \\big).\n\\tag{10.39}\\] These bounds are included in Table 10.1. You can see that the actual errors are indeed below the bounds, but not very much, particularly for small \\(x\\).\n\nOf course, using the exact solution in the error bounds can be considered “cheating” to some extent, since the exact solution of the ODE is in general unknown. There are methods for obtaining estimates for the constant \\(M\\) even if \\(y(x)\\) is not explicitly known, but we will not discuss them at this point.\n\nWith the Euler method, we have an approximation algorithm for the generic initial value problem Eq. 10.4, which works for any sufficiently smooth \\(f\\). We have found an explicit estimate Eq. 10.38 for the approximation error, which in particular shows that the approximation values converge to the exact solution, \\(w_i \\to y(x_i)\\) as \\(h \\to 0\\).\nHowever, the Euler method as presented here has two main shortcomings:\nFirst, the convergence is rather slow - only of order \\(O(h)\\). One would need to choose the step size \\(h\\) very small in order to arrive at a useful approximation. Decreasing \\(h\\) means, first of all, an increase in computation time. But also, small values of \\(h\\) make the difference equation Eq. 10.11 prone to roundoff errors; limits in floating point precision limit the usable range for \\(h\\). (For more details on the influence of roundoff errors on the approximation result, see for example (Burden and Faires 2010 Theorem 5.10).)\nSecond, we have formulated the method for a first-order ODE. Most applications, however, use higher-order ODEs (usually second-order), systems of first-order ODEs, or indeed a combination of both. Our approximation methods needs to be generalized to these cases in order to be useful in practice.\nNext we will introduce the generalizations needed for handling higher-order ODEs and systems of ODEs. In most textbooks, you will find this generalization only in later chapters, for example in Sec. 5.9 of (Burden and Faires 2010), or not at all. However, here I take the viewpoint that, while treating systems of ODEs is not really difficult, it is so important that it should be introduced right in the beginning! As we shall see, this can be boiled down to almost no more than a little change in notation.\n\n\n10.2.3 Systems of ODEs\nA generic initial value problem for a system of \\(m\\) first-order ODEs would look as follows: \\[\n\\begin{aligned}\ny_1\\,'(x) &= f_1(x,y_1(x),\\ldots,y_m(x)), \\\\\n&\\vdots\\\\\ny_m\\,'(x) &= f_m(x,y_1(x),\\ldots,y_m(x)),\n\\end{aligned}\n\\tag{10.40}\\] for \\(x\\) in some interval \\([a,b]\\), with initial values \\[\ny_1(a) = \\alpha_1, \\ldots, y_m(a) = \\alpha_m.\n\\tag{10.41}\\] Here \\(a\\), \\(b\\), \\(\\alpha_1,\\ldots,\\alpha_m\\) are given constants, and \\(f_1,\\ldots,f_m\\) are functions from \\(\\mathbb{R}\\times \\mathbb{R}^m\\) to \\(\\mathbb{R}\\). The exact solution of the system would consist of functions \\(y_1,\\ldots,y_m:[a,b] \\to \\mathbb{R}\\).\nThe idea of handling these ODE systems mainly involves rewriting them in a convenient way. To that end, let us introduce the vectors \\[\n\\begin{aligned}\n  \\boldsymbol{\\alpha}&= \\left(\\alpha_1,\\ldots,\\alpha_m\\right),\\\\\n  \\mathbf{y}&= \\left(y_1,\\ldots,y_m\\right),\n\\end{aligned}\n\\tag{10.42}\\] and the vector-valued function \\(\\mathbf{f}: \\mathbb{R} \\times \\mathbb{R}^m \\to \\mathbb{R}^m\\) given by \\[\n\\mathbf{f}(x,\\mathbf{y}) = \\left(f_1(x,y_1,\\ldots,y_m), \\ldots, f_m(x,y_1,\\ldots,y_m)\\right).\n\\tag{10.43}\\] With these, the IVP Eq. 10.40 for the ODE system reads \\[\n\\mathbf{y}'(x) = \\mathbf{f}(x,\\mathbf{y}(x)),  \\quad a \\leq x \\leq b, \\quad \\mathbf{y}(a) = \\boldsymbol{\\alpha}.\n\\tag{10.44}\\]\nNote the formal similarity with the analogue Eq. 10.4 for a single ODE! Our exact solution \\(\\mathbf{y}\\) is now a function from \\([a,b]\\) to \\(\\mathbb{R}^m\\).\nThe idea in generalizing our approximation methods to systems of ODEs is based on this formal similarity as well. For example, the difference equation for the “Euler method for ODE systems” reads \\[\n\\begin{aligned}\n   \\mathbf{w}_0 &:= \\boldsymbol{\\alpha},\\\\\n   \\mathbf{w}_{i+1} &:= \\mathbf{w}_i + h\\, \\mathbf{f}(x_i,\\mathbf{w}_i) \\quad (i=0,\\ldots,N-1).\n\\end{aligned}\n\\tag{10.45}\\] The approximation values \\(\\mathbf{w}_i\\) are now vectors in \\(\\mathbb{R}^m\\). The error estimates obtained in Section 10.2.2 carry over very directly to the case of ODE systems; more on this will follow in later sections.\n\n\n10.2.4 Second-order ODEs\nIn applications, one often meets second-order ODEs. Initial value problems for them can be defined as follows: \\[\ny'' (x) = f(x,y(x),y'(x)),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha, \\, y'(a)=\\alpha'.\n\\tag{10.46}\\]\nNote that we need to specify an additional initial value \\(\\alpha'\\in\\mathbb{R}\\) for the first derivative.\nFortunately, these can be rewritten into an equivalent system of first-order ODEs, so that they are — for our purposes — not really different from what was discussed above. Namely, we substitute \\(y\\) and \\(y'\\) with the components of a 2-vector \\(\\mathbf{u}\\): We set \\(u_1 = y\\), \\(u_2=y'\\).\nMore formally, this works as follows. Given a solution \\(y(x)\\) of Eq. 10.46, we set \\[\n   \\mathbf{g}(x,\\mathbf{u}) := \\big(u_2, f(x,u_1,u_2)\\big).\n\\tag{10.47}\\]\nIt is then easy to check that \\(\\mathbf{u}(x)\\) is a solution of the IVP\n\\[\n\\mathbf{u}' = \\mathbf{g}(x,\\mathbf{u}),  \\quad a \\leq x \\leq b, \\quad \\mathbf{u}(a) = \\boldsymbol{\\beta}.\n\\tag{10.48}\\]\nOn the other hand, given a solution \\(\\mathbf{u}(x)\\) of Eq. 10.48, we set \\(y(x):=u_1(x)\\), \\(\\alpha := \\beta_1\\), \\(\\alpha' := \\beta_2\\) and obtain a solution of Eq. 10.46. In this sense, Eq. 10.46 and Eq. 10.48 are equivalent; and for the purpose of developing numerical methods, it is sufficient if we consider the first-order system Eq. 10.48.\n\nExample 10.3 (Example of a second-order ODE) Let us illustrate the substitution process in an example. Consider the IVP for a second-order ODE, \\[\n\\begin{split}\n&y''(x) = y'(x)\\cos(x) +2 y(x),\\quad 0 \\leq x \\leq 1, \\\\\n&y(0) = 2, \\, y'(0)=-3.\n\\end{split}\n\\tag{10.49}\\]\nSo, \\(f(x,y,y')=y'\\cos(x) +2 y\\) in the present case. Using the rules in Eq. 10.47, we obtain an equivalent IVP for a system of two first-order equations: \\[\n\\mathbf{u}'(x) = \\begin{pmatrix}\n        u_2(x) \\\\ u_2(x)\\cos(x) +2 u_1(x)           \n        \\end{pmatrix},\n\\quad 0 \\leq x \\leq 1, \\quad \\mathbf{u}(0) = \\begin{pmatrix}\n        \\vphantom{-}2 \\\\ -3\n        \\end{pmatrix}.\n\\tag{10.50}\\] Once we have found an (approximate) solution for this system, we would set \\(y(x):=u_1(x)\\) and obtain an (approximate) solution of Eq. 10.49.\n\nWith similar methods, one can rewrite third-order, fourth-order, etc. ODEs as systems of first-order ODEs. Equally, systems of higher-order ODEs can be transformed into systems of first-order ODEs by appropriate substitutions. For example, systems of second-order ODEs are very common in Newtonian Mechanics: \\(N\\) particles moving in three-dimensional space are modelled using a system of \\(3N\\) coupled second-order ODEs, which can be transformed into a system of \\(6N\\) coupled first-order ODEs.\nThus, the most general case of IVP that we need to consider is given by Eq. 10.44. In the following, we will formulate all our approximation methods for this case.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "ivp.html#sec-ivpfundam",
    "href": "ivp.html#sec-ivpfundam",
    "title": "10  Initial Value Problems",
    "section": "10.3 Fundamentals",
    "text": "10.3 Fundamentals\nWe will now take a step back, and revisit the theory of initial value problems for ODEs and their numerical treatment from a more general perspective. In doing so, we will always consider initial value problems for systems of (first-order) ODEs, in the form Eq. 10.44. This means that we will make extensive use of techniques from Vector Calculus.\n\n10.3.1 Vectors and matrices\nIn order to describe numerical approximations of vectors, we will need a notion of distance between two vectors. Throughout this part of the course, we do not use the Euclidean norm for this purpose, but the maximum norm or \\(\\ell_\\infty\\) norm, which is given by\n\\[\n\\lVert \\mathbf{v} \\rVert_\\infty := \\max_{1\\leq i \\leq m}\\vert v_{i}\\vert.\n\\tag{10.51}\\]\nFrom now on, we will just write \\(\\lVert \\mathbf{v} \\rVert\\) instead of \\(\\lVert \\mathbf{v} \\rVert_\\infty\\).\nWe also need a corresponding norm for matrices \\(\\mathbf{A}\\in\\mathcal{M}(m,m)\\).\n\n\n10.3.2 Calculus in several variables\nWe will also need to work with functions that depend on vectors, and with vector-valued functions. For a review of the techniques of Calculus in several variables, see for example (Weir, Thomas, and Hass 2010 Ch. 14) or (Stewart 1991 Ch. 15). We give a very brief review here, in our notation.\nLet \\(f\\) be a function from \\(\\mathbb{R}^m\\) to \\(\\mathbb{R}\\) (a function of \\(m\\) variables). Instead of derivatives of functions of a single variable, one can consider partial derivatives of \\(f\\), denoted as \\[\n\\frac{\\partial f}{\\partial x_j}(\\mathbf{x}) = \\frac{d}{dt} f(x_1, \\ldots, x_j+t, \\ldots,  x_m) \\Big\\vert_{t=0},\n\\tag{10.52}\\] and higher order partial derivatives accordingly. If \\(\\mathbf{f}\\) is a vector-valued function, that is, \\(\\mathbf{f}: \\mathbb{R}^m \\to \\mathbb{R}^k\\), then all partial derivatives are vector-valued as well (each component is differentiated). All first derivatives of such a function can conveniently be combined into an \\(k\\times m\\) matrix, \\[\n\\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}} =  \\begin{pmatrix}\n        \\frac{\\partial f_1}{\\partial x_1} &\\cdots& \\frac{\\partial f_1}{\\partial x_m} \\\\\n         \\vdots & & \\vdots \\\\\n        \\frac{\\partial f ^{(k)}}{\\partial x_1} &\\cdots& \\frac{\\partial f ^{(k)}}{\\partial x_m}\n       \\end{pmatrix}\n\\tag{10.53}\\] The multi-dimensional chain rule can be expressed quite easily in this formalism: if \\(\\mathbf{f}\\) and \\(\\mathbf{g}\\) are vector-valued mappings such that \\(\\mathbf{g}\\circ \\mathbf{f}: \\mathbf{x}\\mapsto \\mathbf{g}(\\mathbf{f}(\\mathbf{x}))\\) is defined (i.e. the range of \\(\\mathbf{f}\\) matches the domain of \\(\\mathbf{g}\\)) then the derivative of \\(\\mathbf{g}\\circ \\mathbf{f}\\) is given by \\[\n\\frac{\\partial (\\mathbf{g}\\circ \\mathbf{f})}{\\partial \\mathbf{x}}\n=  \\frac{\\partial \\mathbf{g}}{\\partial \\mathbf{y}} \\cdot \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}}  .\n\\tag{10.54}\\] where \\(\\cdot\\) represents matrix multiplication. Higher-order derivatives can be treated in a similar, though somewhat more complicated matrix formalism.\nAlso, a generalization of Taylor’s theorem holds for functions of several variables. This is summarized in Appendix A.\n\n\n10.3.3 ODEs\nWe now treat initial value problems for ODEs in our vector formalism. In a first reading, it is always a useful exercise to reduce our statements to the case of one ODE (\\(m=1\\)), in which case the computations become more elementary. In this case, we can simply replace \\(\\mathbf{y}\\) with a scalar function \\(y\\), the initial value vector \\(\\boldsymbol{\\alpha}\\) with a number \\(\\alpha\\), the norm \\(\\lVert  \\, \\cdot \\,  \\rVert\\) with the absolute value \\(\\lvert \\, \\cdot \\, \\rvert\\), and so forth.\nLet us first define formally what we mean by a solution of an initial value problem.\n\nDefinition 10.1 Let \\(m \\in \\mathbb{N}\\), \\(a&lt;b \\in \\mathbb{R}\\), \\(\\boldsymbol{\\alpha}\\in \\mathbb{R}^m\\), and \\(\\mathbf{f}: [a,b]\\times \\mathbb{R}^m \\to \\mathbb{R}^m\\). We say that a function \\(\\mathbf{y}\\in\\mathcal{C}^1([a,b],\\mathbb{R}^m)\\) is a solution of the initial value problem (IVP) \\[\n\\mathbf{y}' = \\mathbf{f}(x,\\mathbf{y}),  \\quad a \\leq x \\leq b, \\quad \\mathbf{y}(a) = \\boldsymbol{\\alpha}\n\\tag{10.55}\\]\nif for all \\(x \\in [a,b]\\), \\[\n\\mathbf{y}'(x) = \\mathbf{f}(x,\\mathbf{y}(x)) \\quad \\text{and}  \\quad \\mathbf{y}(a)=\\boldsymbol{\\alpha}.\n\\tag{10.56}\\]\n\nOur first question is when such an IVP has a unique solution (so that we can reasonably search for a numerical approximation of it). The key condition involved here is the so-called Lipschitz condition.\n\nDefinition 10.2 We say that \\(\\mathbf{f}:[a,b]\\times \\mathbb{R}^m \\to \\mathbb{R}^m\\) satisfies a Lipschitz condition if there is a constant \\(L&gt;0\\) such that for all \\(x \\in [a,b]\\) and \\(\\mathbf{y},\\hat{\\mathbf{y}}\\in\\mathbb{R}^m\\),\n\\[\n  \\lVert  \\mathbf{f}(x,\\mathbf{y}) - \\mathbf{f}(x,\\hat{\\mathbf{y}})  \\rVert \\leq L \\| \\mathbf{y}-\\hat{\\mathbf{y}}\\|.\n\\tag{10.57}\\] The constant \\(L\\) above is called a Lipschitz constant.\n\nThe Lipschitz condition is in a sense an intermediate concept between continuity and differentiability. Often, we can use a simple criterion to check it — in fact, we already have, in the definition of the constant \\(L\\) in the error analysis of Euler’s method in one variable.\n\nLemma 10.1 If \\(\\partial \\mathbf{f}/ \\partial \\mathbf{y}\\) exists and is bounded, then \\(\\mathbf{f}\\) satisfies a Lipschitz condition with Lipschitz constant \\[\nL = \\sup\\left\\{ \\Big\\lVert \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{y}} (x,\\mathbf{y}) \\Big\\rVert  : x \\in [a,b], \\mathbf{y}\\in \\mathbb{R}^m \\right\\}.\n\\tag{10.58}\\]\n\nNote here that \\(\\partial \\mathbf{f}/ \\partial \\mathbf{y}\\) is an \\(m \\times m\\) matrix! Again, you may first want to consider the case \\(m=1\\).\n\nProof. Given \\(x \\in [a,b]\\), \\(\\mathbf{y},\\hat{\\mathbf{y}}\\in \\mathbb{R}^m\\), and \\(j \\in \\{1,\\ldots, m\\}\\), consider the function \\(g:[0,1]\\to\\mathbb{R}\\) defined by \\(g(t)=f_j((1-t)\\hat{\\mathbf{y}}+t\\mathbf{y})\\), so \\(g(0)=\\hat{\\mathbf{y}}\\) and \\(g(1)=\\mathbf{y}\\), and apply the scalar MVT to give \\(\\mathbf{y}-\\hat{\\mathbf{y}}=g(1)-g(0)=g'(t_0)\\) for some \\(t_0\\in(0,1)\\); now, using the chain rule, \\[\n\\begin{split}\ng'(t)&=\\frac{\\partial f_j}{ \\partial \\mathbf{y}}(x,(1-t)\\hat{\\mathbf{y}}+t\\mathbf{y})\\cdot\\frac{d}{dt}((1-t)\\hat{\\mathbf{y}}+t\\mathbf{y})\\\\\n&=\\frac{\\partial f_j}{ \\partial \\mathbf{y}}(x,(1-t)\\hat{\\mathbf{y}}+t\\mathbf{y})\\cdot(\\mathbf{y}-\\hat{\\mathbf{y}}).\n\\end{split}\n\\tag{10.59}\\] Combining these gives us \\[\nf_j(x,\\mathbf{y}) - f_j(x,\\hat{\\mathbf{y}}) =\n\\frac{\\partial f_j}{ \\partial \\mathbf{y}}(x,\\boldsymbol{\\eta}) \\cdot (\\mathbf{y}-\\hat{\\mathbf{y}})\n\\tag{10.60}\\] where \\(\\boldsymbol{\\eta}=(1-t_0)\\hat{\\mathbf{y}}+t_0\\mathbf{y}\\). Using the property of the vector norm of the scalar product (see Definition 4.1) we find \\[\n| f_j(x,\\mathbf{y}) - f_j(x,\\hat{\\mathbf{y}}) | \\leq  \n   \\Big\\lVert \\frac{\\partial f_j}{ \\partial \\mathbf{y}} (x,\\boldsymbol{\\eta}) \\Big\\rVert\n\\, \\| \\mathbf{y}-\\hat{\\mathbf{y}}\\|\n    \\leq L \\| \\mathbf{y}-\\hat{\\mathbf{y}}\\|\n\\tag{10.61}\\] with \\(L\\) as in Eq. 10.58. Taking the maximum over \\(j\\) implies the result. ◻\n\nWhy do we consider this kind of condition? Because the Lipschitz condition is the essential ingredient for the well-definedness of the initial value problem. Namely, one has:\n\nTheorem 10.1 Let \\(\\mathbf{f}: [a,b]\\times \\mathbb{R}^m \\to \\mathbb{R}^m\\) be continuous and satisfy a Lipschitz condition. Then, for any \\(\\boldsymbol{\\alpha}\\in \\mathbb{R}^m\\), the initial value problem Eq. 10.55 has a unique solution \\(\\mathbf{y}\\).\n\nThis theorem is given here without proof. (It is one of the central theorems in the theory of ordinary differential equations. See (Burden and Faires 2010 Theorem 5.17) for references.)\nThe Lipschitz condition is not only relevant for the abstract existence of a solution. Recalling Eqs. Eq. 10.30–Eq. 10.31, we see that it also enters our error estimates for numeric approximations. We will analyse this in more detail later.\nLet us discuss a few examples for \\(m=1\\), on the interval \\([a,b]=[0,2]\\).\n\nExample 10.4 (Unique solution) Let us recall the example Eq. 10.12, with \\(f(x,y)=y-x^2+1\\). This function is certainly continuous in both variables, and differentiable in \\(y\\). We have \\(\\partial f(x,y) / \\partial y = 1\\); in particular, the derivative is bounded. By Lemma 10.1, we have a Lipschitz constant \\(L=1\\) and thus, by Theorem 10.1, a unique solution of the IVP. In fact, for the initial condition \\(y(0)=1/2\\), the solution is given in Eq. 10.13.\n\n\nExample 10.5 (No solution) Consider \\(f(x,y)=y^2+1\\). Again, the function is continuous and differentiable. However, \\(\\partial f(x,y) / \\partial y = 2y\\) is unbounded, so Lemma 10.1 cannot be applied. Actually, we can explicitly see that \\(f\\) does not satisfy a Lipschitz condition. Namely, if it did, then the quotient \\[\n\\frac{|f(x,y)-f(x,\\hat{y})|}{|y-\\hat{y}|}         \\quad (\\text{for }x \\in [0,2],\\; y \\neq \\hat{y} \\in \\mathbb{R})\n\\tag{10.62}\\] would be bounded (by the Lipschitz constant \\(L\\)). However, in our case, set \\(\\hat{y}=0\\); then \\[\n\\frac{|f(x,y)-f(x,\\hat{y})|}{|y-\\hat{y}|}\n= \\frac{|y^2 +1-1|}{|y|} = |y|\n\\tag{10.63}\\] which is not bounded. So \\(f\\) cannot satisfy a Lipschitz condition.\nHence, for the corresponding initial value problem, \\[\ny' = y^2+1,  \\quad 0 \\leq x \\leq 2, \\quad y(0) = 0,\n\\tag{10.64}\\] the existence and uniqueness result Theorem 10.1 does not apply. In fact, a solution for small \\(x\\) is given by \\[\ny(x) = \\tan(x),\n\\tag{10.65}\\] but this solution does not exist for all \\(x \\in [0,2]\\).\nThe problem here is that \\(\\partial f(x,y) / \\partial y\\) is unbounded as \\(y\\) grows large. One can still control IVPs of this kind, using so-called local Lipschitz conditions, where the estimate Eq. 10.57 is required to hold only for \\((x,\\mathbf{y}),(x,\\hat{\\mathbf{y}})\\in \\mathcal{D}\\) with \\(\\mathcal{D}\\) any fixed compact set, and the Lipschitz constant \\(L\\) is allowed to depend on \\(\\mathcal{D}\\). Our numerical methods will still be applicable in this case, as long as we do not approach the possible singularities of the solution too closely. However, the formalism becomes much more complicated, and we do not treat these cases explicitly here.\n\n\nExample 10.6 (Non-unique solution) Consider \\(f(x,y)=\\sqrt[3]{y}\\). While \\(f\\) is continuous, the partial derivative \\(\\partial f(x,y) / \\partial y\\) does not exist at \\(y=0\\), so again, Lemma 10.1 cannot be applied. Indeed, set \\(\\hat{y}=0\\), then \\[\n\\frac{|f(x,y)-f(x,\\hat{y})|}{|y-\\hat{y}|}\n= \\frac{|y|^{1/3}}{|y|} = |y|^{-2/3}\n\\tag{10.66}\\] which is unbounded near \\(y=0\\). So \\(f\\) does not satisfy a Lipschitz condition, and we are not guaranteed a unique solution of the IVP \\[\ny' = \\sqrt[3]{y},  \\quad 0 \\leq x \\leq 2, \\quad y(0) = 0.\n\\tag{10.67}\\] In fact, this IVP has at least three solutions: \\[\ny(x)= \\Big(\\frac{2x}{3}\\Big)^{3/2},\\quad\ny(x)= -\\Big(\\frac{2x}{3}\\Big)^{3/2},\\quad\ny(x) = 0.\n\\tag{10.68}\\]\nThis case is, in a sense, worse than the other examples above. Running our numerical methods for the IVP Eq. 10.67 is likely to give unpredictable results; even a small rounding error might cause us to “switch” between the different solutions of the IVP.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "ivp.html#sec-onestep",
    "href": "ivp.html#sec-onestep",
    "title": "10  Initial Value Problems",
    "section": "10.4 One-Step Difference Methods",
    "text": "10.4 One-Step Difference Methods\nWe now return to the initial value problem Eq. 10.55: \\[\n\\mathbf{y}'(x) = \\mathbf{f}(x,\\mathbf{y}(x)),  \\quad a \\leq x \\leq b, \\quad \\mathbf{y}(a) = \\boldsymbol{\\alpha}.\n\\tag{10.69}\\] As in Euler’s method, we use equally-spaced mesh points \\(x_0,\\ldots,x_N\\) in the interval \\([a,b]\\), with a uniform step size \\(h=(b-a)/N\\), so \\(x_i=a+ih\\), and we seek approximate values \\(\\mathbf{w}_i\\in\\mathbb{R}^m\\), with \\(\\mathbf{w}_i\\approx\\mathbf{y}(x_i)\\).\nEuler’s method was based on the Taylor expansion \\[\n\\underbrace{y(x+h)}_\\text{exact}=\\underbrace{y(x)+hy'(x)}_{\\text{approx}}+\\underbrace{\\frac{h^2}{2}y''(\\xi)}_{\\text{error}}.\n\\tag{10.70}\\] Any other formula of this type can be used to define a similar method and, if the error term is smaller than the one in Euler’s method, should lead to smaller errors in the approximate solution. In complete generality, and for vectors instead of scalars, we consider a formula \\[\n\\mathbf{y}(x+h)=\\mathbf{y}(x)+h\\boldsymbol{\\phi}(x,\\mathbf{y}(x),h)+\\text{error}\n\\tag{10.71}\\] All the higher-order Taylor approximations fit in to this framework, as do the important Runge-Kutta methods described below. This leads to the general single-step method \\[\n\\begin{aligned}\n  \\mathbf{w}_0 &:= \\mathbf{\\alpha},\n\\\\\n  \\mathbf{w}_{i+1} &:= \\mathbf{w}_i + h \\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h).\n\\end{aligned}\n\\tag{10.72}\\] Introducing some notation for the error, we write \\[\n\\mathbf{y}(x_{i+1})=\\mathbf{y}(x_i)+h\\boldsymbol{\\phi}(x_i,\\mathbf{y}(x_i),h)+h\\boldsymbol{\\tau}_{i+1}(h)\n\\tag{10.73}\\] where \\(\\boldsymbol{\\tau}_{i+1}(h)\\), the local truncation error, is defined by \\[\n\\boldsymbol{\\tau}_{i+1}(h)=\\frac{1}{h}\\left[\\mathbf{y}(x_{i+1})-\\mathbf{y}(x_i)-h\\boldsymbol{\\phi}(x_i,\\mathbf{y}(x_i),h)\\right]\n\\tag{10.74}\\]\nIn terms of the numerical method, this is the error that would occur at step \\(i+1\\) if we started on the exact solution curve, divided by the step size. We assume we have an upper bound \\(\\tau(h)\\) such that, for some \\(h_0&gt;0\\), \\[\n\\|\\boldsymbol{\\tau}_i(h)\\|\\leq\\tau(h)\n\\tag{10.75}\\] for all \\(i\\in\\{0,\\ldots,N\\}\\) and all \\(h\\in(0,h_0]\\). For the method to be useful, we must have \\(\\tau(h)\\to 0\\) as \\(h\\to 0^+\\); in Euler’s method, \\(\\tau(h)=Mh/2\\) but in other methods \\(\\tau(h)\\) is much smaller than this: typically \\(\\tau(h)=O(h^n)\\) as \\(h\\to 0^+\\) for some \\(n&gt;1\\). We also assume the existence of a Lipschitz constant \\(L\\) such that \\[\n\\|\\boldsymbol{\\phi}(x, \\mathbf{y}, h)-\\boldsymbol{\\phi}(x, \\hat{\\mathbf{y}}, h)|\\leq L\\|\\mathbf{y}-\\hat{\\mathbf{y}}\\|\n\\tag{10.76}\\] for all \\(x\\in[a,b]\\), for all \\(\\mathbf{y},\\hat{\\mathbf{y}}\\in\\mathbb{R}^m\\) and all \\(h\\in(0,h_0]\\) (this replaces the second use of Taylor’s Theorem in the analysis of Euler’s method; looking back at that calculation, the Lipschitz constant is all that was needed). We conclude the setup by defining the actual error at step \\(i\\) by \\[\n\\boldsymbol{\\varepsilon}_i=\\mathbf{y}(x_i)-\\mathbf{w}_i.\n\\tag{10.77}\\]\nUnder these hypotheses, we have:\n\nTheorem 10.2 Consider an initial value problem as in Eq. 10.55, which we assume to have a solution \\(\\mathbf{y}\\). For this IVP, consider the one-step difference method described by Eq. 10.72. Then, \\[\n\\lVert \\mathbf{y}(x_i) - \\mathbf{w}_i \\rVert \\leq \\frac{\\tau(h)}{L} \\big(e^{L(x_i-a)}-1\\big)\n\\quad \\text{for all } h\\in(0,h_0], \\; i \\in \\{0,\\ldots,N\\}.\n\\tag{10.78}\\]\n\n\nProof. We establish this in much the same way as we did the corresponding result for Euler’s method. Starting with the Taylor-like formula for \\(\\mathbf{y}(x_{i+1})\\) in terms of \\(\\mathbf{y}(x_i)\\), \\(\\boldsymbol{\\phi}\\) and \\(\\boldsymbol{\\tau}_{i+1}\\), we have: \\[\n\\begin{aligned}\n\\mathbf{y}(x_{i+1}) &= \\mathbf{y}(x_i+h) \\\\\n             &= \\mathbf{y}(x_i)+h\\boldsymbol{\\phi}(x_i,\\mathbf{y}(x_i),h)+h\\boldsymbol{\\tau}_{i+1}(h) \\\\\n             &= \\boldsymbol{\\varepsilon}_i+\\underbrace{\\mathbf{w}_i+h\\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)}_{=\\mathbf{w}_{i+1}}+h[\\boldsymbol{\\phi}(x_i,\\mathbf{y}(x_i),h)-\\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)]+h\\boldsymbol{\\tau}_{i+1}(h) \\\\\n           &= \\boldsymbol{\\varepsilon}_i+\\mathbf{w}_{i+1}+h[\\boldsymbol{\\phi}(x_i,\\mathbf{y}(x_i),h)-\\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)]+h\\boldsymbol{\\tau}_{i+1}(h) \\\\\n\\end{aligned}\n\\tag{10.79}\\] so, subtracting \\(\\mathbf{w}_{i+1}\\) from both sides, \\[\n\\boldsymbol{\\varepsilon}_{i+1}=\\boldsymbol{\\varepsilon}_i+h[\\boldsymbol{\\phi}(x_i,\\mathbf{y}(x_i),h)-\\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)]+h\\boldsymbol{\\tau}_{i+1}(h)\n\\tag{10.80}\\] Exactly as for Euler’s method, we estimate using the triangle inequality \\[\n\\begin{split}\n\\|\\boldsymbol{\\varepsilon}_{i+1}\\|&\\leq\\|\\boldsymbol{\\varepsilon}_i\\|+h\\|\\boldsymbol{\\phi}(x_i,\\mathbf{y}(x_i),h)-\\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)\\|+\\|\\boldsymbol{\\tau}_{i+1}(h)\\|\\\\\n&\\leq(1+hL)\\|\\boldsymbol{\\varepsilon}_i\\|+h\\tau(h)\n\\end{split}\n\\tag{10.81}\\] using the Lipschitz hypothesis on \\(\\boldsymbol{\\phi}\\) and the upper bound \\(\\tau\\) for the local truncation errors. This is exactly the same formula as for Euler, so we can read off the same answer: \\[\n\\|\\boldsymbol{\\varepsilon}_n\\|\\leq\\frac{\\tau(h)}{L}(e^{L(x_n-a)}-1)\\leq\\frac{\\tau(h)}{L}(e^{L(b-a)}-1)\n\\tag{10.82}\\]\n\nThe main conclusion is that if we leave the integration width fixed and decrease the step size, then the error at each point is bounded above by a fixed multiple of \\(\\tau(h)\\): local error determines global error.\n\nThus, also in the general case, if the local truncation order is of order \\(O(h^n)\\), then the the global error is of the same order. In the following, we will see a variety of one-step methods which aim at achieving a low local truncation error. We will then only need to prove an estimate for \\(\\tau_{i}\\) as defined in Eq. 10.74, and the behaviour of the global error with \\(h\\) will be under control.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "ivp.html#taylor-methods",
    "href": "ivp.html#taylor-methods",
    "title": "10  Initial Value Problems",
    "section": "10.5 Taylor Methods",
    "text": "10.5 Taylor Methods\nWe will now see the first example of one-step difference methods (beyond Euler’s method), namely the so-called Taylor Methods.\nThe idea here is as follows. In Euler’s Method, we approximated the exact solution \\(y(x)\\) with a linear function, as in Eq. 10.23. In other words, we used a first-order Taylor expansion. For a better approximation, we can use an \\(n\\)-th order Taylor expansion, now for a vector-valued \\(\\mathbf{y}(x)\\): \\[\n\\begin{split}\n\\mathbf{y}(x_{i+1}) = \\mathbf{y}(x_i + h) = \\mathbf{y}(x_i)\n&+ h \\frac{d\\mathbf{y}}{dx}(x_i) + \\frac{h^2}{2} \\frac{d^2\\mathbf{y}}{dx^2}(x_i) + \\cdots\\\\\n&+ \\frac{h^n}{n!} \\frac{d^n\\mathbf{y}}{dx^n}(x_i) + \\mathbf{R}_i,\n\\end{split}\n\\tag{10.83}\\] where, according to Theorem A.3, the remainder term \\(\\mathbf{R}_i\\) is bounded by \\[\n\\left\\|\\mathbf{R}_i\\right\\| \\leq \\frac{h^{n+1}}{(n+1)!} \\sup_{x \\in [x_i, x_{i+1}]} \\left\\| \\frac{d^{n+1}\\mathbf{y}}{dx^{n+1}} (x) \\right\\|.\n\\tag{10.84}\\]\nFollowing our approach in the Euler method, we now need to replace the unknown exact solution \\(\\mathbf{y}(x)\\) in the right-hand side of Eq. 10.83 with expressions in the function \\(\\mathbf{f}\\). Since \\(\\mathbf{y}(x)\\) solves the ODE, we can certainly write\n\\[\n    \\frac{ \\mathrm{d}^{} \\mathbf{y} }{\\mathrm{d}x^{} } (x) = \\mathbf{f}(x,\\mathbf{y}(x)),\n\\tag{10.85}\\]\nTo obtain the second derivative, we need to differentiate this, which requires the use of the chain rule At this point, we need to use the chain rule in several variables: Even if \\(m=1\\), the function \\(f\\) depends on two variables, \\(x\\) and \\(y\\). One of the functions we need to consider (the outermost function) is the mapping from \\(\\mathbb{R}^{m+1}\\) to \\(\\mathbb{R}^m\\) \\[\n(x,y_1,\\dots,y_m)\\mapsto \\mathbf{f}(x,\\mathbf{y})\n\\tag{10.86}\\] The derivative of this is the \\(m\\times(m+1)\\) matrix given by\n\\[\n\\left[\\frac{\\partial\\mathbf{f}(x,\\mathbf{y})}{\\partial x}, \\frac{\\partial\\mathbf{f}(x,\\mathbf{y})}{\\partial \\mathbf{y}}\\right],\n\\tag{10.87}\\] which represents the \\(m\\times 1\\) column vector \\(\\partial\\mathbf{f}(x,\\mathbf{y})/\\partial x\\) being concatenated horizontally with the \\(m\\times m\\) matrix \\(\\partial\\mathbf{f}(x,\\mathbf{y})/\\partial \\mathbf{y}\\). The other function we need to consider (the innermost function) is the mapping from \\(\\mathbb{R}\\) to \\(\\mathbb{R}^{m+1}\\) \\[\nx\\mapsto[x,\\mathbf{y}(x)]:=(x,y_1(x),\\dots,y_m(x))\n\\tag{10.88}\\] whose derivative is the \\(m+1\\) dimensional column vector \\[\n\\begin{bmatrix}\n1 \\\\\n\\mathbf{y}'(x) \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 \\\\\n\\mathbf{f}(x, \\mathbf{y}(x)) \\\\\n\\end{bmatrix}\n\\tag{10.89}\\] where we have substituted for \\(\\mathbf{y}'(x)\\) using the differential equation. Here we have stacked the scalar \\(1\\) on top of the \\(m\\)-dimensional column vector \\(\\mathbf{y}'(x)=\\mathbf{f}(x,\\mathbf{y}(x))\\).\nNow, the derivative of the RHS of Eq. 10.85 is the product of the \\(m\\times(m+1)\\) matrix Eq. 10.87 and the \\(m+1\\) dimensional vector Eq. 10.89. This product has the general form \\[\n\\begin{bmatrix} A, B \\end{bmatrix}\n\\cdot\n\\begin{bmatrix} C \\\\ D \\end{bmatrix}\n=A\\cdot C+B\\cdot D\n\\tag{10.90}\\] (which works for any block matrices, provided all the sizes are compatible, i.e. provided \\(A\\cdot C+B\\cdot D\\) makes sense). We need to substitute \\[\nA=\\frac{\\partial\\mathbf{f}(x,\\mathbf{y})}{\\partial x}; \\qquad\nB= \\frac{\\partial\\mathbf{f}(x,\\mathbf{y})}{\\partial \\mathbf{y}}; \\qquad\nC= 1; \\qquad\nD= \\mathbf{f}(x,\\mathbf{y}(x))\n\\tag{10.91}\\] which gives us\n\\[\n\\frac{d^2 \\mathbf{y}}{d x^2}(x) = \\underbrace{ \\frac{\\partial \\mathbf{f}}{\\partial x}(x,\\mathbf{y}(x)) + \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{y}}\\cdot \\mathbf{f}(x,\\mathbf{y}(x)) }_{=: \\frac{ \\mathrm{d}^{} \\mathbf{f} }{\\mathrm{d}x^{} } (x,\\mathbf{y}(x))}.\n\\tag{10.92}\\]\nWe call the right-hand side the total derivative of \\(\\mathbf{f}\\).\nFor higher derivatives, we can apply an analogous argument: We define recursively, \\[\n\\begin{split}\n\\frac{ \\mathrm{d}^{0} \\mathbf{f}(x,\\mathbf{y}) }{\\mathrm{d}x^{0} }  &:= \\mathbf{f}(x,\\mathbf{y}),\\\\\n    \\frac{ \\mathrm{d}^{j+1} \\mathbf{f}(x,\\mathbf{y}) }{\\mathrm{d}x^{j+1} }  &:=\n\\frac{\\partial}{\\partial x}  \\frac{ \\mathrm{d}^{j} \\mathbf{f}(x,\\mathbf{y}) }{\\mathrm{d}x^{j} }\n+ \\Big( \\frac{\\partial}{\\partial \\mathbf{y}}  \\frac{ \\mathrm{d}^{j} \\mathbf{f}(x,\\mathbf{y}) }{\\mathrm{d}x^{j} }  \\Big) \\cdot \\mathbf{f}(x,\\mathbf{y}).\n\\end{split}\n\\tag{10.93}\\] Then we know that, when evaluated on the exact solution, we have\n\\[\n\\frac{ \\mathrm{d}^{j} \\mathbf{f} }{\\mathrm{d}x^{j} }  (x,\\mathbf{y}(x)) =  \\frac{ \\mathrm{d}^{j+1} \\mathbf{y} }{\\mathrm{d}x^{j+1} } (x,\\mathbf{y}).\n\\tag{10.94}\\] Hence, Eq. 10.83 rewrites to \\[\n\\mathbf{y}(x_{i+1}) = \\mathbf{y}(x_i) + hf(x_i, \\mathbf{y}(x_i)) + \\underbrace{\\frac{h^2}{2} \\frac{d\\mathbf{f}}{dx}(x_i, \\mathbf{y}(x_i)) + \\cdots + \\frac{h^n}{n!} \\frac{d^{n-1}\\mathbf{f}}{dx^{n-1}}(x_i, \\mathbf{y}(x_i))}_{=:\\mathbf{h}\\phi(x, \\mathbf{y}(x_i),h)=:\\mathbf{hT}_n(x, \\mathbf{y}(x_i),h)} + \\mathbf{R}_i.\n\\tag{10.95}\\] This motivates us to define the Taylor method of order \\(n\\) by the difference equation \\[\n\\begin{aligned}\n  \\mathbf{w}_0 &:= \\boldsymbol{\\alpha},\n\\\\\n  \\mathbf{w}_{i+1} &:= \\mathbf{w}_{i} + h \\mathbf{f}(x_i,\\mathbf{w}_i)\n+ \\frac{h^2}{2}  \\frac{ \\mathrm{d}^{} \\mathbf{f} }{\\mathrm{d}x^{} } (x_i,\\mathbf{w}_i)\n+ \\ldots\n+ \\frac{h^n}{n!}  \\frac{ \\mathrm{d}^{n-1} \\mathbf{f} }{\\mathrm{d}x^{n-1} }  (x_i,\\mathbf{w}_i)\n  \\\\\n&\\hphantom{:}= \\mathbf{w}_{i} + h \\mathbf{T}_n(x_i,\\mathbf{w}_i,h) ,\n\\end{aligned}\n\\tag{10.96}\\] where \\[\n\\mathbf{T}_n(x,\\mathbf{y},h) := \\sum_{j=0}^{n-1} \\frac{h^{j}}{(j+1)!}  \\frac{ \\mathrm{d}^{j} \\mathbf{f} }{\\mathrm{d}x^{j} } (x,\\mathbf{y}).\n\\tag{10.97}\\]\nWe have thus defined a one-step difference method with function \\(\\boldsymbol{\\phi}=\\mathbf{T}_n\\). According to Theorem 10.2, its global error is determined by its local truncation error, and by a Lipschitz constant for \\(\\mathbf{T}_n\\) (which we do not consider in detail here).\n\nTheorem 10.3 The local truncation error of the Taylor method of order \\(n\\) satisfies the bound \\[\n\\|\\boldsymbol{\\tau}_{i}(h)\\| \\leq \\frac{h^{n}}{(n+1)!} \\sup_{x \\in [a,b]}\n\\Big\\lVert   \\frac{ \\mathrm{d}^{n+1} \\mathbf{y} }{\\mathrm{d}x^{n+1} }  (x)  \\Big\\rVert=:\\tau(h),\n\\tag{10.98}\\] supposing that the exact solution \\(\\mathbf{y}(x)\\) has \\((n+1)\\) continuous derivatives.\n\n\nProof. By definition of the local truncation error in Eq. 10.74 and using Eq. 10.97, we have \\[\n\\begin{aligned}\n\\|\\boldsymbol{\\tau}_{i+1}(h)\\| &= \\frac{1}{h} \\big\\lVert  \\mathbf{y}(x_{i+1}) - \\mathbf{y}(x_{i}) - h \\,\\mathbf{T}_n(x_i,\\mathbf{y}(x_i),h)  \\big\\rVert\n\\\\\n&= \\frac{1}{h} \\big\\lVert  \\mathbf{y}(x_{i+1}) - \\mathbf{y}(x_{i})\n- \\sum_{j=0}^{n-1} \\frac{h^{j+1}}{(j+1)!}  \\frac{ \\mathrm{d}^{j} \\mathbf{f} }{\\mathrm{d}x^{j} } (x_i,\\mathbf{y}(x_i))  \\big\\rVert.\n\\end{aligned}\n\\tag{10.99}\\] However, comparing with Eq. 10.95, this means \\[\n\\|\\boldsymbol{\\tau}_{i+1}(h)\\| = \\frac{1}{h} \\lVert  \\mathbf{R}_i  \\rVert,\n\\tag{10.100}\\] and the proposed statement now follows from Eq. 10.84. ◻\n\nSo, for any \\(n\\), we get an approximation method of order \\(O(h^n)\\). The Taylor method of order 1 coincides with Euler’s method. Thus, as a side result, we have proved that Euler’s method converges in the case of ODE systems.\n\nExample 10.7 Let us once again consider the example IVP 1 from Eq. 10.12, \\[\ny'(x) = y(x)-x^2+1,  \\quad 0 \\leq x \\leq 1, \\quad y(0) = \\frac{1}{2}.\n\\tag{10.101}\\] Thus \\(f(x,y)=y-x^2+1\\). To set up the Taylor methods, say of order up to 4, we need to compute the first 3 total derivatives of \\(f\\). In our example, this yields: \\[\n\\begin{aligned}\n   \\frac{ \\mathrm{d}^{} f(x,y) }{\\mathrm{d}x^{} }  &= \\frac{\\partial f(x,y)}{\\partial x}  +  \\frac{\\partial f(x,y)}{\\partial y} f(x,y)\\\\ &= (-2x) +  1\\cdot (y-x^2+1) = y-x^2-2x+1;\n\\\\\n   \\frac{ \\mathrm{d}^{2} f(x,y) }{\\mathrm{d}x^{2} } & = \\frac{\\partial}{\\partial x} \\frac{ \\mathrm{d}^{} f(x,y) }{\\mathrm{d}x^{} }   + \\frac{\\partial}{\\partial y} \\frac{ \\mathrm{d}^{} f(x,y) }{\\mathrm{d}x^{} }   f (x,y)\\\\\n  &= (-2x-2) + 1 \\cdot (y-x^2+1) = y-x^2-2x-1;\n\\\\\n   \\frac{ \\mathrm{d}^{3} f(x,y) }{\\mathrm{d}x^{3} } & = \\frac{\\partial}{\\partial x} \\frac{ \\mathrm{d}^{2} f(x,y) }{\\mathrm{d}x^{2} }   + \\frac{\\partial}{\\partial y} \\frac{ \\mathrm{d}^{2} (x,y)f }{\\mathrm{d}x^{2} }   f(x,y)\\\\\n  &= (-2x-2) + 1 \\cdot (y-x^2+1) = y-x^2-2x-1.\n\\end{aligned}\n\\tag{10.102}\\] In this simple example, we can now see that all higher-order total derivatives are equal to \\(\\mathrm{d}^2f(x,y)/\\mathrm{d}x^2\\); this will not normally be true.\nOur second-order Taylor function \\(T_2\\) is then \\[\n\\begin{split}\nT_2(x,y,h) &= f(x,y) + \\frac{h}{2}  \\frac{ \\mathrm{d}^{} f(x,y) }{\\mathrm{d}x^{} }\\\\\n&= (y-x^2+1) + \\frac{h}{2}(y-x^2-2x+1)\\\\\n&= (1+\\frac{h}{2}) (y-x^2+1)-hx.\n\\end{split}\n\\tag{10.103}\\] The second-order Taylor method therefore reads, \\[\n\\begin{split}\nw_0 :=& \\frac{1}{2},\\\\\nw_{i+1} :=& w_i+hT_2(x_i,w_i,h) \\\\=& w_i + (h+\\frac{h^2}{2})(w_i-x_i^2+1) - h^2 x_i.\n\\end{split}\n\\tag{10.104}\\] Analogously, one finds after a bit of computation that \\[\n\\begin{aligned}\n  T_4(x,y,h) &= f(x,y) + \\frac{h}{2}  \\frac{ \\mathrm{d}^{} f(x,y) }{\\mathrm{d}x^{} }\n+ \\frac{h^2}{6}  \\frac{ \\mathrm{d}^{2} f(x,y) }{\\mathrm{d}x^{2} }  + \\frac{h^3}{24}  \\frac{ \\mathrm{d}^{3} f(x,y) }{\\mathrm{d}x^{3} }\n\\\\&= \\Big( 1 +\\frac{h}{2} + \\frac{h^2}{6} + \\frac{h^3}{24} \\Big)(y-x^2)\\\\\n&\\quad+ \\Big( 1 +\\frac{h}{3} + \\frac{h^2}{12} \\Big) h x\\\\\n&\\quad+ \\Big( 1 +\\frac{h}{2} - \\frac{h^2}{6} - \\frac{h^3}{24} \\Big).\n\\end{aligned}\n\\tag{10.105}\\]\n\n\n10.5.1 Advantages and disadvantages\nWe have seen that the error of the order \\(n\\) Taylor method is \\(O(h^n)\\). This is much improved over the \\(O(h^1)\\) of Euler’s method. Thus, in most situations, Taylor methods will give a much more accurate result.\nHowever, the error estimate depends on the supremum of the \\((n+1)\\)-th derivative of the exact solution, and on the Lipschitz constant for \\(T_n\\). We do not know a priori that these are small. Usually, this does not pose a problem in practice; we will however see some counterexamples in Section 10.9.\nTaylor methods can be constructed for any order \\(n\\), in a straightforward and unique way, by computing derivatives of the function \\(f\\).\nStill, Taylor methods are not so frequently used in practice. The main reason for this is that they require us to compute the total derivatives of the function \\(f\\) explicitly. In practice, this is too cumbersome to be done by hand. It can be achieved with symbolic differentiation algorithms, using computer algebra packages such as Maple. However, one would like to avoid this extra complexity. Also, it may not always be feasible to compute the derivatives explicitly: Suppose that, in a computer program, the function \\(f\\) is given as a “black box” procedure that computes (or rather approximates) the function values \\(f(x,y)\\) numerically; how would we gain access to the derivatives of \\(f\\)?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "ivp.html#sec-rk",
    "href": "ivp.html#sec-rk",
    "title": "10  Initial Value Problems",
    "section": "10.6 Runge-Kutta Methods",
    "text": "10.6 Runge-Kutta Methods\nRunge-Kutta methods are another example of one-step difference methods; they are very relevant in practice. They arise as modifications of the Taylor methods discussed in the previous section. Their main advantage is that they do not require us to compute derivatives of the function \\(f\\) explicitly.\n\n10.6.1 Motivation: The Modified Euler Method\nThe idea of Runge-Kutta methods is to avoid computing the total derivatives \\(d^nf/dx^n\\). Rather, these are replaced with finite difference quotients.\nRecall that, if \\(g\\) is a twice differentiable function, then we can use Taylor’s Theorem to write \\[\ng(x+h)=g(x)+hg'(x)+O(h^2)\n\\tag{10.106}\\] and rearrange to give \\[\ng'(x) = \\frac{g(x+h)-g(x)}{h} + O(h).\n\\tag{10.107}\\] The fraction on the r.h.s. is called a finite difference quotient. We also remark that, by the MVT (or Taylor’s Theorem) \\[\ng(x+h)=g(x)+O(h).\n\\tag{10.108}\\] We can replace \\(h\\) by \\(O(h^k)\\) here to give \\[\ng(x+O(h^k))=g(x)+O(O(h^k))=g(x)+O(h^k).\n\\tag{10.109}\\]\nWe start with the Taylor method of order two, here for \\(m=1\\), given by the function \\[\n   T_2(x,y,h) = f(x,y) + \\frac{h}{2}  \\frac{ \\mathrm{d}^{} f }{\\mathrm{d}x^{} }  (x,y).\n\\tag{10.110}\\]\nWe use a difference quotient to approximate the total derivative, evaluated on the exact solution \\(y(x)\\): \\[\n\\frac{ \\mathrm{d}^{} f }{\\mathrm{d}x^{} }  (x,y(x)) = \\frac{f\\big(x+h,y(x+h)\\big)-f\\big(x,y(x)\\big)}{h} + O(h).\n\\tag{10.111}\\] Inside this expression, for the term \\(y(x+h)\\), we use a Taylor approximation: \\[\ny(x+h) = y(x) + h y'(x) + O(h^2)\n= y(x) + h f\\big(x,y(x)\\big) + O(h^2).\n\\tag{10.112}\\] Using Eq. 10.109 we obtain \\[\n\\frac{ \\mathrm{d}^{} f }{\\mathrm{d}x^{} }  (x,y(x)) = \\frac{1}{h} \\Big( f\\big(x+h,y(x)+hf(x,y(x)) \\big)-f(x,y(x)) \\Big) + O(h).\n\\tag{10.113}\\] Inserting into Eq. 10.110, we have \\[\nT_2(x,y(x),h) = \\frac{1}{2} f(x,y(x))\n+ \\frac{1}{2}   f\\big(x+h,y(x)+hf(x,y(x)) \\big)\n  + O(h^2).\n\\tag{10.114}\\] Thus, if instead of the function \\(T_2\\), we use the function \\[\n\\phi(x,y,h) = \\frac{1}{2} f(x,y)\n+ \\frac{1}{2}   f\\big(x+h,y+hf(x,y) \\big)\n\\tag{10.115}\\] for our one-step method, we will incur an additional local truncation error of order \\(O(h^2)\\). However, this is not “much worse” than the Taylor method, which already has an error of order \\(O(h^2)\\).\nThe one-step difference method corresponding to \\(\\phi\\) is called the Modified Euler method. Its difference equation, \\(w_{i+1}:=w_i + h\\phi(x_i,w_i,h)\\), can be rewritten in the following cleaned-up form: \\[\n\\begin{aligned}\n   w_0 &:= \\alpha,\n\\\\\nk_{i,1} &:= hf(x_i,w_i),\n\\\\\nk_{i,2} &:= hf(x_i+h,w_i+k_{i,1}),\n\\\\\nw_{i+1} &:= w_i + \\frac{1}{2} k_{i,1} + \\frac{1}{2} k_{i,2}.\n\\end{aligned}\n\\tag{10.116}\\] This shows in particular that only two evaluations of \\(f\\) are needed in each step of the method. That is important to know, since the evaluation of \\(f\\) is usually the time-consuming part when the method is implemented on a computer.\nWe have seen now, roughly, that the Modified Euler method works, and is of order \\(O(h^2)\\). A more complete proof will follow below. Let us first have a look at other methods of the same kind.\n\n\n10.6.2 General Runge-Kutta methods\nA general Runge-Kutta method is defined by a Butcher tableau:\n\\[\n%\n\\begin{array}{c|ccccc}\n   a_1 &  & & & &\n  \\\\\n   a_2 & b_{21} & & & &\n  \\\\\n   a_3 & b_{31} & b_{32} & & &\n  \\\\\n   \\vdots & \\vdots & & \\ddots & &\n  \\\\\n   a_s & b_{s1} & b_{s2} & \\ldots & b_{s,s-1} &\n\\\\\n\\hline\n& c_1 & c_2 & \\ldots & c_{s-1} & c_s\n\\end{array}\n\\tag{10.117}\\] where \\(a_i\\), \\(b_{ij}\\), \\(c_i\\) are real numbers. The tableau is a shorthand notation for the associated difference equation of a one-step method: \\[\n\\begin{aligned}\n\\mathbf{w}_0 &:= \\alpha;\n\\\\\n\\quad&\\quad      \\mathbf{k}_1 := h \\mathbf{f}(x_i + a_1 h, \\mathbf{w}_i + 0),\n  \\\\\n\\quad&\\quad      \\mathbf{k}_2 := h \\mathbf{f}(x_i + a_2 h, \\mathbf{w}_i + b_{21} \\mathbf{k}_1),\n  \\\\\n      \\quad&\\quad \\mathbf{k}_3 := h \\mathbf{f}(x_i + a_3 h, \\mathbf{w}_i + b_{31} \\mathbf{k}_1 + b_{32} \\mathbf{k}_2),\n  \\\\\n   \\quad&\\quad  \\qquad \\vdots\n  \\\\\n   \\quad&\\quad \\mathbf{k}_s := h \\mathbf{f}(x_i + a_s h, \\mathbf{w}_i + \\sum_{j=1}^{s-1} b_{sj} \\mathbf{k}_j);\n\\\\\n    \\mathbf{w}_{i+1} &:= \\mathbf{w}_i + \\sum_{j=1}^s c_j \\mathbf{k}_j\n\\end{aligned}\n\\tag{10.118}\\] (The \\(\\mathbf{k}_j\\) depend in addition on the step \\(i\\), but they are regarded as “intermediate results”, and we do not denote this dependence explicitly.) Our Modified Euler method is an example of such a scheme, namely with the tableau \\[\n\\begin{array}{c|cc}\n   0\n  \\\\\n   1 & 1\n\\\\\n  \\hline\n    & \\;\\tfrac{1}{2} \\; & \\;\\tfrac{1}{2}  \\;\n\\end{array}\n\\tag{10.119}\\]\nWe do not discuss here in general how these tableaux are obtained, or how to prove in general of what order their local truncation error is. However, here are some more examples.\nThe Midpoint method is another method of order \\(O(h^2)\\). It is given by the tableau \\[\n%\n\\begin{array}{c|cc}\n   0\n  \\\\\n   \\tfrac{1}{2} & \\tfrac{1}{2}\n\\\\\n  \\hline\n    & \\;0 \\; & \\;1 \\;\n%\n\\end{array}\n\\tag{10.120}\\] and its difference equation can be written explicitly as \\[\n\\mathbf{w}_0 := \\boldsymbol{\\alpha}, \\quad \\mathbf{w}_{i+1} = \\mathbf{w}_i + h \\, \\mathbf{f}\\big(x_i + \\frac{h}{2}, \\mathbf{w}_i + \\frac{h}{2} \\mathbf{f}(x_i,\\mathbf{w}_i)\n\\big).\n\\tag{10.121}\\] There are more methods of order \\(O(h^2)\\); for example, Heun’s method: 2 \\[\n\\begin{array}{c|cc}\n   0\n  \\\\\n   \\tfrac{2}{3} & \\tfrac{2}{3}\n\\\\\n  \\hline\n    & \\;\\tfrac{1}{4} \\; & \\;\\tfrac{3}{4}  \\;\n\\end{array}\n\\tag{10.122}\\] The explicit form of the difference equation is \\[\n\\mathbf{w}_0 := \\boldsymbol{\\alpha}, \\quad \\mathbf{w}_{i+1} = \\mathbf{w}_i + \\frac{h}{4} \\Big(\\mathbf{f}(x_i,\\mathbf{w}_i) + 3 \\mathbf{f}\\big(x_i\n+ \\frac{2}{3}h, \\mathbf{w}_i + \\frac{2}{3}{h} \\,\\mathbf{f}(x_i,\\mathbf{w}_i) \\big) \\Big).\n\\tag{10.123}\\] Finally, let us mention the “classical” Runge-Kutta method 3 of order \\(O(h^4)\\). This method is widely used in practice. Its Butcher tableau is\n\\[\n\\begin{array}{c|cccc}\n0 & & & & \\\\\n\\frac{1}{2} & \\frac{1}{2} & & & \\\\\n\\frac{1}{2} & 0 & \\frac{1}{2} & & \\\\\n1 & 0 & 0 & 1 & \\\\\n\\hline\n& \\frac{1}{6} & \\frac{2}{6} & \\frac{2}{6} & \\frac{1}{6}\n\\end{array}\n\\tag{10.124}\\] and it is not very useful to write its difference equation in one line! (In general, when used in programming, working with the intermediate results \\(\\mathbf{k}_i\\) is a good way of organizing the code.)\n\n\n10.6.3 Local truncation error for second-order methods\nThe general idea of proving a rigorous error estimate for a Runge-Kutta method is comparing it to the Taylor method of order \\(n\\), with \\(n\\) appropriately chosen. Given the function \\(\\boldsymbol{\\phi}_\\text{RK}(x,y,h)\\) that defines the method (as a one-step difference method), one would try to prove that\n\\[\n   ||\\mathbf{\\phi}_\\text{RK}(x,\\mathbf{y}(x),h) - \\mathbf{T}_n(x,\\mathbf{y}(x),h) ||\\leq c h^n\n\\tag{10.125}\\] with a constant \\(c&gt;0\\). This proof will usually involve a Taylor expansion of the function \\(\\mathbf{f}\\) within \\(\\boldsymbol{\\phi}_\\text{RK}\\), and the constant \\(c\\) will depend on estimates for the function \\(\\mathbf{f}\\) and its derivatives. Once Eq. 10.125 is known, it follows from the definition of the local truncation error Eq. 10.74 and the triangle inequality that \\[\n\\tau_\\text{RK}(h) \\leq \\tau_\\text{Taylor-$n$}(h) + c \\,h^n.\n\\tag{10.126}\\] With the estimate for \\(\\tau_\\text{Taylor-$n$}(h)\\) (the truncation error of the \\(n\\)-th order Taylor method) known from Theorem 10.3 this yields \\[\n\\tau_\\text{RK}(h) \\leq c' \\,h^n.\n\\tag{10.127}\\] with another constant \\(c'&gt;0\\). Theorem 10.2 then tells us that the global error of the Runge-Kutta method is of order \\(O(h^n)\\).\nHowever, for most higher-order methods, such as the classical Runge-Kutta method Eq. 10.124 of order \\(O(h^4)\\), the proof of Eq. 10.125 is rather tedious, since the computation becomes quite lengthy.\nHere, we will give the proof only for \\(O(h^2)\\) methods with a Butcher tableau of the form \\[\n\\begin{array}{c|cc}\n   0\n  \\\\\n   c & c\n\\\\\n  \\hline\n    & \\;(1\\!-\\!d) \\; & \\;d \\;\n\\end{array}\n\\tag{10.128}\\] where \\(c,d \\in (0,1], \\quad cd = \\frac{1}{2}\\). This includes the Modified Euler method (\\(c=1\\), \\(d=1/2\\)), the Midpoint method (\\(c=1/2\\), \\(d=1\\)), and Heun’s method (\\(c=2/3\\), \\(d=3/4\\)).\n\nTheorem 10.4 Consider a Runge-Kutta method of the form Eq. 10.128. Suppose that the function \\(\\mathbf{f}\\) and all its derivatives up to order \\(2\\) are bounded. 4 Then, there exists a constant \\(C\\) such that the local truncation error is bounded by \\[\n\\|\\boldsymbol{\\tau}_i(h)\\| \\leq C h^2.\n\\tag{10.129}\\]\n\n\nProof. As explained above, we need to prove Eq. 10.125 in our case. The function \\(\\boldsymbol{\\phi}\\) is here given by \\[\n  \\boldsymbol{\\phi}(x,\\mathbf{y},h) = (1-d)\\, \\mathbf{f}(x,\\mathbf{y}) + d \\,\\underbrace{\\mathbf{f}\\big(x+ch, \\mathbf{y}+ch\\mathbf{f}(x,\\mathbf{y})\\big)}_{=:\\mathbf{k}},\n\\tag{10.130}\\]\nand we need to compare it to the Taylor method of order 2, given by \\[\n\\mathbf{T}_2(x,y,h) =  \\mathbf{f}(x,\\mathbf{y}) + \\frac{h}{2}  \\frac{ \\mathrm{d}^{} \\mathbf{f} }{\\mathrm{d}x^{} } (x, \\mathbf{y}).\n\\tag{10.131}\\] We first take the term \\(\\mathbf{k}\\) from Eq. 10.130, and use a first-order Taylor expansion of the function \\(\\mathbf{f}\\) around the point \\((x,\\mathbf{y})\\), in the form of Theorem A.5. This gives \\[\n\\begin{aligned}\n\\mathbf{k} &= \\mathbf{f}(x,\\mathbf{y}) +\n  \\frac{\\partial \\mathbf{f}(x,\\mathbf{y})}{\\partial(x,y^{(1)},\\ldots,y^{(m)})}\n\\cdot \\begin{pmatrix}\n         ch\n  \\\\\n   ch\\,f^{(1)}(x,\\mathbf{y})\n  \\\\\n  \\vdots\n  \\\\\n   ch\\,f^{(m)}(x,\\mathbf{y})\n      \\end{pmatrix} + \\mathbf{R}\n\\\\\n  &=\\mathbf{f}(x,\\mathbf{y}) + ch\\frac{\\partial \\mathbf{f}}{\\partial x} + ch \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{y}} \\cdot \\mathbf{f}(x,\\mathbf{y}) + \\mathbf{R}\n\\\\\n  &=\\mathbf{f}(x,\\mathbf{y}) + ch \\frac{d\\mathbf{f}}{dx}(x,\\mathbf{y}) + \\mathbf{R}.\n\\end{aligned}\n\\tag{10.132}\\] We assume that all second partial derivatives of \\(\\mathbf{f}\\) (by \\(x\\) or \\(y_j\\)) are bounded by a constant \\(M\\). According to Theorem A.5, the Taylor remainder term \\(\\mathbf{R}\\) is then bounded by \\[\n\\lVert \\mathbf{R} \\rVert \\leq \\frac{1}{2} (ch)^2 \\lVert  (1, f_1, \\ldots, f_m)  \\rVert^2\n  \\cdot (m+1)^2 M.\n\\tag{10.133}\\] After possibly modifying the constant \\(M\\), we can assume that \\(\\|f_j\\|\\leq M\\) as well, and that \\(M \\geq 1\\). This gives \\[\n\\lVert \\mathbf{R} \\rVert \\leq \\frac{(m+1)^2 M^3 c^2}{2} h^2.\n\\tag{10.134}\\] Inserting Eq. 10.132 into Eq. 10.130 yields \\[\n\\begin{split}\n\\boldsymbol{\\phi}(x,\\mathbf{y},h) &= (1-d) \\mathbf{f}(x,\\mathbf{y}) + d \\mathbf{k}\\\\\n&= \\mathbf{f}(x,\\mathbf{y}) + cdh   \\frac{ \\mathrm{d}^{} \\mathbf{f} }{\\mathrm{d}x^{} } (x,\\boldsymbol{y}) + d\\mathbf{R}\\\\\n&= \\mathbf{T}_2(x,y,h)+d\\mathbf{R},\n\\end{split}\n\\tag{10.135}\\] since \\(cd=1/2\\). Consequently, \\[\n\\lVert  \\boldsymbol{\\phi}(x,\\mathbf{y},h) - \\mathbf{T}_2(x,\\mathbf{y},h) \\rVert \\leq \\frac{(m+1)^2 M^3 c}{4} h^2,\n\\tag{10.136}\\] which completes the proof. ◻\n\n\n\n10.6.4 Advantages and disadvantages\nRunge-Kutta methods are very widely used in practice. While they are slightly less accurate than Taylor methods, they can be chosen of the same order \\(O(h^n)\\), and in this sense they are “as good” as Taylor methods. However, they have the advantage that it is not necessary to compute the total derivatives of \\(\\mathbf{f}\\) explicitly. They are rather straightforward to implement on a computer, given the Butcher tableau of a method. Particularly, the “classical” Runge-Kutta method is a good choice where one needs an algorithm of reasonable accuracy which is easy to implement.\nHowever, the error bounds of Runge-Kutta methods are sensitive to the higher-order derivatives of \\(\\mathbf{f}\\). (They share this problem with Taylor methods.) In some cases, to be discussed in Section 10.9, this leads to problems.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "ivp.html#sec-rkf",
    "href": "ivp.html#sec-rkf",
    "title": "10  Initial Value Problems",
    "section": "10.7 Error Control, Runge-Kutta-Fehlberg Method",
    "text": "10.7 Error Control, Runge-Kutta-Fehlberg Method\n\n10.7.1 Error control\nWe have so far discussed how the approximation error changes with the step size \\(h\\), but we have not really explained how to choose \\(h\\) in practice.\nIn principle, given an IVP, one might first try to prove rigorous error estimates, like in the example in Section 10.2, but with \\(h\\) left open. Then one can choose \\(h\\) according to the maximum error one wants to allow. However, these estimates are very hard (if not impossible) to compute in realistic examples.\nInstead, one would like to have an approximation algorithm that automatically computes an estimate for the error, at least roughly, and that chooses the step size \\(h\\) accordingly. This technique is known as error control.\nThe idea is roughly as follows. Let us use two approximation methods, with approximation values \\(\\mathbf{w}_i\\) and \\(\\tilde{\\mathbf{w}}_i\\). Suppose that \\(\\tilde{\\mathbf{w}}_i\\) is much more exact than \\(\\mathbf{w}_i\\), i.e., that the absolute error of \\(\\tilde{\\mathbf{w}}_i\\) is much smaller than that of \\(\\mathbf{w}_i\\). (For example, the second approximation method might be of higher order in \\(h\\).) Then we have \\[\n\\lVert  \\mathbf{y}(x_i)-\\mathbf{w}_i  \\rVert \\leq \\underbrace{ \\lVert  \\mathbf{y}(x_i)-\\tilde{\\mathbf{w}}_i  \\rVert }_{\\text{negligible}}\n+ \\lVert \\tilde{\\mathbf{w}}_i-\\mathbf{w}_i  \\rVert \\approx \\lVert \\tilde{\\mathbf{w}}_i-\\mathbf{w}_i \\rVert.\n\\tag{10.137}\\] However, the right-hand side can be computed without knowing the exact solution \\(\\mathbf{y}(x)\\).\nTo make this more concrete, let us say that \\(\\mathbf{w}_i\\) and \\(\\tilde{\\mathbf{w}}_i\\) are computed by two one-step difference methods, with defining functions \\(\\boldsymbol{\\phi}\\) and \\(\\tilde{\\boldsymbol{\\phi}}\\), respectively. Let us assume that \\(\\boldsymbol{\\phi}\\) yields a local truncation error \\(\\|\\boldsymbol{\\tau}_{i}(h)\\|\\) of order \\(O(h^n)\\), while the local truncation error \\(\\|\\tilde{\\boldsymbol{\\tau}}_{i}(h)\\|\\) of \\(\\tilde{\\boldsymbol{\\phi}}\\) is of order \\(O(h^{n+1})\\).\nFurther, we fix \\(i\\) and suppose that \\(\\mathbf{y}(x_i)=\\mathbf{w}_i=\\tilde{\\mathbf{w}}_i\\), that is, we start form an exact value in the previous step. 5 For given step size \\(h\\), we want to estimate the local truncation error \\(\\|\\boldsymbol{\\tau}_{i+1}(h)\\|\\) of the first method, supposing that \\(\\tilde{\\boldsymbol{\\tau}}_{i+1}\\) is negligible compared with it. \\[\n\\begin{gathered}\n   \\|\\boldsymbol{\\tau}_{i+1}(h)\\| = \\frac{1}{h} \\lVert \\mathbf{y}(x_{i+1})-\\mathbf{y}(x_i) -h \\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)  \\rVert\n\\\\\n= \\frac{1}{h} \\lVert  \\underbrace{\\big(\\mathbf{y}(x_{i+1})-\\mathbf{y}(x_i) -h \\tilde{\\boldsymbol{\\phi}}(x_i,\\mathbf{w}_i,h)\\big)}_{\\text{$\\sim h\\|\\tilde{\\boldsymbol{\\tau}}_{i+1}\\|$, negligible} }\n  + h \\tilde{\\boldsymbol{\\phi}}(x_i,\\mathbf{w}_i,h) -h \\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)  \\rVert\n\\\\\n\\approx\n  \\lVert  \\tilde{\\boldsymbol{\\phi}}(x_i,\\mathbf{w}_i,h) - \\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)  \\rVert.\n\\end{gathered}\n\\tag{10.138}\\] Thus we can determine the local truncation error approximately by evaluating the functions \\(\\boldsymbol{\\phi}\\) and \\(\\tilde{\\boldsymbol{\\phi}}\\).\n\\[\n\\begin{array}{c|ccccccl}\n   0 &  \n  \\\\\n   \\frac{1}{4} & \\frac{1}{4}\n  \\\\\n   \\frac{3}{8} & \\frac{3}{32} & \\frac{9}{32}\n  \\\\\n   \\frac{12}{13} & \\frac{1932}{2197} & -\\frac{7200}{2197} & \\frac{7296}{2197}\n  \\\\\n   1 & \\frac{439}{216} & -8 & \\frac{3680}{513} & - \\frac{845}{4104}\n\\\\\n   \\frac{1}{2} & -\\frac{8}{27} & 2 & -\\frac{3544}{2565} &  \\frac{1859}{4104} & -\\frac{11}{40}\n\\\\\n\\hline\n  \\text{\\textbf{(a)}}  & \\frac{25}{216} & 0 & \\frac{1408}{2565} &  \\frac{2197}{4104} & -\\frac{1}{5} &\n\\\\\n\\hline\n  \\text{\\textbf{(b)}}  & \\frac{16}{135} & 0 & \\frac{6656}{12825} & \\frac{28561}{56430} & - \\frac{9}{50} & \\frac{2}{55}\n\\end{array}\n\\tag{10.139}\\]\nHowever, what we actually want is to choose the step size \\(h\\) so that \\(\\|\\boldsymbol{\\tau}_{i+1}(h)\\| \\leq T\\) with some given “tolerance” value \\(T\\). To that end, let us assume that \\(\\|\\boldsymbol{\\tau}_{i+1}(h)\\|\\) is not only of order \\(O(h^n)\\), but in fact (roughly) proportional to \\(h^n\\): \\[\n   \\|\\boldsymbol{\\tau}_{i+1} (h)\\| \\approx K \\, h^n \\quad \\text{for some $K&gt;0$}.\n\\tag{10.140}\\] We proceed as follows. We start with some fixed step size \\(h\\) and compute the related function values: \\[\n|\\boldsymbol{\\tau}_{i+1} (h)| \\approx K \\, h^n  \\approx \\lVert  \\tilde{\\boldsymbol{\\phi}}(x_i,\\mathbf{w}_i,h) - \\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)  \\rVert.\n\\tag{10.141}\\]\nNow we want to adjust \\(h\\) by a factor \\(q&gt;0\\), such that \\(\\|\\boldsymbol{\\tau}_{i+1}(qh)\\| \\approx T\\). By our assumption Eq. 10.140, \\[\n   \\|\\boldsymbol{\\tau}_{i+1} (qh)\\| \\approx K \\, (qh)^n  \\approx T.\n\\tag{10.142}\\]\nDividing Eq. 10.142 by Eq. 10.141 yields \\[\nq^n\\approx \\frac{T}{\\lVert  \\tilde{\\boldsymbol{\\phi}}(x_i,\\mathbf{w}_i,h) - \\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h)  \\rVert},\n\\tag{10.143}\\] thus we should choose \\[\nq =  \\left( \\frac{T}{\\lVert\\tilde{\\boldsymbol{\\phi}}(x_i,\\mathbf{w}_i,h) - \\boldsymbol{\\phi}(x_i,\\mathbf{w}_i,h) \\rVert} \\right)^{1/n}   =  \\left( \\frac{hT}{  \\lVert\\tilde{\\mathbf{w}}_{i+1} - \\mathbf{w}_{i+1}  \\rVert }  \\right)^{1/n},\n\\tag{10.144}\\]\nwhere it is understood that \\(\\mathbf{w}_{i+1},\\tilde{\\mathbf{w}}_{i+1}\\) are computed with \\(\\boldsymbol{\\phi},\\tilde{\\boldsymbol{\\phi}}\\) using the step size \\(h\\).\n\n\n10.7.2 The Runge-Kutta-Fehlberg method\nA popular implementation of the above principle is the Runge-Kutta-Fehlberg method. It uses an order-4 Runge-Kutta method for \\(\\boldsymbol{\\phi}\\) and an order-5 Runge-Kutta method for \\(\\tilde{\\boldsymbol{\\phi}}\\). The Butcher tableaux for both methods is ?eq-butcherrkf. \\[\n\\begin{array}{c|ccccccl}\n   0 &  \n  \\\\\n   \\frac{1}{4} & \\frac{1}{4}\n  \\\\\n   \\frac{3}{8} & \\frac{3}{32} & \\frac{9}{32}\n  \\\\\n   \\frac{12}{13} & \\frac{1932}{2197} & -\\frac{7200}{2197} & \\frac{7296}{2197}\n  \\\\\n   1 & \\frac{439}{216} & -8 & \\frac{3680}{513} & - \\frac{845}{4104}\n\\\\\n   \\frac{1}{2} & -\\frac{8}{27} & 2 & -\\frac{3544}{2565} &  \\frac{1859}{4104} & -\\frac{11}{40}\n%\n\\\\\n\\hline\n  \\text{\\textbf{(a)}}  & \\frac{25}{216} & 0 & \\frac{1408}{2565} &  \\frac{2197}{4104} & -\\frac{1}{5} &\n%\n\\\\\n\\hline\n  \\text{\\textbf{(b)}}  & \\frac{16}{135} & 0 & \\frac{6656}{12825} & \\frac{28561}{56430} & - \\frac{9}{50} & \\frac{2}{55}\n\\end{array}\n\\]\nThe special feature of this algorithm is that the two approximation methods share most parts of their coefficient schemes; more precisely, the auxiliary values \\(\\mathbf{k}_1,\\ldots,\\mathbf{k}_6\\) are the same in both approximation methods. Only the “final lines” in the Butcher tableaux are different: for computing \\(\\mathbf{w}_{i+1}\\), one uses the line marked (a), while for \\(\\tilde{\\mathbf{w}}_{i+1}\\), the line marked (b) is used. This arrangement makes the algorithm rather efficient: the function \\(\\mathbf{f}\\) needs to be evaluated only 6 times per step. Compare this with the 4 function evaluations needed for the classical Runge-Kutta method of order 4 without error control. The additional overhead caused by the error control method is noticeable, but not too large.\n\n\n\\begin{algorithm} \\caption{The Runge-Kutta-Fehlberg method} \\begin{algorithmic} \\Function{RungeKuttaFehlberg}{$a,b,\\boldsymbol{\\alpha},T,h_{min},h_{max}$} \\State \\Comment{tolerance $T$; minimal/maximal step size $h_{min}$, $h_{max}$} \\State $x := a$, $\\boldsymbol{w} := \\boldsymbol{\\alpha}$, $h := h_{max}$ \\Repeat \\State Compute $\\boldsymbol{k}_1,\\ldots, \\boldsymbol{k}_6$ from Butcher tableau with step size $h$ \\State $R := {h}^{-1}\\lVert \\sum_{j=1}^6 (c_j-\\tilde c_j) \\boldsymbol{k}_j \\rVert$ \\Comment{Estimate local truncation error} \\If{ $R \\leq T$ } \\State $x := x+h$, $\\boldsymbol{w} := \\boldsymbol{w} + \\sum_{j=1}^5 c_j \\boldsymbol{k}_j$ \\Comment{accept approximation} \\EndIf \\State \\Comment{Now choose the new step size} \\State $q :=(T/2R)^{1/4}$ \\Comment{factor to multiply $h$ with} \\If{$q \\leq 0.1$} \\State $h := 0.1h$ \\Comment{do not decrease too much} \\ElsIf{$q \\geq 4$} \\State $h := 4h $ \\Comment{do not increase too much} \\Else \\State $h := h \\cdot q$ \\EndIf \\If{$h \\geq h_{max}$} \\State $h:= h_{max}$ \\Comment{do not exceed max step size} \\EndIf \\If{ $x + h &gt; b$ } \\State $h := b-x$ \\Comment{next step would exceed interval} \\ElsIf{$h &lt;h_{min}$} \\State Error: minimum step size exceeded \\EndIf \\Until{$x\\geq b$} \\Return $\\boldsymbol{w}$ \\EndFunction \\end{algorithmic} \\end{algorithm}\n\n\nAlgorithm 10.1 shows the Runge-Kutta-Fehlberg method in pseudocode. It works roughly by the principles discussed above, but with some modification in detail. In lines 4–8, the next approximation value \\(\\mathbf{w}_{i+1}\\) is computed; however, this happens only if the estimate for the local truncation error, computed according to Eq. 10.138, is below the specified tolerance \\(T\\). Then, in lines 9–22, the step size \\(h\\) for the next step is computed. In slight deviation from Eq. 10.144, one chooses a more conservative factor, \\[\nq =\\left(\\frac{hT}{2\\lVert\\tilde{\\mathbf{w}}_{i+1} - \\mathbf{w}_{i+1}\\rVert}\\right)^{1/4}\n\\tag{10.145}\\] (note \\(n=4\\)). Also, the factor \\(q\\) is limited to the interval \\([0.1,4]\\) (lines 10–16), in order to avoid possible instabilities by rapid changes in the step size. Further, the step size is never increased beyond a given value \\(h_\\text{max}\\) (line 17); and if it decreases below a minimum step size \\(h_\\text{min}\\), we terminate with an error message (line 21) – otherwise we might run into problems with limited floating point precision. Some extra handling is needed for the last step of the approximation, in order to ensure that we end up exactly at the right-hand boundary of the interval \\([a,b]\\) (line 19).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "ivp.html#multi-step-methods",
    "href": "ivp.html#multi-step-methods",
    "title": "10  Initial Value Problems",
    "section": "10.8 Multi-Step Methods",
    "text": "10.8 Multi-Step Methods\nN.B.: This section is intended as a brief overview, and its material is not examinable. More information can be found, e.g., in (Burden and Faires 2010, sec. 5.6).\nMulti-step methods are an altervative way of approximating the solution of the initial value problem \\[\n\\mathbf{y}' = \\mathbf{f}(x,\\mathbf{y}),  \\quad a \\leq x \\leq b, \\quad \\mathbf{y}(a) = \\boldsymbol{\\alpha}.\n\\tag{10.146}\\]\nAgain, they are generalizations of Euler’s method, and we use the same division of \\([a,b]\\) into equally spaced mesh points \\(x_0,\\ldots,x_n\\). But rather than using several evaluations of the function \\(\\mathbf{f}\\) in each approximation step, like Runge-Kutta methods do, we make use of the values of \\(\\mathbf{f}\\) that have already been computed at previous mesh points.\nA general \\(k\\)-step multi-step method is given by a difference equation\n\\[\n\\begin{split}\n\\mathbf{w}_0 &:= \\mathbf{\\alpha}, \\\\\n\\mathbf{w}_1 &:= \\alpha_1, ~~\\ldots~~,~ \\mathbf{w}_{k-1} := \\alpha_{k-1}, \\\\\n\\mathbf{w}_{i+1} &:= \\alpha_{k-1} \\mathbf{w}_i + \\alpha_{k-2} \\mathbf{w}_{i-1} + \\cdots + \\alpha_0 \\mathbf{w}_{i-k+1} \\\\[5pt]\n&\\quad + h \\left( b_k \\mathbf{f}(x_{i+1}, \\mathbf{w}_{i+1}) + b_{k-1} \\mathbf{f}(x_i, \\mathbf{w}_i) + \\cdots + b_0 \\mathbf{f}(x_{i-k+1}, \\mathbf{w}_{i-k+1}) \\right).\n\\end{split}\n\\tag{10.147}\\] Here \\(a_0 \\ldots a_{k-1}, b_0 \\ldots b_{k} \\in \\mathbb{R}\\) are constants that define the method. \\(\\boldsymbol{\\alpha}_1 \\ldots \\boldsymbol{\\alpha}_{k-1} \\in\\mathbb{R}^m\\) are certain starting values that are needed for the difference equation to work; we will discuss later how to obtain them. If \\(b_k=0\\), the method is called explicit; otherwise, it is called implicit. In the latter case, \\(\\mathbf{w}_{i+1}\\) appears on both sides of the difference equation, and is hence defined only implicitly; we will discuss later how such methods can be used.\nLike for one-step methods, one defines the local truncation error of the multistep method Eq. 10.147 by \\[\n\\mathbf{\\tau}_{i+1} := \\frac{1}{h} \\left[ \\mathbf{y}(x_{i+1}) - \\sum_{j=0}^{k-1} a_{k-1-j} \\mathbf{y}(x_{i-j}) - h \\sum_{j=0}^{k} b_{k-j} \\mathbf{f}(x_{i+1-j}, \\mathbf{y}(x_{i-j+1})) \\right].\n\\tag{10.148}\\] Again, the local truncation error determines the global error, i.e., an analogue of Theorem 10.2 for multi-step methods holds. However, we do not discuss this here.\nExamples of \\(k\\)-step multistep methods are the so-called Adams-Bashforth and Adams-Moulton methods. They are derived from rewriting the differential equation as an integral equation, \\[\n\\mathbf{y}'=\\mathbf{f}(x,\\mathbf{y}(x)) \\quad \\Leftrightarrow \\quad\n  \\mathbf{y}(x_{i+1}) = \\mathbf{y}(x_i) + \\int_{x_i}^{x_{i+1}} \\mathbf{f}(x,\\mathbf{y}(x)) \\,dx,\n\\tag{10.149}\\] and then approximating the components \\(\\hat{f}_j\\) on the right hand side with Lagrange interpolating polynomials. The integral can be done explicitly, and one obtains the difference equation of a multi-step method; see (Burden and Faires 2010, sec. 5.6) for details. The number \\(k\\) of steps depends on the number of interpolation points chosen. Adams-Bashforth methods (?tbl-abmethod) are \\(k\\)-step explicit methods of error order \\(O(h^k)\\) and Adams-Moulton methods (?tbl-ammethod) are \\(k\\)-step implicit methods of error order \\(O(h^{k+1})\\),\nNotation: \\(\\mathbf{f}_j := \\mathbf{f}(x_j,\\mathbf{w}_j)\\).\nAs with Taylor and Runge-Kutta methods, the estimates for the local truncation error depend on higher-order total derivatives of \\(\\mathbf{f}\\).\nIn order to apply these multi-step methods in examples, we need additional start values \\(\\mathbf{w}_1=\\boldsymbol{\\alpha}_1, \\ldots,\n\\mathbf{w}_{k-1} = \\boldsymbol{\\alpha}_{k-1}\\). These are normally obtained by using one-step methods of the same error order. For example, for the four-step Adams-Bashforth method, one might use the classical Runge-Kutta method of order \\(O(h^4)\\).\nNotation: \\(\\mathbf{f}_j := \\mathbf{f}(x_j,\\mathbf{w}_j)\\).\n\n10.8.1 Predictor-corrector methods\nImplicit multi-step methods, like the Adams-Moulton methods shown in ?tbl-ammethod, involve the term \\(\\mathbf{f}(x_{i+1},\\mathbf{w}_{i+1})\\) on the right-hand side of the difference equation. This means that \\(\\mathbf{w}_{i+1}\\) is defined only implicitly; it is unclear at first how these methods should be used in practice.\nOne option would be to solve the difference equation for \\(\\mathbf{w}_{i+1}\\), either symbolically (for simple cases of \\(\\mathbf{f}\\)) or numerically. This is useful only in very specific cases; we will come back to this approach in Section 10.9.\nThe other, and indeed frequently used, option is to combine them with explicit multi-step methods into so-called predictor-corrector methods. These work as follows.\nSuppose that \\(\\mathbf{w}_0,\\ldots,\\mathbf{w}_i\\) are already known. These are inserted into the difference equation of an explicit method, the (predictor), which gives an approximation value \\(\\mathbf{w}_{i+1}^{(p)}\\). This value is then inserted into the r.h.s. of the difference equation of an implicit method, the corrector, in order to obtain \\(\\mathbf{w}_{i+1}\\).\nTo illustrate this, let us consider a frequently used case: the Adams-Bashforth 4-step method as the predictor, combined with the Adams-Moulton 3-step method as the corrector. In each step of the method, we compute the “predicted value” by the explicit method, \\[\n\\mathbf{w}_{i+1}^{(p)} = \\mathbf{w}_i +\n      \\frac{h}{24} (55 \\mathbf{f}_i - 59 \\mathbf{f}_{i-1} + 37 \\mathbf{f}_{i-2} - 9 \\mathbf{f}_{i-3}),\n\\tag{10.150}\\] and afterwards the “corrected value” using the implicit method: \\[\n\\mathbf{w}_{i+1} = \\mathbf{w}_i + \\frac{h}{24} (9 \\mathbf{f}(x_{i+1},\\mathbf{w}_{i+1}^{(p)}) + 19 \\mathbf{f}_i - 5\n   \\mathbf{f}_{i-1} + \\mathbf{f}_{i-2}).\n\\tag{10.151}\\] Here \\(\\mathbf{f}_j := \\mathbf{f}(x_j,\\mathbf{w}_j)\\). Both the predictor and the corrector are of order \\(O(h^4)\\), and so is the entire method, as it turns out. However, the combined predictor-corrector method is more precise than each of the parts alone.\n\n\n\\begin{algorithm} \\caption{Adams fourth-order predictor-corrector} \\begin{algorithmic} \\Function{AdamsPredictorCorrector}{$a,b,\\boldsymbol{\\alpha},N$} \\State \\Comment{endpoints $a \\leq b$; initial condition $\\boldsymbol{\\alpha}$; number of steps $N$} \\State $h := (b-a)/N$, $x_0 := a$, $\\boldsymbol{w}_0 := \\boldsymbol{\\alpha}$, $\\boldsymbol{f}_0 := \\boldsymbol{f}(x_0,\\boldsymbol{w}_0)$. \\For { $i = 1,2,3$ } \\Comment{prepare first steps} \\State Compute $\\boldsymbol{w}_i$ using Runge-Kutta fourth order \\State $x_i := x_{i-1}+h$; $\\boldsymbol{f}_i := \\boldsymbol{f}(x_i,\\boldsymbol{w}_i)$ \\EndFor \\For {$i = 4,\\ldots,N$} \\Comment{main approximation} \\State $x := a + ih$ \\State $\\boldsymbol{w} := \\boldsymbol{w}_3 + \\frac{h}{24} (55 \\boldsymbol{f}_3 - 59 \\boldsymbol{f}_2 + 37 \\boldsymbol{f}_1 - 9 \\boldsymbol{f}_0)$ \\Comment{predict} \\State $\\boldsymbol{w} := \\boldsymbol{w}_3 + \\frac{h}{24} (9 \\boldsymbol{f}(x,\\boldsymbol{w}) + 19 \\boldsymbol{f}_3 - 5 \\boldsymbol{f}_2 + \\boldsymbol{f}_1)$ \\Comment{correct} \\For{j = 0,1,2} \\State $x_j := x_{j+1}$; $\\boldsymbol{w}_j := \\boldsymbol{w}_{j+1}$; $\\boldsymbol{f}_j := \\boldsymbol{f}_{j+1}$; \\EndFor \\State $x_3 := x$; $\\boldsymbol{w}_3 := \\boldsymbol{w}$; $\\boldsymbol{f}_3 := \\boldsymbol{f}(x,\\boldsymbol{w})$; \\EndFor \\State \\Return $\\boldsymbol{w}$ \\EndFunction \\end{algorithmic} \\end{algorithm}\n\n\nAlgorithm 10.2 shows this predictor-corrector method in pseudocode. Lines 3–6 use the classical Runge-Kutta method to set up the required initial values, while lines 7–15 implement the actual multistep method. The scheme is quite efficient, since in each step of the method, only two evaluations of the function \\(\\mathbf{f}\\) are used: in line 10 and in line 14 of the algorithm. All other values \\(\\mathbf{f}_j\\) are already known from the previous steps.\n\n\n10.8.2 Advantages and disadvantages\nMultistep methods, in particular Adams-Bashforth and Adams-Moulton methods, can be formulated for any error order \\(O(h^n)\\). However, independent of \\(n\\), they involve only one evaluation of \\(\\mathbf{f}\\) per step (or two for predictor-corrector methods). Compare this with Runge-Kutta methods, where the number of evaluations needed in each step grows approximately like \\(n\\). Therefore, in particular at high orders, multistep methods tend to be faster than Runge-Kutta methods.\nWe can naturally combine an explicit and an implicit method of same error order into a predictor-corrector method, which further improves precision. (It should be noted that a similar approach is possible with implicit Runge-Kutta methods, which we have not discussed here.)\nHowever, multistep methods have the disadvantage that they are more difficult to implement. In particular, an additional one-step method is needed in order to compute the extra start values needed for the method.\nLike for Taylor and Runge-Kutta methods, the error estimates for Adams-Bashforth and Adams-Moulton methods depends on higher-order derivatives of \\(\\mathbf{f}\\), which are not always small. We will discuss this in Section 10.9.\nSimilar to the Runge-Kutta-Fehlberg algorithm described in Section 10.7, we can modify Adams predictor-corrector methods so that they include an automatic choice of the step size. The difference between predicted and corrected value gives a natural indication of the local truncation error. However, the implementation of such a method is not really straightforward, and we do not discuss it in detail here; see for example (Burden and Faires 2010, sec. 5.7). One of the difficulties is that, each time when we change the step size \\(h\\), also the initial values \\(\\boldsymbol{\\alpha}_j\\) need to be computed again. This can make changing the step size rather costly. It is also possible to generalize multistep methods so that they work with variable order. Again, we do not discuss that here.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "ivp.html#sec-stiff",
    "href": "ivp.html#sec-stiff",
    "title": "10  Initial Value Problems",
    "section": "10.9 Stiff equations",
    "text": "10.9 Stiff equations\nIn this section, we will discuss a certain class of initial value problems, called stiff equations, which give rise to particular problems when applying numerical methods to them.\n\nLet us consider the following IVP as an example: \\[\n   y'(x) = - 20y(x) + 10\\cos(2x), \\quad 0 \\leq x \\leq 3, \\quad y(0)=1.\n\\tag{10.152}\\]\nThis IVP has the exact solution \\[\ny(x) =\n  \\underbrace{\\frac{50}{101} \\cos(2x) + \\frac{5}{101} \\sin(2x)}_{\\text{steady-state solution}}\n  + \\underbrace{\\frac{51}{101} \\exp(-20x)}_{\\text{transient solution}} .\n\\tag{10.153}\\] Note here that one part of the solution, the transient solution, decays very rapidly as \\(x\\) grows. For large \\(x\\), only the remainder - the steady-state solution - contributes to \\(y(x)\\).\nWhen applying our approximation methods developed so far to this IVP, one notices the following behaviour: Below a certain “critical step size”, our methods give a reasonable approximation of the exact solution, as expected. However, above this step size, the approximation is completely unreliable, and usually grows very rapidly – although the exact solution is bounded by 1. This applies to all methods developed so far, and going to higher-order methods – such as classical Runge-Kutta – does not help.\nThe reason for this becomes apparent when computing the derivatives of the transient solution: \\[\n\\frac{ \\mathrm{d}^{n}  }{\\mathrm{d}x^{n} }  \\exp(-20x) = (-20)^n \\exp(-20x).\n\\tag{10.154}\\] This expression can be very large, in particular for high \\(n\\). Since our error bounds all depended on the supremum of higher-order derivatives of \\(y(x)\\), this explains the large approximation error.\n\nODEs that show this behaviour are called stiff equations. An exact definition of this term is hard to give. Roughly speaking, their crucial property is that they have a transient part of the solution, which decays very rapidly. Looking at the ODE Eq. 10.152 directly, this might be seen from the large negative factor in front of \\(y\\). Of course, in realistic examples, the exact solution of the problem will not be known, the ODE may look more complicated, and one will need to deal with a system of equations rather than with a single equation, so that it is much harder to deduce the “stiff” behaviour from the ODE directly. In applications, it is often apparent from the context whether a problem is stiff or not. Stiff equations take their name from problems in mechanics: a system with “stiff” springs, i.e., with large spring constants and/or strong friction, is typically described by a stiff ODE.\n\n10.9.1 The test equation\nIn order to understand the problem better, and to decide which numerical methods best to apply, we need a simple but comprehensive test case for our numerical methods. To that end, we apply our methods to the test equation \\[\n   y'(x) = \\lambda y(x), \\quad 0 \\leq x , \\quad y(0)=1,\n\\tag{10.155}\\] where \\(\\lambda \\in \\mathbb{C}\\) is a constant, with \\(\\mathop{\\mathrm{Re}}\\lambda &lt; 0\\). The exact solution is \\[\ny(x) = \\exp(\\lambda x).\n\\tag{10.156}\\] This solution has only a transient part, which makes it ideal for our purposes.\n(We are now dealing with an ODE for a complex-valued function \\(y\\). This does not really need a generalization of our previous methods: We can always split \\(y\\) into a two-vector \\((\\mathop{\\mathrm{Re}}y, \\mathop{\\mathrm{Im}}y)\\), and thus rewrite our equations as a system of two first-order ODEs with real values. However, the complex-valued notation is convenient here. The nonzero imaginary part of \\(\\lambda\\) allows us to include oscillatory solutions as well, with almost no added effort.)\nLet us apply the Euler method to the test equation. The difference equation gives \\[\nw_{i+1} = w_i + h \\,f(x_i,w_i) = w_i + \\lambda h w_i = (1 + \\lambda h) w_i.\n\\tag{10.157}\\] With \\(w_0=1\\), it is then clear that for all \\(i \\in \\mathbb{N}\\),\n\\[\n   w_i = (1+\\lambda h)^i.\n\\tag{10.158}\\] Thus, if \\(|1+\\lambda h|&gt;1\\), the approximation grows exponentially for large \\(i\\), and is therefore “grossly wrong” as the exact solution vanishes for large \\(x\\). If \\(|1+\\lambda h|&lt;1\\), then \\(w_i\\to 0\\), which at least roughly resembles the behaviour of the exact solution.\nFor our other (explicit) approximation methods, one finds in generalization of Eq. 10.158, \\[\n   w_i = \\bigl(Q(\\lambda h)\\bigr)^i\n\\tag{10.159}\\] with some function \\(Q\\) (for explicit methods, \\(Q\\) is in fact a polynomial). The approximation values grow or decay if \\(|Q(\\lambda h)| &gt; 1\\) or \\(|Q(\\lambda h)| &lt; 1\\), respectively.\nThis motivates us to define the region of stability of an approximation method: \\[\n\\mathcal{R}:= \\big\\{\\mu \\in \\mathbb{C} \\;\\big|\\; |Q(\\mu)| &lt; 1 \\big\\}.\n\\tag{10.160}\\] In order for the approximation to be “reasonable”, i.e. to ensure \\(w_i \\to 0\\) as \\(i \\to \\infty\\), we then need to choose our step size \\(h\\) so that \\(h\\lambda \\in \\mathcal{R}\\).\n\n\n\n\n\n\nFigure 10.2: Region of stability for Taylor methods\n\n\n\nSpecifically for Euler’s method, we have \\(Q(\\mu)=1+\\mu\\), and \\(\\mathcal{R}\\) is a disc with center \\(-1\\) and radius \\(1\\). For higher-order Taylor methods, the regions of stability can be computed similarly; they are shown in Figure 10.2. For all examples of Runge-Kutta methods discussed in Section 10.6, the region agrees with that of the Taylor method of the same order. 6\nHowever, from this picture, it appears that all of our methods are vulnerable to the problems posed by stiff equations, as suggested also by the example above. For having a stable method for a large range of step sizes, we need to look at a different approach. It turns out that certain implicit multi-step methods provide an advantage here.\nLet us, in particular, consider the Implicit Trapezoidal method, which is given by the difference equation \\[\n\\begin{split}\n\\mathbf{w}_0&:=\\boldsymbol{\\alpha}, \\\\\n\\mathbf{w}_{i+1} &= \\mathbf{w}_i + \\frac{h}{2} (\\mathbf{f}(x_{i+1},\\mathbf{w}_{i+1}) + \\mathbf{f}(x_i,\\mathbf{w}_i)).\n\\end{split}\n\\tag{10.161}\\] Applying it to the test equation Eq. 10.155, we obtain \\[\nw_{i+1} = w_i + \\frac{h}{2} (\\lambda w_{i+1} + \\lambda w_i)\n  =  \\big( 1 + \\frac{\\lambda h}{2} \\big) w_i  + \\frac{\\lambda h}{2} w_{i+1}.\n\\tag{10.162}\\] We can solve this for \\(w_{i+1}\\): \\[\nw_{i+1} = \\frac{2+\\lambda h}{2-\\lambda h} w_i.\n\\tag{10.163}\\] Thus, the result is again of the form Eq. 10.159, with \\[\nQ(\\mu) = \\frac{2+\\mu}{2-\\mu}.\n\\tag{10.164}\\] Since \\[\n\\begin{gathered}\n|Q(\\mu)| &lt; 1\n    \\quad \\Leftrightarrow \\quad\n|2+\\mu|^2 &lt; |2-\\mu|^2\n\\\\\n    \\quad \\Leftrightarrow \\quad\n4+ 4 \\mathop{\\mathrm{Re}}\\mu + |\\mu|^2\n&lt;\n4- 4 \\mathop{\\mathrm{Re}}\\mu + |\\mu|^2\n    \\quad \\Leftrightarrow \\quad\n\\mathop{\\mathrm{Re}}\\mu &lt; 0,\n\\end{gathered}\n\\tag{10.165}\\] the region of stability \\(\\mathcal{R}\\) is just the left half plane. This is the maximum we could hope for: the implicit trapezoidal method gives reasonable results on stiff problems for all step sizes.\nMethods of this kind, i.e., whose region of stability \\(\\mathcal{R}\\) contains the entire left half plane, are called absolutely stable or A-stable.\nOne can apply the above stability analysis to other implicit methods as well, with some added complication – namely, when solving the difference equation as in Eq. 10.163, we may in general find several solutions. Figure 10.3 show the resulting regions of stability in some examples. Not all implicit methods are A-stable. In fact, there are no A-stable multistep methods of order \\(O(h^3)\\) or above. Sometimes, one uses a class of implicit multistep methods known as backward differentiation methods (BDM), which exist for arbitrary error order and come at least close to A-stability; we do not discuss them here.\n\n\n\n\n\n\nFigure 10.3: Region of stability for Adams-Bashforth and Adams-Moulton methods, AB4: Adams-Bashforth 4-step; AM3/AM4: Adams-Moulton 3-step/4-step; ABM43: Adams-Bashforth-Moulton predictor-corrector, 4/3-step. Graphics taken from\n\n\n\n\n\n10.9.2 Implementing the Implicit Trapezoidal Method\nOur analysis so far suggests that we should use the Implicit Trapezoidal method for the numerical treatment of stiff ODEs. However, since the difference equation of the method defines \\(w_{i+1}\\) only implicitly, this poses conceptual problems.\nIn the extremely simple case of the test equation Eq. 10.155, we were able to solve the difference equation explicitly for \\(w_{i+1}\\); see Eq. 10.163. We can generalize this to the case of a linear ODE: \\[\n   y'(x) = \\ell(x) y(x) + g(x), \\quad a \\leq x \\leq b, \\quad y(a)=\\alpha.\n\\tag{10.166}\\]\nHere \\(\\ell,g\\) are continuous functions from \\([a,b]\\) to \\(\\mathbb{R}\\). In this case, the difference equation Eq. 10.161 of the implicit trapezoidal method reads, \\[\nw_{i+1} = w_i + \\frac{h}{2}\n  \\Big(\n    \\ell(x_{i+1}) w_{i+1} + g(x_{i+1}) +\\ell(x_{i}) w_{i} + g(x_{i})\n  \\Big).\n\\tag{10.167}\\] Much like in Eq. 10.163, this can be solved for \\(w_{i+1}\\): \\[\n\\begin{gathered}\n   w_{i+1}\n  \\Big(\n    1 - \\frac{h}{2}\\ell(x_{i+1})\n  \\Big)\n=\n  \\Big(\n    1 + \\frac{h}{2}\\ell(x_{i})\n  \\Big)\n   + \\frac{h}{2} g(x_{i+1})+ \\frac{h}{2} g(x_{i})\n%\n\\\\\n\\Rightarrow\n\\quad\nw_{i+1} = \\frac{2 + h \\ell(x_{i})}{ 2 - h \\ell(x_{i+1})} w_i\n+ h \\frac{g(x_{i+1}) + g(x_{i}) }{2 - h \\ell(x_{i+1})}.\n\\end{gathered}\n\\tag{10.168}\\] Thus, for linear ODEs as in Eq. 10.166, the implicit trapezoidal method can be applied with an explicit difference equation.\nFor a nonlinear ODE, it will generally not be possible to solve the difference equation symbolically. However, we can try to solve it numerically. As an approach for numerically solving nonlinear equations, we shall use Newton Iteration.\nAs a reminder: 7 Let \\(F: \\mathbb{R} \\to \\mathbb{R}\\) be twice differentiable; suppose we are looking for a solution \\(x\\) of the equation \\[\nF(x) = 0.\n\\tag{10.169}\\] This solution is found with Newton’s method as follows. Starting with \\(x_0\\) sufficiently close to a solution, one recursively defines the sequence \\[\n   x_k := x_{k-1} - \\frac{F(x_{k-1})}{F'(x_{k-1})}.\n\\tag{10.170}\\] Then \\(x_k \\to x_\\infty\\) with \\(F(x_\\infty)=0\\).\nWhen implementing this on a computer, one cannot pass to the limit \\(k \\to \\infty\\), but needs to stop the iteration when a sufficient precision is reached. In practice, one usually takes the magnitude of the difference term on the r.h.s. of Eq. 10.170 as an indicator: The iteration is stopped when \\(|F(x_{k-1})/F'(x_{k-1})|&lt;T\\), where \\(T&gt;0\\) is the desired tolerance level.\nIn our situation of the implicit trapezoidal method, we need to solve the equation \\[\nw_{i+1} = w_i + \\frac{h}{2} \\big( f(x_i,w_i)+ f(x_{i+1},w_{i+1})\\big).\n\\tag{10.171}\\] for \\(w_{i+1}\\), where \\(x_i\\), \\(x_{i+1}\\), \\(w_i\\) are given numbers. In other words, we are looking for zeros of the function \\[\nF(\\hat{w}) = \\hat{w} - w_i - \\frac{h}{2} \\big( f(x_i,w_i)+ f(x_{i+1},\\hat{w})\\big).\n\\tag{10.172}\\] Following Eq. 10.170, the following sequence should converge to the solution \\(w_{i+1}\\): \\[\n\\begin{aligned}\n     \\hat{w}_0 &:= w_{i},\\\\\n     \\hat{w}_k &:= \\hat{w}_{k-1} - \\underbrace{\\frac{\\hat{w}_{k-1} - w_i - \\frac{h}{2}\\big(\n       f(x_i,w_i) + f(x_{i+1},\\hat{w}_k)\n     \\big)}{ 1 - \\frac{h}{2} \\frac{\\partial f}{\\partial\n     y}(x_{i+1},\\hat{w}_{k-1}) }}_{=:v}.\n  \\end{aligned}\n\\tag{10.173}\\] We would run this iteration until \\(|v|&lt;T\\).\nBoth in the case of linear and nonlinear equations, we have so far discussed a single ODE only. For applications in practice, we would need to generalize the methods to systems of ODEs. This is indeed possible, but requires a bit of thought.\nIn the linear case Eq. 10.166, one would consider a matrix-valued function \\(\\ell\\) and a vector-valued \\(g\\). The difference equation can then still be solved symbolically, like in Eq. 10.168; however, the division by the factor \\((2-h\\ell(x_{i+1}))\\) needs to be replaced by a multiplication with an inverse matrix, or equivalently, by solving a system of linear equations. Likewise, in the nonlinear case, we can handle ODE systems but would need the multi-dimensional version of Newton’s method (or, in other words, Newton’s method for systems of nonlinear equations). We shall not discuss the details of this generalization here.\n\n\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical Analysis. 9th ed. Brooks Cole.\n\n\nStewart, J. 1991. Calculus. Brooks/Cole.\n\n\nWeir, M. D., G. B. Thomas, and J. Hass. 2010. Thomas’ Calculus. Addison-Wesley.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "ivp.html#footnotes",
    "href": "ivp.html#footnotes",
    "title": "10  Initial Value Problems",
    "section": "",
    "text": "The same example is considered in (Burden and Faires 2010, sec. 5.3).↩︎\nThe names of methods may vary in the literature; it is best to compare the tableaux when reading different sources!↩︎\nIf you hear someone speaking of “the Runge-Kutta method”, they are probably referring to this \\(O(h^4)\\) method.↩︎\nThis is not necessarily a realistic assumption - but one that simplifies the proof. One can do a similar argument using local bounds on \\(\\mathbf{f}\\) and its derivatives in a suitable neighbourhood of the exact solution; however, this introduces formal complications which we want to avoid here.↩︎\nWe will not deal with any “global” error behaviour here.↩︎\nThis is true for all of our examples, but not for all Runge-Kutta methods in general.↩︎\nFor more details on Newton’s method for solving (single) nonlinear equations, see Section 3.5, or (Burden and Faires 2010, sec. 2.3).↩︎",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Initial Value Problems</span>"
    ]
  },
  {
    "objectID": "bvp.html",
    "href": "bvp.html",
    "title": "11  Boundary Value Problems",
    "section": "",
    "text": "11.1 Fundamentals\nIn this last part of the course, we will consider boundary problems (BVPs) for ODEs, specifically second-order ODEs. Here, in contrast to initial value problems, one does not specify the value of the function \\(y\\) and its derivative at the left-hand side of the interval in question. Rather, one fixes the value of \\(y(x)\\) at both the left- and the right-hand side. The BVP we will consider throughout is\n\\[\ny''(x) = f(x,y(x),y'(x)),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha, \\; y(b) = \\beta,\n\\tag{11.1}\\]\nwhere \\(f: [a,b] \\times \\mathbb{R}^2 \\to \\mathbb{R}\\) and \\(\\alpha,\\beta \\in \\mathbb{R}\\).\nBoundary value problems for first-order ODEs are not meaningful, so we need to consider at least ODEs of second order. One can as well formulate BVPs for higher-order ODEs, for systems of ODEs, or by specifying the derivative \\(y'\\) at the boundary rather than the function \\(y\\) itself. We will however not treat these cases here.\nOur first question is whether a unique solution of Eq. 11.1 exists, before approximating it numerically. This question turns out to be more delicate than with IVPs. We first consider a few examples.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Boundary Value Problems</span>"
    ]
  },
  {
    "objectID": "bvp.html#sec-fundamentals",
    "href": "bvp.html#sec-fundamentals",
    "title": "11  Boundary Value Problems",
    "section": "",
    "text": "Example 11.1 Let us consider the very simple BVP \\[\ny'' = y,  \\quad 0 \\leq x \\leq 1, \\quad y(0) = y(1) = 1.\n\\tag{11.2}\\] The ODE \\(y''=y\\) itself (disregarding the boundary conditions for a moment) clearly has the two solutions \\(y(x)=e^x\\) and \\(y(x)=e^{-x}\\). From the theory of linear ODEs, one knows then that the general solution of the ODE is \\[\ny(x) = c e^x + de^{-x},\\quad c,d \\in \\mathbb{R}.\n\\tag{11.3}\\] That is, every solution of \\(y''=y\\) has this form. Now inserting the boundary conditions, we have \\[\n1 = c e^0 + d e^0 = c + d \\quad \\Leftrightarrow \\quad d = 1-c,\n\\tag{11.4}\\] and \\[\n   1 = c e^1 + d e^{-1} = ce + \\frac{d}{e} \\quad \\Leftrightarrow \\quad  1\n     = ce + \\frac{1-c}{e} = c\\left(e-\\frac{1}{e}\\right) + \\frac{1}{e}.\n\\tag{11.5}\\] From Eq. 11.5, we find that the boundary conditions are satisfied if and only if \\[\n1 - \\frac{1}{e} = c\\left(e-\\frac{1}{e}\\right) \\quad \\Leftrightarrow \\quad\n  c = \\frac{e-1}{e^2-1} = \\frac{1}{e+1},\n\\tag{11.6}\\] of which we compute \\(d = 1-c = \\frac{e}{e+1}\\). That means, the function \\[\ny(x) = \\frac{e^x}{e+1} + \\frac{e^{1-x}}{e+1}\n\\tag{11.7}\\] is a solution of the BVP Eq. 11.2, and by our computation, it is the only solution of the BVP. In short, Eq. 11.2 has a unique solution.\n\n\nExample 11.2 Now let us consider a slightly modified BVP, \\[\ny'' = -y,  \\quad 0 \\leq x \\leq 2 \\pi, \\quad y(0) = y(2\\pi) = 1.\n\\tag{11.8}\\]\nAgain, from the theory of linear ODEs, one knows that the general solution of the ODE (disregarding the boundary conditions) is\n\\[\n   y(x) = c \\cos(x)+ d \\sin(x),\\quad c,d \\in \\mathbb{R}.\n\\tag{11.9}\\] The boundary conditions demand that \\[\n1=y(0) = c \\cos(0) + d \\sin(0) = c \\Leftrightarrow c=1,\\quad\n\\tag{11.10}\\] and likewise \\[\n   1=y(2\\pi) = c  \\Leftrightarrow c=1.\n\\tag{11.11}\\] However, the choice of \\(d\\) does not affect the boundary conditions! In fact, any function of the form \\[\ny(x) = \\cos(x)+ d \\sin(x),\\quad d \\in \\mathbb{R}\n\\tag{11.12}\\] solves the BVP Eq. 11.8. This BVP has many solutions.\n\n\nExample 11.3 Finally, consider another slight modification of our example:\n\\[\ny'' = -y,  \\quad 0 \\leq x \\leq 2 \\pi, \\quad y(0) = 0, \\; y(2\\pi) = 1.\n\\tag{11.13}\\]\nAgain, the general solution of the ODE is given by Eq. 11.9. However, now our boundary conditions demand that \\[\n0=y(0) = c ,\\quad\n\\text{and }\n   1=y(2\\pi) = c,\n\\tag{11.14}\\] which gives us a contradiction. In other words, the BVP Eq. 11.13 has no solution.\n\n\n11.1.1 A criterion\nWe need a criterion that guarantees that a BVP has a unique solution. As is clear from the above examples, the Lipschitz condition which we previously considered does not suffice. The following theorem (Burden and Faires 2010 Theorem 11.1), which we quote here without proof, gives a sufficient (not a necessary) criterion.\n\nTheorem 11.1 Suppose that \\(f:[a,b] \\times \\mathbb{R}^2 \\to \\mathbb{R}\\) is continuous, that the partial derivatives1 \\(\\partial f(x,y,y') / \\partial y\\) and \\(\\partial f(x,y,y') / \\partial y'\\) exist and are continuous, and that*\n\n\\(\\dfrac{\\partial f}{\\partial y}(x,y,y') &gt; 0\\) for all \\(x \\in [a,b]\\), \\(y,y' \\in \\mathbb{R}\\),\n\\(\\Big\\lvert \\dfrac{\\partial f}{\\partial y'}(x,y,y') \\Big\\rvert \\leq M\\) for all \\(x \\in [a,b]\\), \\(y,y' \\in \\mathbb{R}\\),\n\nwith a constant \\(M&gt;0\\). Then, the boundary value problem\n\\[\ny''(x) = f(x,y(x),y'(x)),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha, \\; y(b) = \\beta\n\\tag{11.15}\\]\nhas a unique solution for any \\(\\alpha,\\beta \\in \\mathbb{R}\\).\n\nBriefly speaking, in order to obtain a unique solution, it suffices that \\(\\partial f / \\partial y\\) is positive and \\(\\partial f / \\partial y'\\) is bounded. The former condition was violated in our examples Eq. 11.8 and Eq. 11.13.\n\n\n11.1.2 Linear ODEs\nWe will often consider the simplified, but still very relevant, case of boundary value problems for linear ODEs. By this, we mean a BVP of the form \\[\ny''(x) = p(x) y'(x) + q(x) y(x) + r(x),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha, \\; y(b) = \\beta,\n\\tag{11.16}\\]\nwhere \\(p,q,r: [a,b]\\to\\mathbb{R}\\). A uniqueness criterion for these can be given as follows.\n\nTheorem 11.2 Suppose that \\(p,q,r \\in \\mathcal{C}^0([a,b])\\), and that \\(q(x)&gt;0\\) for all \\(x \\in [a,b]\\). Then, the boundary value problem Eq. 11.16 has a unique solution for any \\(\\alpha,\\beta \\in \\mathbb{R}\\).\n\n\nProof. This follows immediately from Theorem 11.1. In the present case, \\[\n\\begin{split}\nf(x,y,y') &=  p(x) y' + q(x) y + r(x),\\\\\n\\quad \\frac{\\partial f(x,y,y'}{\\partial y} &= q(x),\\\\\n\\quad \\frac{\\partial f(x,y,y'}{\\partial y'} &= p(x),\n\\end{split}\n\\tag{11.17}\\] and continuous functions on a bounded interval are always bounded. ◻\n\n\n\n11.1.3 Approximation methods\nIn the following sections, we will discuss three very different approximation methods for the solutions of BVPs:\n\nthe Shooting Method, which makes use of the techniques for IVPs which we discussed in Chapter 10,\nthe Finite Difference Method, which approximates the derivatives of the ODE with difference quotients,\nthe Rayleigh-Ritz Method, which reformulates the BVP as a minimization problem of a certain integral.\n\nThe Finite Difference Method and the Rayleigh-Ritz method are particularly important: first, because they are adapted to the nature of boundary value problems; second, because they have generalizations to the approximation theory of partial differential equations.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Boundary Value Problems</span>"
    ]
  },
  {
    "objectID": "bvp.html#the-shooting-method",
    "href": "bvp.html#the-shooting-method",
    "title": "11  Boundary Value Problems",
    "section": "11.2 The Shooting Method",
    "text": "11.2 The Shooting Method\nAs the first approximation method for the solutions of BVPs, we will discuss the Shooting Method. It works by transforming the boundary value problem into an initial value problem, and then using our known approximation methods for BVPs.\n\n11.2.1 The idea\nWe will consider the BVP \\[\ny''(x) = f(x,y(x),y'(x)),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha, \\; y(b) = \\beta.\n\\tag{11.18}\\]\nFor applying our approximation methods for IVPs to the differential equation, we are missing one initial value, namely for \\(y'(a)\\).\nLet us, for the moment, just pick some fixed \\(\\gamma \\in \\mathbb{R}\\), and then consider the initial value problem \\[\n  y_\\gamma''(x) = f(x,y_\\gamma(x),y_\\gamma'(x)),  \\quad a \\leq x \\leq b, \\quad y_\\gamma(a) = \\alpha, \\; y_\\gamma'(a) = \\gamma.\n\\tag{11.19}\\]\n(The solution \\(y_\\gamma(x)\\) will depend on our choice of \\(\\gamma\\), and we indicate this with the \\(\\gamma\\) subscript.) We can solve the IVP Eq. 11.19 with one of our known approximation methods. This will yield an approximation value \\(w_N \\approx y_\\gamma(b)\\). Now we can compare whether our choice of \\(\\gamma\\) was reasonable: Namely, we can see whether \\(w_N \\approx \\beta\\), or how far \\(w_N\\) is away from \\(\\beta\\). Depending on this result, we adjust our value \\(\\gamma\\), and run the approximation method for Eq. 11.19 again. We repeat this until \\(w_N \\approx \\beta\\) to a reasonable precision; then the \\(w_j\\) will approximate \\(y(x_j)\\), where \\(y\\) is the solution of the BVP Eq. 11.18.\n\n\n11.2.2 Systematic Approach\nThe open point is how to choose the value \\(\\gamma\\). Of course, we want a systematic (i.e., algorithmic) way to find the optimum value.\nTo formalize this, let us consider the map \\[\ng: \\mathbb{R} \\to \\mathbb{R}, \\; \\gamma \\mapsto y_\\gamma(b),\n\\tag{11.20}\\] where \\(y_\\gamma(x)\\) is the exact solution of the IVP Eq. 11.19. We already have methods to compute \\(g\\) approximately (by using approximation methods for IVPs). We need to find \\(\\gamma\\) such that \\(y_{ \\gamma}(x)=\\beta\\), i.e., such that\n\\[\n   g( \\gamma) = \\beta.\n\\tag{11.21}\\] In other words, we need to find an (approximate) solution to the equation Eq. 11.21. We will consider two cases:\nIn the simpler case, \\(g\\) is a linear function, i.e., \\(g(\\gamma)=m\\gamma + c\\). In this case, Eq. 11.21 can be solved explicitly (once \\(m\\) and \\(c\\) are known), namely\n\\[\n   \\gamma = \\frac{\\beta - c}{m}.\n\\tag{11.22}\\] It remains to determine the constants \\(m\\) and \\(c\\).\nMore generally, \\(g\\) can be a nonlinear function, and in this case we need to solve Eq. 11.21 numerically. We will use Newton’s method to that end. That is, we consider a sequence \\(\\gamma_k\\), recursively defined by\n\\[\n   \\gamma_k := \\gamma_{k-1} - \\frac{g(\\gamma_{k-1})-\\beta}{g'(\\gamma_{k-1})},\n\\tag{11.23}\\]\nwhich is expected to converge to the desired value \\(\\gamma\\). To that end, it remains to compute the derivative \\(g'\\) of the map \\(g\\).\n\n\n11.2.3 Linear Shooting\nLet us first consider the linear case. Not very surprisingly, this arises when the underlying ODE is linear. That is, let us assume that our BVP is of the form \\[\ny''(x) = p(x) y'(x) + q(x) y(x) + r(x),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha, \\; y(b) = \\beta,\n\\tag{11.24}\\]\nwith \\(p,q,r\\) being continuous functions on \\([a,b]\\).\nIt turns out to be convenient to consider two related IVPs, neither of which involves the value \\(\\gamma\\): \\[\ny_0''(x) = p(x) y_0'(x) + q(x) y_0(x) + r(x),  \\quad a \\leq x \\leq b,  \\quad y_0(a) = \\alpha,\\quad  y_0'(a) = 0;\n\\tag{11.25}\\] \\[\nz'' = p(x) z'(x) + q(x) z(x) , \\quad  a \\leq x \\leq b, \\quad z(a) = 0, \\quad z'(a) = 1.\n\\tag{11.26}\\] Using their exact solutions \\(y_0(x)\\) and \\(z(x)\\), we can define \\[\n  y_\\gamma(x) := y_0(x) + \\gamma z(x);\n\\tag{11.27}\\] and by adding Eq. 11.25 and Eq. 11.26, we see that this \\(y_\\gamma\\) is the (unique) solution of the IVP Eq. 11.19.\nThe solutions \\(y_0(x)\\) and \\(z(x)\\) can be found (approximately) by our known methods from Chapter 10. We can then compute the correct value of \\(\\gamma\\) for our boundary value problem, as indicated in Eq. 11.22: \\[\n     \\gamma = \\frac{\\beta - y_0(b)}{z(b)}.\n\\tag{11.28}\\] Re-inserting this value \\(\\gamma\\) into Eq. 11.27, we have found the (approximate) solution of the BVP.\n\n\n\\begin{algorithm} \\caption{The Linear Shooting method with Runge-Kutta approximation} \\begin{algorithmic} \\Function{LinearShooting}{$a,b,\\alpha,\\beta,N$} \\State \\Comment{boundary values $\\alpha,\\beta$; number of Runge-Kutta steps $N$} \\State $F :=\\; (x,\\mathbf{u}) \\mapsto (u^{(2)},p(x) u^{(2)} + q(x) u^{(1)} + r(x))$ \\Comment{Rewrite and solve IVP for $y_0$} \\State $ \\mathbf{y} := $ \\Call{RungeKutta}{$F, a,b, (\\alpha,0), N$} \\Comment{$\\mathbf{y} = ( \\mathbf{y}_0,\\ldots, \\mathbf{y}_N)$, each $\\mathbf{y}_j$ is a 2-vector} \\State $G :=\\; (x,\\mathbf{u}) \\mapsto (u^{(2)},p(x) u^{(2)} + q(x) u^{(1)})$ \\Comment{Rewrite and solve IVP for $z$} \\State $ \\mathbf{z} := $ \\Call{RungeKutta}{$G, a,b, (0,1), N$} \\Comment{$\\mathbf{z} = ( \\mathbf{z}_0,\\ldots, \\mathbf{z}_N)$, each $\\mathbf{z}_j$ is a 2-vector} \\State $\\gamma := \\dfrac{\\beta - y_N^{(1)} }{z_N^{(1)}}$ \\Comment{Determine correct initial value} \\For{$i = 0,\\ldots,N$} \\State $w_i := y_i^{(1)} + \\gamma z_i^{(1)}$ \\Comment{compute solution of BVP} \\EndFor \\Return ($w_{0},\\ldots,w_{N}$) \\EndFunction \\end{algorithmic} \\end{algorithm}\n\n\nAlgorithm 11.1 summarizes the Linear Shooting Method. We first rewrite the IVP Eq. 11.25 for \\(y_0\\) as a system of two first-order ODEs, and approximate its solution (lines 3–4). For concreteness’ sake, we choose the classical Runge-Kutta method for the approximation. We do likewise with the IVP Eq. 11.26 for \\(z\\), in lines 5–6. Now we can compute the correct value of \\(\\gamma\\) (line 7), and combine the approximations for \\(y_0\\) and \\(z\\) into the approximation of the BVP solution (lines 8–10).\n\n\n11.2.4 Nonlinear Shooting\nNow let us turn to the nonlinear case, i.e., to a generic BVP of the form \\[\ny''(x) = f(x,y(x),y'(x)),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha, \\; y(b) = \\beta.\n\\tag{11.29}\\]\nAs said before, we will use Newton’s method for finding the correct value of \\(\\gamma\\). That means, we need to compute the sequence \\((\\gamma_k)\\) given by \\[\n  \\gamma_k := \\gamma_{k-1} - \\frac{g(\\gamma_{k-1})-\\beta}{g'(\\gamma_{k-1})}.\n\\tag{11.30}\\]\nTo that end, we need to know how to compute \\(g(\\gamma)\\) and \\(g'(\\gamma)\\) numerically.\nHere finding \\(g(\\gamma)\\) is not difficult: We have \\(g(\\gamma)=y_\\gamma(b)\\), where \\(y_\\gamma\\) is the solution of the IVP\n\\[\n  y_\\gamma''(x) = f(x,y_\\gamma(x),y_\\gamma'(x)),  \\quad a \\leq x \\leq b, \\quad y_\\gamma(a) = \\alpha, \\; y_\\gamma'(a) = \\gamma.\n\\tag{11.31}\\]\nWe can approximate this solution numerically with any of our known methods – say, classical Runge-Kutta – and thus obtain an approximation of \\(g(\\gamma)\\).\nHowever, for its derivative \\(g'\\), the right approach is much less obvious. We need to compute \\[\ng'(\\gamma) = \\frac{\\partial}{\\partial \\gamma} y_\\gamma(x)\\Big|_{x=b} .\n\\tag{11.32}\\] In order to find this value, we differentiate Eq. 11.31 by \\(\\gamma\\), using the chain rule.\n\\[\n\\; \\frac{\\partial y_\\gamma'}{\\partial \\gamma}(a) = 1.\n\\tag{11.33}\\] This does not determine \\(\\partial y_\\gamma/\\partial \\gamma\\) directly. However, it gives us a second-order IVP from which the derivative can be determined.\nTo make this more concrete, let us use the substitution \\[\nu ^{(1)} = y_\\gamma, \\quad\n   u ^{(2)} = y_\\gamma', \\quad\n   u ^{(3)} = \\frac{\\partial y_\\gamma}{\\partial \\gamma}, \\quad\n   u ^{(4)} = \\frac{\\partial y_\\gamma'}{\\partial \\gamma}.\n\\tag{11.34}\\] We can then rewrite Eq. 11.31 and Eq. 11.33 into an IVP for 4 first-order ODEs: \\[\n\\mathbf{u}' = \\begin{pmatrix}\nu^{(2)} \\\\ f(x,u^{(1)},u^{(2)}) \\\\ u^{(4)} \\\\\n\\dfrac{\\partial f}{\\partial y}(x,u^{(1)},u^{(2)}) \\, u^{(3)} +\n\\dfrac{\\partial f}{\\partial y'}(x,u^{(1)},u^{(2)}) \\, u^{(4)}        \n\\end{pmatrix},\n\\quad a \\leq x \\leq b, \\quad \\mathbf{u}(a) =\n   \\begin{pmatrix}\n         \\alpha \\\\ \\gamma \\\\ 0 \\\\ 1\n     \\end{pmatrix} .\n\\tag{11.35}\\] From this IVP, which can be treated, e.g., with the classical Runge-Kutta method, we can now read off \\[\ng(\\gamma) = u ^{(1)}(b), \\quad g'(\\gamma) = u ^{(3)}(b).\n\\tag{11.36}\\] This finally allow us to compute the Newton step Eq. 11.30.\n\n\n\\begin{algorithm} \\caption{The Nonlinear Shooting method with Runge-Kutta approximation} \\begin{algorithmic} \\Function{NonlinearShooting}{$a,b,\\alpha,\\beta,\\gamma_0,N,T,M$} \\State \\Comment{boundary values $\\alpha,\\beta$; start value $\\gamma_0$; number of Runge-Kutta steps $N$;} \\State \\Comment{tolerance $T$; maximum number of Newton iterations $M$} \\State $F:= (x,\\mathbf{u}) \\mapsto \\big(u^{(2)}, f(x,u^{(1)},u^{(2)}), u^{(4)} , \\frac{\\partial f}{\\partial y}(x,u^{(1)},u^{(2)}) \\, u^{(3)} +\\frac{\\partial f}{\\partial y'}(x,u^{(1)},u^{(2)}) \\, u^{(4)} \\big)$ \\State $\\gamma := \\gamma_0$; $k:=0$ \\While{$k\\leq M$} \\State $ \\mathbf{w} := $ \\Call{RungeKutta}{$F, a,b, (\\alpha,\\gamma,0,1), N$} \\State \\Comment{here $\\mathbf{w} = ( \\mathbf{w}_0,\\ldots, \\mathbf{w}_N)$, each $\\mathbf{w}_j$ is a 4-vector} \\State $v := \\dfrac{w_{N}^{(1)}-\\beta}{w_{N}^{(3)}}$; $\\gamma := \\gamma - v$ \\If{$|v|&lt;T$} \\Break \\EndIf \\State $k:=k+1$ \\EndWhile \\Return ($w_{0}^{(1)},\\ldots,w_{N}^{(1)}$) \\EndFunction \\end{algorithmic} \\end{algorithm}\n\n\nLet us summarize the Nonlinear Shooting Method in Algorithm 11.2. Its structure is of the now well-known Newton iteration type. In each iteration of the loop, we solve the IVP Eq. 11.35 with the classical Runge-Kutta method. We then pick the approximation values at the rightmost mesh point and compute the next \\(\\gamma\\) value from them. The usual methods of breaking the Newton loop are in place - either after sufficient precision is reached, or (with an error) after too many steps have been taken.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Boundary Value Problems</span>"
    ]
  },
  {
    "objectID": "bvp.html#sec-fdm",
    "href": "bvp.html#sec-fdm",
    "title": "11  Boundary Value Problems",
    "section": "11.3 The Finite Difference Method",
    "text": "11.3 The Finite Difference Method\nThe Finite Difference Method (FDM) is another, very different method of approximating the solution of the BVP \\[\ny''(x) = f(x,y(x),y'(x)),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha, \\; y(b) = \\beta.\n\\tag{11.37}\\]\nThis method does not refer back to our approximation methods for IVPs, but is adapted directly to BVPs.\n\n11.3.1 The idea\nSimilar to before, we divide our interval with equally spaced mesh points, \\(x_0,\\ldots,x_{N+1}\\), where \\(x_0=a\\) and \\(x_{N+1}=b\\).2 As before, we want to approximate \\(y(x_i)\\) with a value \\(w_i\\) (\\(i=1,\\ldots,N\\)).\nThe main idea of the FDM is to approximate the derivatives \\(y'(x_i)\\) and \\(y''(x_i)\\) with difference quotients (“finite differences”). For example, we could use \\[\n   y'(x_i) \\approx \\frac{w_{i+1}-w_i}{h},\n\\tag{11.38}\\] but we will see an even better choice later. A similar approximation will need to be found for \\(y''(x_i)\\).\nIn this way, the ODE is transformed into a system of equations for \\(w_1,\\ldots,w_N\\), and the boundary conditions are expressed by \\(w_0=\\alpha\\), \\(w_{N+1}=\\beta\\).\n\n\n11.3.2 Centred difference formulas\nAs a first step, we will derive an improved version of the difference quotient approximation Eq. 11.38, in which the error term was of order \\(O(h)\\). Let us assume that the solution \\(y(x)\\) of the BVP has three continuous derivatives. We write down second-order Taylor expansions of \\(y(x_{i+1})\\) and \\(y(x_{i-1})\\), cf. Theorem A.1: \\[\n{4}\n  y(x_{i+1}) \\;=\\; y(x_i+h) = y(x_i) + h y'(x_i) + \\frac{h^2}{2} y''(x_i)\n  + \\frac{h^3}{6} y'''(\\xi_+);\n\\tag{11.39}\\] \\[\n  y(x_{i-1}) = y(x_i-h) = y(x_i) - h y'(x_i) + \\frac{h^2}{2} y''(x_i)\n- \\frac{h^3}{6} y'''(\\xi_-)\n\\tag{11.40}\\] with some \\(\\xi_+ \\in [x_i,x_{i+1}]\\) and \\(\\xi_- \\in [x_{i-1},x_{i}]\\). Subtracting Eq. 11.40 from Eq. 11.39, we obtain \\[\ny(x_{i+1}) - y(x_{i-1}) = 2 h y'(x_i) + \\frac{h^3}{6}\n\\underbrace{\\big(\n   y'''(\\xi_+) + y'''(\\xi_-)\n\\big)}_{\n  2 y'''(\\xi)\n}.\n\\tag{11.41}\\] Here \\(\\xi \\in [x_{i-1},x_{i+1}]\\) is some point obtained from the intermediate value theorem. Solving for \\(y'(x_i)\\), we find\n\\[\ny'(x_i) = \\frac{ y(x_{i+1}) - y(x_{i-1}) }{2h} - \\frac{h^2}{6} y'''(\\xi).\n\\tag{11.42}\\]\nThis is known as a centred difference formula. Note that the “error term” here is of order \\(O(h^2)\\) which is better than the \\(O(h)\\) one obtains in Eq. 11.38.\nWe can obtain a similar formula for \\(y''(x_i)\\) as well, using a third-order Taylor expansion of \\(y\\). See (Burden and Faires 2010, sec. 4.1, Eq. (4.9)) for details. The result is \\[\ny''(x_i) = \\frac{ y(x_{i+1}) - 2 y(x_i) + y(x_{i-1}) }{h^2} - \\frac{h^2}{12} y''''(\\xi)\n\\tag{11.43}\\]\nwith some \\(\\xi \\in [x_{i-1},x_{i+1}]\\).\n\n\n11.3.3 Recipe for the Finite Difference Method\nWe can now formulate an outline of the FDM in our context. Starting from a boundary value problem of the form Eq. 11.37, we consider the \\(N\\) equations\n\\[\n   y''(x_i) = f\\big(x_i, y(x_i), y'(x_i)\\big), \\quad  i = 1,\\ldots,N.\n\\tag{11.44}\\]\nIn order to obtain an approximate solution, we manipulate the equations as follows:\n\nReplace all occurrences of \\(y(x_i)\\) with \\(w_i\\).\nReplace all occurrences of \\(y'(x_i)\\) with \\(\\dfrac{w_{i+1}-w_{i-1}}{2h}\\); cf. Eq. 11.42.\nReplace all occurrences of \\(y''(x_i)\\) with \\(\\dfrac{w_{i+1}-2 w_i +w_{i-1}}{h^2}\\); cf. Eq. 11.43.\nSet \\(w_0=\\alpha\\), \\(w_{N+1}=\\beta\\).\n\nThis will leave us with a system of \\(N\\) equations for the \\(N\\) variables \\(w_1,\\ldots,w_N\\). This equation system can either be linear, in which case we can apply algorithms for solving linear equation systems (see Chapter 5); or it can be nonlinear, in which case we need Newton’s method in several variables (see Chapter 4) to approximate the solution.\nThe error order of this approximation scheme is determined by the remainder term in the centred difference formulas, Eqs. Eq. 11.42 and Eq. 11.43; namely, the method is of order \\(O(h^2)\\). However, we will not prove this here.\n\n\n11.3.4 The Linear Finite Difference Method\nLet us first apply the recipe to a linear ODE, that is, to a boundary value problem of the form \\[\ny''(x) = p(x)y'(x) + q(x) y(x) + r(x),  \\quad a \\leq x \\leq b, \\quad y(a) = \\alpha, \\; y(b) = \\beta.\n\\tag{11.45}\\]\nIn this case, Eq. Eq. 11.44 reads \\[\ny''(x_i) = p(x_i) y'(x_i) + q(x_i) y(x_i) + r(x_i), \\quad  i = 1,\\ldots,N.\n\\tag{11.46}\\] By the substitution rules mentioned above, and with the abbreviations \\(p_i:=p(x_i)\\), \\(q_i:=q(x_i)\\), \\(r_i := r(x_i)\\), we get: \\[\n\\dfrac{w_{i+1}-2 w_i +w_{i-1}}{h^2}\n= p_i \\dfrac{w_{i+1}-w_{i-1}}{2h} + q_i w_i + r_i, \\quad  i = 1,\\ldots,N.\n\\tag{11.47}\\] Multiplying with \\(h^2\\), and bringing all \\(w_j\\) to the left-hand side, we can rewrite this as \\[\nw_{i+1}-2 w_i +w_{i-1} - \\frac{h}{2}p_i w_{i+1}\n+ \\frac{h}{2}p_i w_{i-1} -  h^2 q_i w_i = h^2 r_i,\n\\tag{11.48}\\] or\n\\[\n  \\left(-1+ \\frac{h}{2}p_i\\right) w_{i+1}  \n  + (2+h^2q_i) w_i\n  + \\left(-1- \\frac{h}{2}p_i\\right) w_{i-1}  \n  = - h^2 r_i\n\\tag{11.49}\\] for \\(i = 1,\\ldots,N\\).\nNote here that \\(w_{i-1}\\) may be \\(w_0\\) (if \\(i=1\\)) and \\(w_{i+1}\\) may be \\(w_{N+1}\\) (if \\(i=N\\)). So not all \\(w_j\\) are variables, some need to be replaced with the boundary values \\(\\alpha\\) and \\(\\beta\\). Keeping this in mind, we can rewrite the equation system Eq. 11.49 in matrix form: \\[\n\\begin{gathered}\n\\underbrace{ \\begin{pmatrix}\n2+h^2 q_1 & -1+\\frac{h}{2} p_1 & 0 & \\cdots & 0\n\\\\\n-1-\\frac{h}{2}p_2 & 2 + h^2 q_2 & -1+\\frac{h}{2} p_2 & 0 & \\vdots \\\\\n0 & \\ddots & \\ddots & \\ddots & 0\\\\\n\\vdots & 0 &  -1-\\frac{h}{2}p_{N-1} & 2 + h^2 q_{N-1} & -1+\\frac{h}{2}\np_{N-1}\\\\\n0 & \\cdots & 0 & -1-\\frac{h}{2}p_N & 2 + h^2 q_N   \n\\end{pmatrix} }_{=:\\mathbf{A}}\n\\mathbf{w}\n%\n\\\\\n%\n=\\underbrace{ \\begin{pmatrix}\n%\n-h^2 r_1 + (1+\\frac{h}{2}p_1)\\alpha  \n\\\\\n-h^2 r_2\n\\\\\n\\vdots\n\\\\\n-h^2 r_{N-1}\n\\\\\n-h^2 r_N + (1-\\frac{h}{2}p_N)\\beta  \n%\n\\end{pmatrix} }_{=:\\mathbf{b}}\n.\n%\n\\end{gathered}\n\\tag{11.50}\\] The matrix \\(\\mathbf{A}\\) is tridiagonal. Therefore, we can use fast algorithms (e.g. Crout factorization) in order to solve the linear equation system, and obtain the vector \\(\\mathbf{w}=(w_1,\\ldots,w_N)\\) in \\(O(N)\\) time. This directly gives us the required approximation of the solution \\(y(x)\\).\n\n\n11.3.5 The Nonlinear Finite Difference Method\nLet us now discuss the case of a completely generic, possibly nonlinear ODE. As before, we set out from the \\(N\\) equations in Eq. 11.44. Again we substitute the function \\(y\\) and its derivatives with \\(w_i\\) and their finite differences. However, in absence of more information about the function \\(f\\), we end up with just \\[\n\\dfrac{w_{i+1}-2 w_i +w_{i-1}}{h^2} =\n   f\\Big(x_i, w_i, \\dfrac{w_{i+1}-w_{i-1}}{2h} \\Big),\n   \\quad  i = 1,\\ldots,N.\n\\tag{11.51}\\] We can rewrite this in a more convenient form: \\[\n   0 = \\underbrace{-w_{i+1}+2 w_i -w_{i-1}\n  + h^2 f\\Big(x_i, w_i, \\dfrac{w_{i+1}-w_{i-1}}{2h} \\Big) }_{\n   =:F^{(i)}(\\mathbf{w})\n  }\n\\tag{11.52}\\] for \\(i = 1,\\ldots,N\\). Our task is now to solve the nonlinear equation system \\(\\mathbf{F}(\\mathbf{w})=0\\) for \\(\\mathbf{w}=(w_1,\\ldots,w_N)\\), where it is understood that \\(w_0=\\alpha\\) and \\(w_{N+1}=\\beta\\).\nWe will do this with the \\(N\\)-dimensional version of Newton’s method, as discussed in Chapter 4. To that end, we need to compute the Jacobian matrix of \\(\\mathbf{F}\\); that is, we need to compute all the partial derivatives \\(\\partial F ^{(i)}/\\partial w ^{(j)}\\). Fortunately, most of these turn out to vanish. We compute from Eq. 11.52, \\[\n  \\frac{\\partial F ^{(i)}}{\\partial w ^{(i+1)}}\n   = -1  + \\frac{h}{2} \\frac{\\partial f}{\\partial y'} \\Big(x_i, w_i, \\dfrac{w_{i+1}-w_{i-1}}{2h} \\Big) \\quad \\text{for } i=1,\\ldots,N-1,\n\\tag{11.53}\\] \\[\n  \\frac{\\partial F ^{(i)}}{\\partial w ^{(i-1)}}\n   = -1  - \\frac{h}{2} \\frac{\\partial f}{\\partial y'} \\Big(x_i, w_i, \\dfrac{w_{i+1}-w_{i-1}}{2h} \\Big) \\quad \\text{for } i=2,\\ldots,N,\n\\tag{11.54}\\] \\[\n  \\frac{\\partial F  ^{(i)}}{\\partial w ^{(i)}}\n   = \\hphantom{-} 2  + h^2 \\frac{\\partial f}{\\partial y} \\Big(x_i, w_i, \\dfrac{w_{i+1}-w_{i-1}}{2h} \\Big) \\quad \\text{for } i=1,\\ldots,N.\n\\tag{11.55}\\]\nAll other partial derivatives are 0. That is, the Jacobian matrix \\(\\mathbf{J}=\\partial \\mathbf{F}/\\partial\\mathbf{w}\\) is tridiagonal. This allows us to solve the linear system involved in each step of the Newton iteration very quickly.\nFor doing the Newton iteration, we need a sensible start value for the vector \\(\\mathbf{w}\\). A common choice is to place the points \\((x_i,w ^{(i)})\\) on a straight line from \\((a,\\alpha)\\) to \\((b,\\beta)\\): \\[\nw ^{(i)}_0 = \\alpha + i h \\frac{\\beta-\\alpha}{b-a}.\n\\tag{11.56}\\]\n\n\n\\begin{algorithm} \\caption{The Nonlinear Finite Difference method} \\begin{algorithmic} \\Function{NonlinearFiniteDifference}{$a,b,\\alpha,\\beta,N,M$} \\State \\Comment{boundary values $\\alpha,\\beta$; number of mesh points $N$; max.~Newton iterations $M$} \\State $h := (b-a)/(N+1)$; $k:=1$ \\State $w^{(i)} := \\alpha + i h \\frac{\\beta-\\alpha}{b-a}$ $(i = 1,\\ldots,N)$ \\Comment{Set start value for $\\mathbf{w}$} \\While{$k\\leq M$} \\State Compute $\\mathbf{F}(\\mathbf{w})$ and $\\mathbf{J}(\\mathbf{w})$ \\State Solve $\\mathbf{J}(\\mathbf{w})\\mathbf{v}=\\mathbf{F}(\\mathbf{w})$ for $\\mathbf{v}$ using e.g. Crout factorization \\State $\\mathbf{w} := \\mathbf{w} - \\mathbf{v}$ \\If{$|\\mathbf{v}|&lt;T$} \\Break \\EndIf \\State $k:=k+1$ \\EndWhile \\Return $\\mathbf{w}$ \\EndFunction \\end{algorithmic} \\end{algorithm}\n\n\nAll that’s left to do is to assemble the algorithm. This is done in Algorithm 11.3. The pattern follows our usual approach to Newton’s method.\nIn each step of the Newton iteration, we need to solve one linear equation system. We can use e.g. the Crout factorization algorithm ((Burden and Faires 2010) Algorithm 6.7) to this end — this makes use of the fact that the Jacobian is tridiagonal, and allows every Newton step to run in only \\(O(N)\\) time.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Boundary Value Problems</span>"
    ]
  },
  {
    "objectID": "bvp.html#sec-rritz",
    "href": "bvp.html#sec-rritz",
    "title": "11  Boundary Value Problems",
    "section": "11.4 The Rayleigh-Ritz Method",
    "text": "11.4 The Rayleigh-Ritz Method\nThe third, and radically different, approximation method for BVPs that we will discuss is called the Rayleigh-Ritz method.\n\n11.4.1 Motivation\nWe start with a brief motivation originating in physics, or in engineering. Consider a beam of length \\(L\\), fixed at both end points, which is deflected under its own weight. Denote with \\(y(x)\\), \\(0 \\leq x \\leq L\\), the deflection of the beam at point \\(x\\). There are two complementary approaches of finding \\(y(x)\\).\na) One may think of the problem in terms of a local equilibrium of forces. Several types of forces act at each point \\(x\\) of the beam - the gravitational force (downwards), but also forces relating to the elasticity of the beam, which pull the deflected beam upwards. In the rest position of the beam, the sum of these forces will be 0 at each point. This leads us to an ODE of the form \\(y''(x) = f(x,y(x),y'(x))\\) (we do not specify the function \\(f\\) further here). The ends of the beam are fixed, so we are enforcing \\(y(0)=y(L)=0\\). Thus, we are dealing with a boundary value problem for an ODE.\nb) Particularly in physics, one alternatively thinks of the situation as an energy minimization problem. The total energy of the beam will consist of its energy in the gravitational field, and of the energy associated with elasticity. We can associate with each point of the beam an energy density, \\(\\lambda\\), which depends on the deflection \\(y\\). It will roughly have the form \\[\n\\lambda  = c y'(x)^2 - d y(x) + \\ldots\n\\tag{11.57}\\] with constants \\(c\\) and \\(d\\), where the term proportional to \\((y'(x))^2\\) comes from elasticity, and the term proportional to \\(y\\) from gravitation. (We are not interested in the form of \\(\\lambda\\) in detail here). The rest position of the beam is now found by the requirement that the total energy of the beam is minimal. This total energy is found by integrating \\(\\lambda\\) over the length of the beam:\n\\[\n   E = \\int_0^L \\lambda (y(x),y'(x)) \\, \\mathrm{d}x\n\\tag{11.58}\\] So we are left with the problem of finding the function \\(y(x)\\) that minimizes the integral Eq. 11.58, while satisfying the boundary conditions \\(y(0)=y(L)=0\\).\nThis example – which is added here only for illustration – raises an interesting mathematical question: Can we, under more general conditions, rewrite a boundary value problem for an ODE equivalently as a minimization problem for an integral expression? If yes, we can try to approximate the integral expression numerically (rather than the BVP), which may offer new options for numerical methods.\n\n\n11.4.2 Equivalence of BVPs with minimization problems\nIn this section, we will specialize to a boundary value problems of the following form (a so-called Sturm-Liouville problem): \\[\n  - \\frac{ \\mathrm{d}^{}  }{\\mathrm{d}x^{} } \\left(p(x) \\frac{ \\mathrm{d}^{} y }{\\mathrm{d}x^{} } (x)\\right)+q(x)y(x)=f(x),\n\\quad 0 \\leq x \\leq 1, \\quad\ny(0)=y(1)=0.\n\\tag{11.59}\\] Here \\(p\\), \\(q\\) and \\(f\\) are sufficiently smooth functions from \\([0,1]\\) to \\(\\mathbb{R}\\); for details see below. We can reformulate this BVP as a minimization problem for an integral expression: The solution \\(y(x)\\) minimizes the integral \\[\n  I[\\phi]\n  =\\int_0^1\\Big(p(x) (\\phi'(x))^2+q(x)\n  \\phi(x)^2-2f(x)\\phi(x)\\Big)dx;\n\\tag{11.60}\\] over all functions \\(\\phi\\) that satisfy the boundary conditions that is, if \\(\\phi\\) is any function satisfying the boundary conditions, then one has \\(I[y] \\leq I[\\phi]\\).\nMore precisely, let \\(\\mathcal{C}^2_0[0,1]\\) denote the space of \\(\\mathcal{C}^2\\) functions on \\([0,1]\\) that vanish at the endpoints of the interval. One has:\n\nTheorem 11.3 Let \\(p \\in \\mathcal{C}^1[0,1]\\), and \\(q,f \\in \\mathcal{C}[0,1]\\). Further, suppose that there exists a constant \\(\\delta&gt;0\\) such that \\[\n\\forall  x \\in [0,1]: \\quad p(x) \\geq \\delta, \\; q(x) \\geq 0.\n\\tag{11.61}\\] Then, for any function \\(y \\in \\mathcal{C}^2_{0}[0,1]\\), the following conditions are equivalent.\n\n\\(y\\) is the unique solution of the boundary value problem in Eq. 11.59.\n\\(y\\) is the unique function in \\(\\mathcal{C}^2_{0}[0,1]\\) which minimizes the integral \\(I[y]\\) in Eq. 11.60.\n\n\n\nProof. Proof. Here we prove only (ii) \\(\\implies\\) (i), neglecting the aspect of uniqueness. For a full proof, see (Burden and Faires 2010 Theorem 11.4) and references quoted there.\nIf \\(y\\) minimizes the integral \\(I[y]\\), then for any fixed \\(u \\in \\mathcal{C}^2_0[0,1]\\), the function \\[\n\\epsilon \\mapsto I[y+\\epsilon u]\n\\tag{11.62}\\] has a minimum at \\(\\epsilon=0\\). Therefore, its derivative at \\(\\epsilon=0\\) must vanish:\n\\[\n\\begin{split}\n0 &= \\frac{\\mathrm{d}}{\\mathrm{d}\\epsilon} I[y+\\epsilon u] \\Big\\lvert_{\\epsilon=0}\n\\\\\n&= \\frac{\\mathrm{d}}{\\mathrm{d}\\epsilon}\\Big\\lvert_{\\epsilon=0}\n   \\int_0^1 \\Big(p(x) (y'(x) + \\epsilon u'(x))^2\n   + q(x) (y(x) + \\epsilon u(x))^2 - 2(y(x)+\\epsilon u(x)) f(x)\\Big)  dx\n\\\\\n&= \\int_0^1 \\Big(2 p(x) (y'(x) + \\epsilon u'(x)) u'(x)\n   + 2 q(x) (y(x) + \\epsilon u(x)) u(x) - 2 u(x) f(x)\\Big)  \\Big\\lvert_{\\epsilon=0} dx\n\\\\\n&=  2 \\int_0^1 \\Big(p(x) y'(x) u'(x)\n   + q(x) y(x) u(x) - u(x) f(x)\\Big)  dx.\n\\end{split}\n\\tag{11.63}\\] We integrate by parts in the first term of the integral, \\((p(x)y'(x))u'(x)\\), noting that the boundary terms vanish since \\(u(0)=u(1)=0\\). This gives \\[\n0 = \\int_0^1 \\Big( -(p(x) y'(x))'  \n   + q(x) y(x)  - f(x)\\Big) u(x)  \\,dx\n\\tag{11.64}\\] Since this holds for all \\(u \\in \\mathcal{C}^2_0[0,1]\\), and since all functions under the integral sign are continuous, we can conclude that \\[\n0 =  -(p y')'  + q y  - f\n\\tag{11.65}\\] on the entire interval \\([0,1]\\), which is what we wanted to show. ◻\n\n\n\n11.4.3 Approximating the integral\nThe Rayleigh-Ritz method makes use of the equivalence stated in Theorem 11.3. The idea is to approximate the function that minimizes the integral \\(I[\\phi]\\), rather than approximating the boundary value problem directly. That is, we try to find functions \\(\\phi\\) that make \\(I[\\phi]\\) as small as possible.\nOf course, we cannot try all functions in the infinite dimensional vector space \\(\\mathcal{C}^2_{0}[0,1]\\). Rather we choose a set of \\(N\\) linearly independent functions (“basis functions”3) \\(\\phi_i\\) with \\(\\phi_i(0)=\\phi_i(1)=0\\), and use an arbitrary linear combination \\[\n  \\phi(x)=\\sum_{i=1}^N c_i\\phi_i(x)\n\\tag{11.66}\\] of these functions as our trial function. The coefficients \\(c_i\\) are to minimize the integral. There is a large freedom of choice for the functions \\(\\phi_j\\), and this can be exploited to adapt the approximation method to our needs. We leave the choice of \\(\\phi_j\\) open for the moment, and will fix them later on.\nSubstituting the trial function Eq. 11.66 into \\(I[\\phi]\\) in Eq. 11.60 gives \\[\nI[\\phi]=\\int_0^1\\left(p(x)\\bigg(\\sum_{i=1}^N c_i\\phi'_i(x)\\bigg)^2\n  +q(x)\\bigg(\\sum_{i=1}^N c_i\\phi_i(x)\\bigg)^2\n  -2f(x)\\sum_{i=1}^N c_i\\phi_i(x)\\right)dx.\n\\tag{11.67}\\] We now minimize over the real parameters \\(c_i\\). They will be fixed by the necessary requirement for having an extremum, namely, that all partial derivatives vanish, \\[\n0=\\frac{\\partial I[\\phi]}{\\partial c_j}\n=\\int_0^1\\left(2p(x)\\sum_{i=1}^Nc_i\\phi'_i(x)\\phi'_j(x)\n+2q(x)\\sum_{i=1}^Nc_i\\phi_i(x)\\phi_j(x)-2f(x)\\phi_j(x)\\right)dx\n\\tag{11.68}\\] for all \\(j=1,\\dots,N\\). This is a linear system of the form \\[\n\\sum_{i=1}^N A ^{(j,i)}c ^{(i)}=b ^{(j)},~~~~j=1,\\dots,N,\n\\tag{11.69}\\] where \\[\nA ^{(j,i)}=\\int_0^1\\Big(p(x)\\phi'_i(x)\\phi'_j(x)+q(x)\\phi_i(x)\\phi_j(x)\\Big)dx,\n\\tag{11.70}\\] \\[\nb ^{(j)}=\\int_0^1 f(x)\\phi_j(x) dx.\n\\tag{11.71}\\] Once the basis functions \\(\\phi_j\\) are chosen, we can compute the components of \\(\\mathbf{A}\\) and \\(\\mathbf{b}\\), solve the linear system Eq. 11.69 for \\(\\mathbf{c}\\), and then obtain the approximation function \\(\\phi\\) from Eq. 11.66.\n\n\n11.4.4 Choosing the basis functions\nThe question is now how to choose the functions \\(\\phi_j\\) so that we get a reasonable numerical approximation of the solution \\(y(x)\\), which is furthermore fast to compute. Our requirements are:\n\nThe \\(\\phi_j\\) need to satisfy the boundary conditions: \\(\\phi_j(0)=\\phi_j(1)=0\\).\nThey should be sufficiently smooth. Note that, for purposes of numerical approximation, it is not be necessary to require two continuous derivatives (as for the ODE solution). Since we deal only with integral expressions in \\(\\phi_j\\) and \\(\\phi_j'\\), it should suffice if \\(\\phi_j\\) has one derivative that exists almost everywhere and is piecewise continuous, or at least integrable.\nThey should be designed so that their linear combinations can approximate a wide range of functions. (This may seem a bit vague; but e.g. choosing all the \\(\\phi_j\\) with support in the interval \\([0,\\frac{1}{2}]\\) would clearly be a bad idea.)\nThey should be simple enough so that the integrals for \\(A ^{(i,j)}\\) and \\(b ^{(j)}\\) in Eq. 11.70 and Eq. 11.71 can reasonably be evaluated - if possible, explicitly.\nIf possible, not many of them should have overlapping support, so that the matrix \\(\\mathbf{A}\\) is sparse, i.e., many of its entries are zero. This will make the linear equation system in Eq. Eq. 11.69 fast to solve.\n\nA simple choice of basis functions, satisfying the above requirements, are the piecewise linear functions \\[\n\\phi_i(x)=\\left\\{\\begin{array}{ll}\n0&\\mbox{if }0\\leq x\\leq x_{i-1};\\\\\n\\frac{1}{h_{i-1}}(x-x_{i-1})&\\mbox{if }x_{i-1}&lt; x\\leq x_{i};\\\\\n\\frac{1}{h_{i}}(x_{i+1}-x)&\\mbox{if }x_{i}&lt; x\\leq x_{i+1};\\\\\n0&\\mbox{if }x_{i+1}&lt; x\\leq 1\n\\end{array}\\right.\n\\tag{11.72}\\] for some conveniently chosen mesh points \\[\n0=x_0&lt;x_1&lt;x_2&lt;\\dots&lt;x_N&lt;x_{N+1}=1.\n\\tag{11.73}\\] The \\(h_i\\) are the distances between neighbouring mesh points, \\(h_i=x_{i+1}-x_i\\); note that the mesh points need not be equally spaced. These basis functions \\(\\phi_i\\) have simple piecewise constant derivatives, \\[\n\\phi'_i(x)=\\left\\{\\begin{array}{ll}\n0&\\mbox{if }0 &lt; x &lt; x_{i-1},\\\\\n\\frac{1}{h_{i-1}}&\\mbox{if }x_{i-1}&lt; x &lt;  x_{i},\\\\\n-\\frac{1}{h_{i}}&\\mbox{if }x_{i}&lt; x &lt; x_{i+1},\\\\\n0&\\mbox{if }x_{i+1} &lt; x &lt; 1.\n\\end{array}\\right.\n\\tag{11.74}\\] A particular simplifying feature of this set of basis functions is that only neighbouring functions have any overlap, i.e., \\[\n\\phi_i(x)\\phi_j(x)=0 ~~\\text{ and }~~\n\\phi'_i(x)\\phi'_j(x)=0~~\\text{ unless }j\\in\\{i-1,i,i+1\\}.\n\\tag{11.75}\\] This implies that the matrix \\(\\mathbf{A}\\) is tridiagonal. To calculate the entries of \\(\\mathbf{A}\\) and \\(\\mathbf{b}\\) in Eq. 11.70 and Eq. 11.71, the following integrals need to be evaluated: \\[\n\\begin{aligned}\nQ_{1,i} &= \\left(\\frac{1}{h_i}\\right)^2\\int_{x_i}^{x_{i+1}}\n  (x_{i+1}-x)(x-x_i)q(x)dx,\\\\\nQ_{2,i} &= \\left(\\frac{1}{h_{i-1}}\\right)^2\\int_{x_{i-1}}^{x_{i}}\n  (x-x_{i-1})^2q(x)dx,\\\\\nQ_{3,i} &= \\left(\\frac{1}{h_{i}}\\right)^2\\int_{x_{i}}^{x_{i+1}}\n  (x_{i+1}-x)^2q(x)dx,\\\\\nQ_{4,i} &= \\left(\\frac{1}{h_{i-1}}\\right)^2\\int_{x_{i-1}}^{x_{i}}\n  p(x)dx,\\\\\nQ_{5,i} &= \\frac{1}{h_{i-1}}\\int_{x_{i-1}}^{x_{i}}\n  (x-x_{i-1})f(x)dx,\\\\\nQ_{6,i} &= \\frac{1}{h_{i}}\\int_{x_{i}}^{x_{i+1}}\n  (x_{i+1}-x)f(x)dx.\n\\end{aligned}\n\\tag{11.76}\\] Then \\[\n\\begin{aligned}\nA ^{(i,i)}&=Q_{4,i}+Q_{4,i+1}+Q_{2,i}+Q_{3,i},~~~&i&=1,\\dots,N,\\\\\nA ^{(i,i+1)}&=-Q_{4,i+1}+Q_{1,i},~~~&i&=1,\\dots,N-1,\\\\\nA ^{(i,i-1)}&=-Q_{4,i}+Q_{1,i-1},~~~&i&=2,\\dots,N,\\\\\nb ^{(i)}&=Q_{5,i}+Q_{6,i},~~~&i&=1,\\dots,N.\n\\end{aligned}\n\\tag{11.77}\\] One way to evaluate the \\(6N\\) integrals is to approximate the functions \\(q(x)\\), \\(p(x)\\), and \\(f(x)\\) by their linear interpolating polynomials. That is, we write \\[\nq(x)=\\sum_{i=0}^{N+1}q(x_i)\\phi_i(x)+O(h^2),\n\\tag{11.78}\\] and similarly for \\(p\\) and \\(f\\), where the \\(\\phi_i\\) are as given above for \\(i=1,\\dots,N\\), and \\[\n\\begin{aligned}\n\\phi_0(x)&=\\left\\{\\begin{array}{ll}\n  \\frac{x_1-x}{x_1}&\\text{if }0\\leq x\\leq x_1,\\\\\n  0&\\text{elsewhere};\\end{array}\\right.\n  \\\\\n  \\phi_{N+1}(x)&=\\left\\{\\begin{array}{ll}\n  \\frac{x-x_N}{1-x_N}&\\text{if }x_N\\leq x\\leq 1,\\\\\n  0&\\text{elsewhere}.\\end{array}\\right.\n\\end{aligned}\n\\tag{11.79}\\] The integrals are now trivial to evaluate, for example \\[\n\\begin{aligned}\nQ_{1,i} &= \\left(\\frac{1}{h_i}\\right)^2\\int_{x_i}^{x_{i+1}}\n  (x_{i+1}-x)(x-x_i)q(x)dx\\\\\n  &\\approx\\left(\\frac{1}{h_i}\\right)^2\\int_{x_i}^{x_{i+1}}\n  (x_{i+1}-x)(x-x_i)\\left(\n  q(x_i)\\frac{x_{i+1}-x}{h_i}+q(x_{i+1})\\frac{x-x_i}{h_i}\n  \\right)dx\\\\\n  &=\\frac{h_i}{12}\\left(q(x_i)+q(x_{i+1})\\right).\n\\end{aligned}\n\\tag{11.80}\\] Similarly we find4 \\[\n\\begin{aligned}\nQ_{2,i}&\\approx\\frac{h_{i-1}}{12}\\left(3q(x_i)+q(x_{i-1})\\right),\\\\\nQ_{3,i}&\\approx\\frac{h_{i}}{12}\\left(3q(x_i)+q(x_{i+1})\\right),\\\\\nQ_{4,i}&\\approx\\frac{1}{2 h_{i-1}}\\left(p(x_i)+p(x_{i-1})\\right),\\\\\nQ_{5,i}&\\approx\\frac{h_{i-1}}{6}\\left(2f(x_i)+f(x_{i-1})\\right),\\\\\nQ_{6,i}&\\approx\\frac{h_{i}}{6}\\left(2f(x_i)+f(x_{i+1})\\right).\n\\end{aligned}\n\\tag{11.81}\\] After this calculation, we can now simply solve the linear system Eq. 11.69 for the coefficients \\(\\mathbf{c}=(c_i)\\) in the trial function in order to find the approximation \\[\ny(x)\\approx\\sum_{i=1}^N c_i\\phi_i(x).\n\\tag{11.82}\\]\n\n\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical Analysis. 9th ed. Brooks Cole.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Boundary Value Problems</span>"
    ]
  },
  {
    "objectID": "bvp.html#footnotes",
    "href": "bvp.html#footnotes",
    "title": "11  Boundary Value Problems",
    "section": "",
    "text": "To explain the notation: These are the partial derivatives of \\(f\\) by its second and third argument, respectively.↩︎\nNote the change of convention: Our step size is now \\(h = (b-a)/(N+1)\\), and we have \\(N+2\\) (not \\(N+1\\)) mesh points, of which \\(N\\) are inside the interval \\((a,b)\\). This convention, which we shall use from now on, is very useful for boundary value problems: the function \\(y\\) needs to be determined at \\(x_1,\\ldots,x_N\\) but is already known at \\(x_0\\) and \\(x_{N+1}\\).↩︎\nWhile these are usually called “basis functions”, e.g. in (Burden and Faires 2010), they are of course not a basis of the space \\(\\mathcal{C}^2_{0}[0,1]\\).↩︎\nNote that Burden/Faires (Burden and Faires 2010) reports the formula for \\(Q_{4,i}\\) incorrectly.↩︎",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Boundary Value Problems</span>"
    ]
  },
  {
    "objectID": "pde.html",
    "href": "pde.html",
    "title": "12  Partial Differential Equations",
    "section": "",
    "text": "12.1 Partial differential equations: Overview\nWe will now consider approximation methods for partial differential equations (PDEs). An example for a PDE – familiar from the first-year Calculus course – is the heat equation: \\[\n\\frac{\\partial^2}{\\partial x^2} u(x,t) = \\kappa \\frac{\\partial}{\\partial t} u(x,t)\n\\tag{12.1}\\] with some constant \\(\\kappa &gt; 0\\). PDEs like the above are defined on a certain region in the \\(x\\)-\\(t\\)-plane (or analogously in more than 2 dimensions), and are always complemented by some kind of boundary conditions on the boundary of that region.\nWe will try to generalize our methods for boundary value problems of ODEs to the case of PDEs. The BVP methods we have discussed are:\nUnfortunately, there is no obvious generalization of the Shooting method to PDEs; the concept of transforming a boundary value problem into an initial value problem does not work in this context.\nHowever, the Finite Difference method can be generalized to PDEs. To that end, we would first need to define a suitable notion of mesh points. Instead of dividing an interval into equally spaced subintervals, we now need to divide a region in two variables (say, a rectangle) with an equally spaced grid of mesh points. Then, as before, one can replace the value of \\(u\\) at mesh points with an approximation value, and the derivatives of \\(u\\) with finite difference quotients, and finally solve a (linear) equation system to obtain the approximation values numerically. We will discuss this more in detail in later sections.\nThe Finite Difference method has limitations when the region in question is not as simple as a rectangle, but is irregularly shaped. In this case, it may not be possible to divide it reasonably with an equally spaced grid, or the mesh points at the edge of the grid may not be located exactly on the boundary (which poses problems when interpreting the boundary values). In these cases, generalizations of the Rayleigh-Ritz method can successfully be used, the so-called Finite Element methods. Note that in the Rayleigh-Ritz method, there was a large freedom of choosing the basis functions \\(\\phi_j\\), and even when restricting to piecewise linear functions, the mesh points \\(x_i\\) did not need to be equally spaced. Likewise, in the multi-dimensional generalizations, one can exploit this freedom to adapt the choice of mesh points to a (possibly irregular) boundary. Finite Element methods are the most advanced numerical methods for solving PDEs, and we will not discuss them in detail here; see, e.g., (Burden and Faires 2010 Ch. 12.4) for an introduction.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "pde.html#sec-pdeoverview",
    "href": "pde.html#sec-pdeoverview",
    "title": "12  Partial Differential Equations",
    "section": "",
    "text": "the Shooting method,\nthe Finite Difference method,\nthe Rayleigh-Ritz method.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "pde.html#elliptic-pdes",
    "href": "pde.html#elliptic-pdes",
    "title": "12  Partial Differential Equations",
    "section": "12.2 Elliptic PDEs",
    "text": "12.2 Elliptic PDEs\nIn this section, we will generalize the Finite Difference method to a very specific PDE, namely the Poisson equation. This equation for a function \\(u\\) of two variables \\(x\\) and \\(y\\) has the form\n\\[\n\\begin{split}\n&\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = f(x,y) \\\\\n&\\text{on } R := \\{ (x,y) : a \\leq x \\leq b, c \\leq y \\leq d \\},\\\\\n&u(x,y) = g(x,y) \\text{ for } x \\in \\partial R.\n\\end{split}\n\\tag{12.2}\\] Here \\(f\\) and \\(g\\) are given functions of two variables, and \\(\\partial R\\) denotes the boundary of \\(R\\), that is, the four line segments \\[\n\\begin{split}\n&x=a, c \\leq y \\leq d; \\quad\nx=b, c \\leq y \\leq d; \\quad\\\\\n&a \\leq x \\leq b,  y=c; \\quad\na \\leq x \\leq b,  y=d.\n\\end{split}\n\\tag{12.3}\\]\nThe equation Eq. 12.2 is, in the case \\(f=0\\), also known as the Laplace equation. It is a typical example of the larger class of elliptic differential equations, and the methods we will discuss here apply to other elliptic equations as well.\nWe will try to set up a Finite Difference method to approximate the solution of Eq. 12.2, following our recipe from Section 11.3. To that end, we first have to specify what our mesh points are. Instead of partitioning the interval \\([a,b]\\), they will now need to partition the rectangle \\(R\\). To this end, we choose two numbers of steps, \\(N\\) and \\(M\\), associated with the \\(x\\) and \\(y\\) direction respectively, and two corresponding step sizes \\[\nh := \\frac{b-a}{N+1}, \\quad k := \\frac{d-c}{M+1}.\n\\] We then define \\(N \\times M\\) mesh points \\((x_i, y_j)\\) as \\[\n(x_i, y_j) = (a + i h, c + j k), \\quad 1 \\leq i \\leq N, \\; 1 \\leq j \\leq M.\n\\] These lie on a rectangular grid within the rectangle \\(R\\).\nOur next step is to approximate the relevant derivatives of \\(u\\) at the mesh points. We use the centred difference formula Eq. 11.43 twice, once in \\(x\\) direction (at fixed \\(y\\)) and once in \\(y\\) direction (at fixed \\(x\\)). This gives \\[\n\\begin{aligned}\n\\frac{\\partial^2 u}{\\partial x^2} (x_i,y_j)\n  = \\frac{ u(x_{i+1},y_j) - 2 u(x_i,y_j) + u(x_{i-1},y_j) }{h^2} - \\frac{h^2}{12} \\frac{\\partial^4 u}{\\partial x^4}(\\xi_i,y_j),\n  \\\\\n\\frac{\\partial^2 u}{\\partial y^2} (x_i,y_j)\n  = \\frac{ u(x_{i},y_{j+1}) - 2 u(x_i,y_j) + u(x_{i},y_{j-1}) }{k^2} - \\frac{k^2}{12} \\frac{\\partial^4 u}{\\partial y^4}(x_i,\\eta_j),\n\\end{aligned}\n\\tag{12.4}\\] where \\(\\xi_i\\) and \\(\\eta_j\\) are some unknown points in the intervals.\nAgain following our recipe, we will approximate the solution at mesh points \\(u(x_i,y_j)\\) with approximation values \\(w_{i,j}\\). In the PDE Eq. 12.2, we then replace \\(u(x_i,y_j)\\) with \\(w_{i,j}\\) and the derivatives of \\(u\\) with the expressions Eq. 12.4, but leaving away the remainder terms of order \\(O(h^2)+O(k^2)\\). This yields the following equations for the \\(w_{i,j}\\): \\[\n\\frac{ w_{i+1,j} - 2 w_{i,j} + w_{i-1,j} }{h^2} + \\frac{ w_{i,j+1} - 2 w_{i,j} + w_{i,j-1} }{k^2} = f(x_i,y_j)\n\\] for \\(1 \\leq i \\leq N, \\; 1 \\leq j \\leq M\\). After multiplying with \\(-h^2\\), \\[\n2 \\Big(\\big(\\tfrac{h}{k}\\big)^2+1\\Big) w_{i,j} -  w_{i+1,j} - w_{i-1,j}  -  \\big(\\tfrac{h}{k}\\big)^2 w_{i,j+1} - \\big(\\tfrac{h}{k}\\big)^2 w_{i,j-1}  = -h^2 f(x_i,y_j).\n\\tag{12.5}\\]\nThe boundary conditions are then expressed by setting the values of \\(w_{i,j}\\) for \\(i=0\\), \\(j=0\\), \\(i=N+1\\) or \\(j=M+1\\) to the required boundary values: \\[\n\\begin{aligned}\n  w_{0,j} &= g(x_0,y_j),  &w_{N+1,j} &= g(x_{N+1},y_j) & \\text{for } 1 \\leq j \\leq M,\n  \\\\\n  w_{i,0} &= g(x_i,y_0),  &w_{i,M+1} &= g(x_{j},y_{M+1}) & \\text{for } 1 \\leq i \\leq N.\n\\end{aligned}\n\\tag{12.6}\\] Together, Eq. 12.5 and Eq. 12.6 form a linear equation system that can be solved to obtain approximation values \\(w_{i,j}\\). To that end, it may be useful to renumber the “double indices” \\(i,j\\) with a single index, setting, e.g., \\(\\ell := N(i-1)+j\\). The index \\(k\\) then runs from \\(1\\) to \\(NM\\), and we may rewrite the equation system as \\(\\mathbf{A}\\mathbf{w}= \\mathbf{b}\\) with a \\(NM \\times NM\\) matrix \\(\\mathbf{A}\\) and a vector \\(\\mathbf{b}\\in\\mathbb{R}^{NM}\\).\nAs in the one-dimensional case, the matrix \\(\\mathbf{A}\\) is sparse, that is, many of its entries are known to be zero. (It is not tridiagonal, however.) This makes the system \\(\\mathbf{A}\\mathbf{w}= \\mathbf{b}\\) fast to solve. Nevertheless, it is evident that the number of mesh points (and hence of vector dimensions) can become rather large quite easily, which sets practical limits to the accuracy of this and other approximation methods for PDEs.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "pde.html#parabolic-pdes",
    "href": "pde.html#parabolic-pdes",
    "title": "12  Partial Differential Equations",
    "section": "12.3 Parabolic PDEs",
    "text": "12.3 Parabolic PDEs\nAs a second class of PDEs to be treated with the Finite Difference method, we consider parabolic PDEs. A typical example – and the only one we will consider – is the one-dimensional heat equation (also known as diffusion equation). This equation for a function \\(u\\) of two variables \\(x\\) and \\(t\\) has the form1 \\[\n\\begin{aligned}\n&\\alpha^2 \\frac{\\partial^2 u}{\\partial x^2} =  \\frac{\\partial u}{\\partial t}  \\quad \\text{on } R := \\{ (x,t) : 0 \\leq x \\leq L, 0 \\leq t \\},\\\\\n&u(x,0) = g(x) \\text{ for } 0 &lt; x &lt; L,\\\\\n&u(0,t) = u(L,t) = 0 \\text{ for all } t &gt; 0.\n\\end{aligned}\n\\tag{12.7}\\] The boundary of the region \\(R\\) consists of three pieces here. One also refers to the condition \\(u(x,0) = g(x)\\) as initial condition; as we will see, it has some similarities to initial conditions for ODEs.\nIn applications, \\(u(x,t)\\) might have the interpretation of a local temperature – say, in a homogeneous wall of width \\(L\\) – depending on the spatial position \\(x\\) and on time \\(t\\). The initial condition is the temperature in the wall at time 0, and the remaining boundary conditions represent the temperature of the environment, depending on time \\(t\\).\nAgain, we will set up a Finite Difference method to approximate the solution of Eq. 12.7, following our recipe from Section 11.3. As a first step, we restrict the region \\(R\\) to a rectangle, introducing the condition \\(0 \\leq t \\leq T\\) (with some fixed \\(T&gt;0\\)). Then, as for the Laplace equation, we introduce two numbers of steps, \\(N\\) and \\(M\\), associated with the \\(x\\) and \\(t\\) direction respectively, and two corresponding step sizes \\[\nh := \\frac{L}{N+1}, \\quad k := \\frac{T}{M}\n\\] (note the slightly different convention for \\(k\\) from before). Once more, we define mesh points \\((x_i, t_j)\\) as \\[\n(x_i, t_j) = (i h, j k), \\quad 0 \\leq i \\leq N+1, \\; 0 \\leq j \\leq M.\n\\]\nThe next step is to approximate the derivatives of \\(u\\), and here the very specific properties of the equation Eq. 12.7 show up. In the variable \\(x\\), we once more use the centred difference formula Eq. 11.43, leading to \\[\n\\frac{\\partial^2u}{\\partial x^2}u(x_{i},t_j)  = \\frac{ u(x_{i+1},t_j) - 2 u(x_i,t_j) + u(x_{i-1},t_j) }{h^2} + O(h^2).\n\\tag{12.8}\\]\nHowever, for the derivative by \\(t\\), we cannot follow the same approach. The problem here is that the centred difference formula for the first derivative would involve \\(u(x_i,t_{j+1})\\) and \\(u(x_i,t_{j-1})\\), but we have only one boundary (or initial) condition to fix the value if the mesh point is on the boundary of \\(R\\), and this would lead to an under-determined linear equation system later. As a way out, we use the (much simpler) forward difference formula, \\[\n\\frac{\\partial u}{\\partial t}u(x_{i},t_j)  = \\frac{ u(x_{i},t_{j+1}) -  u(x_i,t_j) }{k} + O(k).\n\\tag{12.9}\\]\nFurther following our recipe, we insert the finite difference formulas Eq. 12.8 and Eq. 12.9 into the PDE Eq. 12.7, then replace \\(u(x_i,y_j)\\) with approximation values \\(w_{i,j}\\) and leave away the remainder terms of order \\(O(h^2)+O(k)\\). This yields the following equations for the \\(w_{i,j}\\): \\[\n\\alpha^2 \\frac{ w_{i+1,j} - 2 w_{i,j} + w_{i-1,j} }{h^2} = \\frac{ w_{i,j+1} - w_{i,j} }{k} ,\n\\quad 1 \\leq i \\leq N, \\; 0 \\leq j &lt; M.\n\\] or, setting \\(\\lambda := \\alpha^2 k / h^2\\), \\[\n  w_{i,j+1} = (1-2\\lambda) w_{i,j} + \\lambda (w_{i+1,j}+w_{i-1,j})\n\\tag{12.10}\\]\nwhere \\(w_{0,j}=w_{N+1,j}=0\\) for all \\(j\\) (boundary condition) and \\(w_{i,0} = g(x_i)\\) for all \\(i\\) (initial condition).\nAn interesting point is that the linear equation system Eq. 12.10 is extremely easy to solve: Namely, inserting the known values \\(w_{i,0}\\) into the right-hand side gives us \\(w_{i,1}\\) for all \\(i\\); again inserting these into the right hand side gives us \\(w_{i,2}\\) for all \\(i\\); and so forth. We can rewrite this procedure in matrix form: Setting \\[\n\\begin{aligned}\n\\mathbf{w}_j &:= (w_{1,j},\\ldots, w_{N,j}),\\\\\n\\mathbf{A}_+ &:= \\begin{pmatrix}\n          (1-2\\lambda) & \\lambda&  0 & & \\cdots & 0 \\\\\n          \\lambda & (1-2\\lambda) & \\lambda&  0 & \\cdots & 0 \\\\\n          0 & \\lambda & (1-2\\lambda) & \\lambda&   \\cdots & 0 \\\\\n       0 & \\ddots & \\ddots & \\ddots & \\ddots & \\lambda \\\\\n          0 & \\cdots & & 0 & \\lambda & (1-2\\lambda)\n       \\end{pmatrix} \\quad \\text{(an $N \\times N$ matrix)},\n\\end{aligned}\n\\] we obtain the relation \\[\n\\mathbf{w}_{j+1} = \\mathbf{A}_+ \\mathbf{w}_j .\n\\] Thus, starting with the initial value \\(\\mathbf{w}_0\\), the approximation can be obtained by an iterated matrix multiplication. This approximation method is called the Forward Difference method.\nThe Forward Difference method is very simple to apply, but it has a major disadvantage: it becomes unstable if the the step size \\(k\\) is not chosen very small. This phenomenon is closely related to the one we saw for stiff equations in Section 10.9. We will skip a more in-depth analysis here; see (Burden and Faires 2010, sec. 12.2).\nWe do, however, want to present a solution to the stability problem here, which is similar to the one found for stiff equations: we use an “implicit method” for approximation, the Backward Difference method. To that end, instead of the forward difference formula Eq. 12.9, we use the backward difference formula\n\\[\n\\frac{\\partial u}{\\partial t} (x_i,t_j)\n    = \\frac{ u(x_{i},t_{j}) -  u(x_i,t_{j-1}) }{k} + O(k).\n\\tag{12.11}\\] Leaving all other construction steps the same, we arrive at another method of order \\(O(h^2+k)\\) where the equation system Eq. 12.10 is now replaced by\n\\[\n  w_{i,j-1} = (1+2\\lambda) w_{i,j} - \\lambda (w_{i+1,j}+w_{i-1,j}).\n\\tag{12.12}\\]\nAgain, we rewrite this in matrix form: with \\[\n\\begin{aligned}\n\\mathbf{w}_j &:= (w_{1,j},\\ldots, w_{N,j}),\\\\\n\\mathbf{A}_- &:= \\begin{pmatrix}\n          (1+2\\lambda) & -\\lambda&  0 & & \\cdots & 0 \\\\\n          -\\lambda & (1+2\\lambda) & -\\lambda&  0 & \\cdots & 0 \\\\\n          0 & -\\lambda & (1+2\\lambda) & -\\lambda&   \\cdots & 0 \\\\\n       0 & \\ddots & \\ddots & \\ddots & \\ddots & -\\lambda\\\\\n          0 & \\cdots & & 0 & -\\lambda & (1+2\\lambda) ,\n       \\end{pmatrix},\n\\end{aligned}\n\\] we can rewrite Eq. 12.12 as \\[\n\\mathbf{w}_{j-1} = \\mathbf{A}_- \\mathbf{w}_j .\n\\] This does no longer explicitly give \\(\\mathbf{w}_j\\) from \\(\\mathbf{w}_{j-1}\\). However, this is only a matter of matrix inversion (or, equivalently, solving linear equation systems) as we clearly have \\[\n\\mathbf{w}_{j} = \\mathbf{A}_-^{-1} \\mathbf{w}_{j-1} .\n\\] Starting from \\(\\mathbf{w}_0\\), this again allows us to compute all approximation values by iterative matrix multiplication (or iteratively solving linear equation systems). Since the matrix \\(\\mathbf{A}\\) is sparse (tridiagonal), this can be done very efficiently. Thus the Backward Difference method is only slightly more complex than the Forward Difference method. It does, however, not suffer from stability problems.\nWe can reach a unified view of the two schemes by considering the \\(N\\times N\\) tridiagonal matrix \\[\nB=\\begin{pmatrix}\n          2 & -1 &  0 & & \\cdots & 0 \\\\\n          -1 & 2 & -1&  0 & \\cdots & 0 \\\\\n          0 & -1 & 2 & -1&   \\cdots & 0 \\\\\n       0 & \\ddots & \\ddots & \\ddots & \\ddots & -1\\\\\n          0 & \\cdots & & 0 & -1 & 2\n\\end{pmatrix}\n\\] Applied to a vector \\(y\\in\\mathbb{R}^N\\), it gives \\[\n-2y_1+y_2, \\dots, y_{i+1}-2y_i+y_{i+1},\\dots, y_{N-1}-2y_N\n\\] Apart from a factor of \\(1/h^2\\), this is exactly the symmetric difference formula for the second derivative, applied the sequence of values \\(0,y_1,y_2,\\dots,y_N,0\\).\nConsider Euler’s method, with step length \\(k\\): \\[\n\\mathbf{w}_{j+1}=\\mathbf{w}_j+k(\\text{derivative})\n\\] In our problem, the time derivative is \\(\\alpha^2\\) times the second space derivative, which can be calculated using the matrix \\(B\\). Once the scale factors are taken into account, Euler’s method leads us to \\[\n\\mathbf{w}_{j+1}=\\mathbf{w}_j+\\lambda B\\mathbf{w}_j=(I+\\lambda B)\\mathbf{w}_j=A_+\\mathbf{w}_j\n\\] which is exactly the forward difference method above. The backward difference method is given by \\[\n\\mathbf{w}_{j+1}=\\mathbf{w}_j+\\lambda B\\mathbf{w}_{j+1}\n\\] in which we think of the one-sided difference quotient as an approximation for the derivative at the right-hand endpoint, not the left-hand endpoint. This rearranges to \\[\n\\mathbf{w}_j=(I-\\lambda B)\\mathbf{w}_{j+1}=A_-\\mathbf{w}_{j+1},\n\\] which is exactly the backward difference method above. As a single-step method for ODEs, this is known as the backward Euler or implicit Euler method.\nFinally, analogously to the implicit trapezoidal method, we can use the average of the steps from the forward and backward difference method to give the Crank-Nicolson method. \\[\n\\mathbf{w}_{j+1}=\\mathbf{w}_j+\\frac{1}{2}\\left(\\lambda B\\mathbf{w}_j+\\lambda B\\mathbf{w}_{j+1}\\right)\n\\] Rearranging this gives us \\[\n(I-\\lambda B/2)\\mathbf{w}_{j+1}=(I+\\lambda B/2)\\mathbf{w}_j\n\\] Like the backward difference method, this gives us a tridiagonal system of equations to solve to get from \\(\\mathbf{w}_j\\) to \\(\\mathbf{w}_{j+1}\\), and can be used to find \\(\\mathbf{w}_j\\) for any \\(j\\).\nIt turns out that the error terms for the forward and backward difference methods have the form \\(Ck+O(k^2)\\) and \\(-Ck+O(k^2)\\). Taking the average cancels the \\(\\pm Ck\\) terms and leaves an error of order \\(O(k^2)\\); in combination with the space variable, we have \\(O(h^2)+O(k^2)\\) for the whole method, as compared with \\(O(h^2)+O(k)\\) for the forward and backward difference methods. Like the implicit trapezoidal method, the Crank-Nicolson method is absolutely stable.\n\n\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical Analysis. 9th ed. Brooks Cole.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "pde.html#footnotes",
    "href": "pde.html#footnotes",
    "title": "12  Partial Differential Equations",
    "section": "",
    "text": "In the form presented here, the equation is actually explicitly solvable in terms of a Fourier series. One might ask therefore why numerical approximation methods are necessary. The answer is that the boundary conditions \\(u(0, t) = u(L, t) = 0\\) chosen here are rather simplistic, which was done to simplify the discussion. But the numerical method can be generalized to more intricate boundary conditions where an explicit solution is no longer feasible.↩︎",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix A — Taylor’s theorem",
    "section": "",
    "text": "In many of the approximations and error estimates that we make throughout this course, Taylor’s theorem plays an important role. Since the theorem can be formulated in various ways, in particular, with different forms of the remainder term, it will be recalled in this appendix, with the conventions we use.\nWe first repeat the theorem in its simplest form, for a real-valued function of one real variable, with the remainder in Lagrange form (Apostol 1969, sec. 7.7).\n\nTheorem A.1 Let \\(I\\subset\\mathbb{R}\\) be an interval, and \\(f \\in \\mathcal{C}^{k+1}(I,\\mathbb{R})\\). For each \\(a \\in I\\) and \\(x \\in I\\), there exists \\(\\xi \\in [a,x]\\) such that \\[\nf(x) = \\sum_{j=0}^k \\frac{1}{j!} \\frac{d^j f}{dx^j}(a) \\, (x-a)^j\n   + \\frac{1}{(k+1)!} \\frac{d^{k+1} f}{dx^{k+1}}(\\xi) \\, (x-a)^{k+1}.\n\\tag{A.1}\\]\n\nFor our purposes, we need generalizations of Taylor’s theorem both to functions of several variables and to vector-valued functions. Let us formulate a full generalization to functions \\(\\mathbf{f}:\\mathbb{R}^m\\to\\mathbb{R}^n\\), even if we do not actually need it in this generality.\nFor this, we need some notation. A tuple of \\(m\\) nonnegative integers, \\(\\mathbf{j}= (j ^{(1)},\\ldots,j ^{(m)})\\in \\mathbb{N}_0^m\\), is called a multi-index. We use the following shorthand notation: \\[\n\\begin{aligned}\n|\\mathbf{j}| &= j ^{(1)} + \\ldots + j ^{(m)} &\\text{(the \\emph{length} of the multi-index)},\n\\\\\n\\mathbf{j}! &= j ^{(1)}! \\cdot \\ldots \\cdot j ^{(m)}!, &\n\\\\\n\\mathbf{x}^{\\mathbf{j}} &= (x ^{(1)})^{j ^{(1)}} \\cdot\\ldots\\cdot (x ^{(m)})^{j ^{(m)}}& \\text{for $\\mathbf{x}\\in\\mathbb{R}^m$},\n\\\\\n\\frac{\\partial^{|\\mathbf{j}|} \\mathbf{f}}{\\partial \\mathbf{x}^\\mathbf{j}} &=\n\\frac{\\partial^{|\\mathbf{j}|} \\mathbf{f}}{ (\\partial x ^{(1)})^{j ^{(1)}} \\cdots (\\partial x ^{(m)})^{j ^{(m)}}}. &\n\\end{aligned}\n\\tag{A.2}\\] Taylor’s theorem can then be formulated as follows.\n\nTheorem A.2 Let \\(D \\subset \\mathbb{R}^m\\) be convex, and let \\(\\mathbf{f}\\in \\mathcal{C}^{k+1}(D,\\mathbb{R}^n)\\). For each \\(\\mathbf{a}\\in D\\), there exists \\(\\mathbf{R}_\\mathbf{a}: D \\to \\mathbb{R}^n\\) such that \\[\n\\mathbf{f}(\\mathbf{x}) = \\sum_{|\\mathbf{j}|\\leq k} \\frac{1}{\\mathbf{j}!} \\frac{\\partial^{|\\mathbf{j}|} \\mathbf{f}}{\\partial\\mathbf{x}^\\mathbf{j}}(\\mathbf{a}) \\, (\\mathbf{x}-\\mathbf{a})^\\mathbf{j}+ \\mathbf{R}_\\mathbf{a}(\\mathbf{x})\n\\tag{A.3}\\] and \\[\n\\lVert \\mathbf{R}_\\mathbf{a}(\\mathbf{x}) \\rVert \\leq \\lVert \\mathbf{x}-\\mathbf{a} \\rVert^{k+1}\\sum_{|\\mathbf{j}|=k+1} \\frac{1}{\\mathbf{j}!}\n    \\sup_{\\mathbf{x}' \\in D} \\big\\lVert \\frac{\\partial^{|\\mathbf{j}|} \\mathbf{f}}{\\partial\\mathbf{x}^\\mathbf{j}}(\\mathbf{x}') \\big\\rVert\n\\tag{A.4}\\] for all \\(\\mathbf{x}\\in D\\).\n\n(See (Devinatz 1968, sec. 7.4) for a proof in the case \\(n=1\\) and with an explicit remainder term. The above version then follows by estimating the remainder with its supremum, and taking the maximum over the components of \\(\\mathbf{f}\\). It is possible to obtain an explicit form of the remainder for \\(n&gt;1\\) as well, although not in Lagrange form; but the formula is slightly complicated, and we will not need it.)\nWe are interested in the following special cases. First, there is the case where \\(m=1\\), i.e., \\(\\mathbf{f}\\) depends only on one variable. Then the multi-index \\(\\mathbf{j}\\) is just a number \\(j \\in \\mathbb{N}_0\\), the partial derivatives are ordinary derivatives, and we obtain:\n\nTheorem A.3 Let \\(I\\) be an interval, and let \\(\\mathbf{f}\\in \\mathcal{C}^{k+1}(I,\\mathbb{R}^n)\\). For each \\(a \\in I\\), there exists \\(\\mathbf{R}_a : I \\to \\mathbb{R}^n\\) such that \\[\n\\mathbf{f}(x) = \\sum_{j=0}^{k} \\frac{1}{j!} \\frac{d^j \\mathbf{f}}{dx^j}(a) \\, (x-a)^j + \\mathbf{R}_a(x)\n\\tag{A.5}\\] and \\[\n\\lVert \\mathbf{R}_a(x) \\rVert \\leq  \\frac{\\lvert x-a \\rvert^{k+1}}{(k+1)!}\n    \\sup_{x' \\in I} \\big\\lVert \\frac{d^j \\mathbf{f}}{dx^j}(x') \\big\\rVert\n\\tag{A.6}\\] for all \\(x \\in I\\).\n\nOn other occasions, we will need the function \\(\\mathbf{f}: \\mathbb{R}^m\\to\\mathbb{R}^n\\) in full generality, but use the Taylor expansion only up to order \\(k \\leq 1\\). In this case, the relevant derivatives of \\(\\mathbf{f}\\) can be written in an easier way: Those with \\(|\\mathbf{j}|=1\\) are just single derivatives \\(\\partial \\mathbf{f}/\\partial x ^{(p)}\\) with \\(p\\) ranging from \\(1\\) to \\(m\\), and they can conveniently be combined into a matrix \\(\\partial\\mathbf{f}/\\partial \\mathbf{x}\\). We have \\[\n\\sum_{|\\mathbf{j}|=1} \\frac{1}{\\mathbf{j}!} \\frac{\\partial^{|\\mathbf{j}|} \\mathbf{f}}{\\partial\\mathbf{x}^\\mathbf{j}}(\\mathbf{a}) \\, (\\mathbf{x}-\\mathbf{a})^\\mathbf{j}= \\frac{\\partial \\mathbf{f}}{\\partial\\mathbf{x}}(\\mathbf{a}) \\cdot (\\mathbf{x}-\\mathbf{a}),\n\\tag{A.7}\\] reading the r.h.s. as a matrix product. The derivatives with \\(|\\mathbf{j}|=2\\) are of the form \\(\\partial^2 \\mathbf{f}/\\partial x ^{(p)}\\partial x ^{(q)}\\), where both cases \\(p=q\\) and \\(p \\neq q\\) occur. Working out the numerical prefactors, one obtains the following special cases for order \\(k=0\\) and \\(k=1\\) repectively.\n\nTheorem A.4 Let \\(D \\subset \\mathbb{R}^m\\) be convex, and let \\(\\mathbf{f}\\in \\mathcal{C}^{1}(D,\\mathbb{R}^n)\\). For each \\(\\mathbf{a}\\in D\\), there exists \\(\\mathbf{R}_\\mathbf{a}: D \\to \\mathbb{R}^n\\) such that \\[\n\\mathbf{f}(\\mathbf{x}) = \\mathbf{f}(\\mathbf{a}) + \\mathbf{R}_\\mathbf{a}(\\mathbf{x})\n\\tag{A.8}\\] and \\[\n\\lVert \\mathbf{R}_\\mathbf{a}(\\mathbf{x}) \\rVert \\leq \\lVert \\mathbf{x}-\\mathbf{a} \\rVert \\; \\sup_{\\mathbf{x}' \\in D} \\big\\lVert  \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}}(\\mathbf{x}') \\big\\rVert\n\\tag{A.9}\\] for all \\(\\mathbf{x}\\in D\\).\n\n\nTheorem A.5 Let \\(D \\subset \\mathbb{R}^m\\) be convex, and let \\(\\mathbf{f}\\in \\mathcal{C}^{2}(D,\\mathbb{R}^n)\\). For each \\(\\mathbf{a}\\in D\\), there exists \\(\\mathbf{R}_\\mathbf{a}: D \\to \\mathbb{R}^n\\) such that \\[\n\\mathbf{f}(\\mathbf{x}) = \\mathbf{f}(\\mathbf{a}) + \\frac{\\partial \\mathbf{f}}{\\partial\\mathbf{x}}(\\mathbf{a}) \\cdot (\\mathbf{x}-\\mathbf{a}) +  \\mathbf{R}_\\mathbf{a}(\\mathbf{x})\n\\tag{A.10}\\] and \\[\n\\lVert \\mathbf{R}_\\mathbf{a}(\\mathbf{x}) \\rVert \\leq \\frac{1}{2}\\lVert \\mathbf{x}-\\mathbf{a} \\rVert^{2} \\sum_{p,q=1}^m  \n    \\sup_{\\mathbf{x}' \\in D} \\big\\lVert \\frac{\\partial^2 \\mathbf{f}}{\\partial x ^{(p)} \\partial x ^{(q)}}(\\mathbf{x}') \\big\\rVert\n\\tag{A.11}\\] for all \\(\\mathbf{x}\\in D\\).\n\n\n\n\n\nApostol, T. M. 1969. Calculus, Vol. 1. 2nd ed. Wiley.\n\n\nDevinatz, A. 1968. Advanced Calculus. Holt, Rinehart; Winston.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Taylor's theorem</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Apostol, T. M. 1969. Calculus, Vol. 1. 2nd ed. Wiley.\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. Numerical\nAnalysis. 9th ed. Brooks Cole.\n\n\nDevinatz, A. 1968. Advanced Calculus. Holt, Rinehart; Winston.\n\n\nKelley, C. T. 1995. Iterative Methods for\nLinear and Nonlinear\nEquations. Frontiers in Applied\nMathematics. Society for Industrial; Applied Mathematics\n(SIAM).\n\n\nOrtega, James M. 1972. Numerical Analysis; a Second Course.\nComputer Science and Applied Mathematics. New York: Academic Press. https://yorsearch.york.ac.uk/permalink/f/1d5jm03/44YORK_ALMA_DS21223457930001381.\n\n\nStewart, J. 1991. Calculus. Brooks/Cole.\n\n\nWait, R. A. 1979. The Numerical Solution\nof Algebraic Equations.\nWiley-Interscience Publication. John Wiley. https://yorsearch.york.ac.uk/permalink/f/1d5jm03/44YORK_ALMA_DS21219298850001381.\n\n\nWeir, M. D., G. B. Thomas, and J. Hass. 2010. Thomas’ Calculus.\nAddison-Wesley.",
    "crumbs": [
      "Appendices",
      "References"
    ]
  }
]