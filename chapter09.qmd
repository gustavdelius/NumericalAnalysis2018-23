# A direct method for solving tridiagonal linear systems

Consider the following system of linear equations
$$
A\mathbf{x}= \mathbf{F},
$$

where $\mathbf{F}\in\mathbb{R}^n$ is a given vector, $\mathbf{x}\in\mathbb{R}^n$ is the vector of unknowns and $A$ is a given $n\times n$ tridiagonal matrix, i.e. 
$$
A= \begin{pmatrix}
       C_1      &B_1    &0      &\cdots &\cdots &\cdots  &0      \\
       A_2      &C_2    &B_2    &\ddots &       &        &\vdots  \\
       0        &A_3    &C_3    &B_3    &\ddots &        &\vdots  \\
       \vdots   &\ddots &\ddots &\ddots &\ddots &\ddots  &\vdots  \\
       \vdots   &       &\ddots &\ddots &\ddots &\ddots  &0       \\
       \vdots   &       &       &\ddots &\ddots &C_{n-1} &B_{n-1} \\
       0        &\cdots &\cdots &\cdots &0      &A_n     &C_n
\end{pmatrix}.
$$ 

A system like this has appeared when we discussed spline interpolation (see @eq-d14). Similar linear systems also arise in finite-difference methods for solving differential equations. Of course, the solution of this system can be approximated using iterative techniques such as Jacobi or Gauss-Seidel methods. However, there are much more efficient direct methods for solving such systems. All direct methods are equivalent to Gaussian elimination applied to the above trigiagonal system. One of these, called the double-sweep method, is described below.

The above system of linear equations can be written as 
$$
\begin{split}
C_{1}x_{i}+B_{1}x_{2}&=F_{1}, \\
A_{i}x_{i-1}+C_{i}x_{i}+B_{i}x_{i+1}&=F_{i} \quad \hbox{for}\quad i=2, \dots, n-1,\\
A_{n}v_{n-1}+C_{n}v_{n}&=F_{n}.
\end{split}
$$ {#eq-dsweep1}


It is convenient to introduce 
$$
x_0=0 \quad \hbox{and} \quad x_{n+1}=0.  
$${#eq-dsweep2}

Then @eq-dsweep1 can be rewritten as 
$$
A_{i}x_{i-1}+C_{i}x_{i}+B_{i}x_{i+1}=F_{i} \quad \hbox{for}\quad i=1, \dots, n,
$$ {#eq-dsweep3}

and equations @eq-dsweep2 are now interpreted as boundary conditions for @eq-dsweep3.

To solve @eq-dsweep3, we will seek $\alpha_{i}$ and $\beta_{i}$ such that 
$$
x_{i-1}=\alpha_{i}x_{i}+\beta_{i}  \quad  \hbox{for} \quad
i=1, 2, \dots, n+1.  
$${#eq-y24}
Substitution of @eq-y24 into @eq-dsweep3 yields 
$$
(\alpha_{i}A_{i}+C_{i})x_{i}+B_{i}x_{i+1}+\beta_{i}A_{i}-F_{i}=0 \quad \hbox{for}\quad i=1, \dots, n. 
$${#eq-y25}
From @eq-y24, we also have 
$$
x_{i}=\alpha_{i+1}x_{i+1}+\beta_{i+1}  \quad  \hbox{for} \quad
i=0, 1, \dots, n.
$$ 
Substituting this into @eq-y25, we find that 
$$
[(\alpha_{i}A_{i}+C_{i})\alpha_{i+1}+B_{i}]x_{i+1}+[
(\alpha_{i}A_{i}+C_{i})\beta_{i+1}+\beta_{i}A_{i}-F_{i}]=0 \quad \hbox{for}\quad i=1, \dots, n.
$$ 
The last equation is satisfied if the two expressions in the square brackets are both zero. This leads to the following recursive formulae: 
$$
\alpha_{i+1}=-\frac{B_{i}}{C_{i}+\alpha_{i}A_{i}}, \quad
\beta_{i+1}=-\frac{\beta_{i}A_{i}-F_{i}}{C_{i}+\alpha_{i}A_{i}}, \quad
\hbox{for}\quad i=1, \dots, n. 
$${#eq-y26}
Now if $\alpha_{1}$ and $\beta_{1}$ are known, then $\alpha_{i}$ and $\beta_{i}$ for $i=2, 3, \dots, n+1$ can be computed from @eq-y26. $\alpha_{1}$ and $\beta_{1}$ can be determined from @eq-y24 and the fact that $x_{0}=0$. Indeed, 
$$
x_{0}= \alpha_{1}x_{1}+\beta_{1} \quad \hbox{and} \quad x_{0}=0 \quad \Rightarrow \quad
\alpha_{1}x_{1}+\beta_{1}=0.
$$ 
To satisfy the last equation, we choose $\alpha_{1}=0$ and $\beta_{1}=0$. Once we know all $\alpha_{i}$ and $\beta_{i}$, we compute $x_{n}, x_{n-1}, \dots, x_{1}$ using formula @eq-y24.

Formulae @eq-y24 and @eq-y26 will work provided that the coefficients $A_{i}$, $B_{i}$ and $C_{i}$ are such that $C_{i}+\alpha_{i}A_{i}\neq 0$ for $i=1,\dots,n$. For tridiagonal systems that arise in finite-difference methods for differential equations, the coefficients $A_{i}$, $B_{i}$ and $C_{i}$ usually satisfy the inequalities 
$$
A_{i}, B_{i} > 0, \quad  C_{i} < 0, \quad -C_{i} \geq A_{i} + B_{i}.  
$${#eq-y23}
It can be shown that these restrictions on $A_{i}$, $B_{i}$ and $C_{i}$ are sufficient for the double-sweep method to work.
